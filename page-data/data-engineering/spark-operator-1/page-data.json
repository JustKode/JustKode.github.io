{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-engineering/spark-operator-1/","result":{"data":{"markdownRemark":{"html":"<p>안녕하세요, 박민재입니다. 아마 2년 전 즈음에 <a href=\"https://justkode.kr/data-engineering/spark-on-k8s-1/\">Spark on Kubernetes</a> 관련 내용을 다뤘었는데요 (이 글 또한, 개정판을 작성 해 볼게요), 이번에는 Spark Job을 Kubernetes Cluster에 편리하게 제출할 수 있게 하는 Spark Operator에 대해 알아 보도록 하겠습니다.</p>\n<h3>Spark on Kubernetes를 사용하는 이유?</h3>\n<p>그렇다고, 이 글에서 아예 설명 하지 않고 넘어가는 것은 아닌 것 같아, <strong>Spark on Kubernetes</strong>를 사용하는 이유를 세 줄로 요약 하면 다음과 같습니다.</p>\n<ul>\n<li>Resource 관리: YARN과 같이 Container 단위로 Resource를 사용하는 것이 아닌, <strong>Kubernetes의 동적 리소스 할당</strong>을 이용하여 더 효율적으로 <strong>Computing Resource</strong>를 사용 합니다.</li>\n<li>YARN과 독립: <strong>Computing Resource를 YARN과 완전히 독립</strong>하여, 다른 작업을 수행 하지 않고, <strong>온전히 Spark Job의 Computing Resource로 사용</strong> 할 수 있습니다.</li>\n<li>Containerize: Hadoop 내 Spark 의존성에 대해서 신경 쓰지 않고, 독립적인 <strong>Spark 연산 환경</strong>을 구성할 수 있습니다.</li>\n</ul>\n<h3>Kubernetes Operator Pattern</h3>\n<p>먼저 Kubernetes에 존재하는 <strong>Operator Pattern</strong>에 대해서 알아 보도록하겠습니다. Kubernetes의 Operator 패턴은 Kubernetes 클러스터에서 사용자가 <strong>Custom Resource Definition(CRD)</strong> 를 이용 하여, Pod, Service, Deployment, ConfigMap 등의 <strong>여러 개의 Resource를 하나의 개념으로 묶어 배포 및 관리를 할 수 있게 하는 패턴</strong>입니다. 복잡한 어플리케이션을 하나의 Resource 개념으로 캡슐화 하고, 이를 관리 하는 Controller 구현체를 추가 작성하여, Upgrade, HA, Networking을 일괄적으로 관리 하는 형식으로 이용 할 수가 있는거죠.</p>\n<p align=\"center\">\n    <img src=\"/post_image/spark-operator/01.png\" width=\"600px\" />\n    <div align=\"center\" color=\"#aaaaaa\">AS-IS (기존 Kubernetes의 Resource를 사용)</div>\n</p>\n<p align=\"center\">\n    <img src=\"/post_image/spark-operator/02.png\" width=\"600px\" />\n    <div align=\"center\" color=\"#aaaaaa\">TO-BE (Kubernetes Operator Pattern을 사용)</div>\n</p>\n<p>아래는 <strong>SparkApplication을 제출하는 YAML 파일의 예시</strong> 입니다. 이렇게 간단한 코드로 Pod, Ingress 등 <strong>여러 Kubernetes Resource를 손쉽게 일괄 배포</strong> 할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> sparkoperator.k8s.io/v1beta2\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> SparkApplication\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> spark<span class=\"token punctuation\">-</span>pi\n  <span class=\"token key atrule\">namespace</span><span class=\"token punctuation\">:</span> default\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> Scala\n  <span class=\"token key atrule\">mode</span><span class=\"token punctuation\">:</span> cluster\n  <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> spark<span class=\"token punctuation\">:</span>3.5.1\n  <span class=\"token key atrule\">mainClass</span><span class=\"token punctuation\">:</span> org.apache.spark.examples.SparkPi\n  <span class=\"token key atrule\">mainApplicationFile</span><span class=\"token punctuation\">:</span> local<span class=\"token punctuation\">:</span>///opt/spark/examples/jars/spark<span class=\"token punctuation\">-</span>examples_2.12<span class=\"token punctuation\">-</span>3.5.1.jar</code></pre></div>\n<h3>Spark Operator</h3>\n<p>오늘 설명할 <strong>Spark Operator</strong>도 Kubernetes의 <strong>Operator Pattern</strong>으로 Spark Job을 쉽게 Kubernetes Cluster로 제출 할 수 있게 도와줍니다. 현재 Open Source로 지원 되고 있는 Spark Operator 같은 경우에는 크게 2개가 있습니다.</p>\n<ul>\n<li>Kubeflow Spark Operator: <a href=\"https://github.com/kubeflow/spark-operator\">https://github.com/kubeflow/spark-operator</a></li>\n<li>Apache Spark Kubernetes Operator: <a href=\"https://github.com/apache/spark-kubernetes-operator\">https://github.com/apache/spark-kubernetes-operator</a></li>\n</ul>\n<p>Spark Operator 관련 Star, PR 수가 압도적으로 Kubeflow Spark Operator가 더 높습니다. 커뮤니티가 더 활발하다는 이야기죠. 따라서 오늘은 Kubeflow Spark Operator로 설명을 진행 합니다.</p>\n<blockquote>\n<p>여담이지만, Apache Spark 4.0.0-preview가 README.md에 있는 것 보면, Apache Spark Maintainer 들이 Spark 4 버전을 목표로 이를 개발하고 있는 걸지도 모르겠군요.</p>\n</blockquote>\n<h3>Architecture</h3>\n<p><a href=\"https://www.kubeflow.org/docs/components/spark-operator/overview/\">공식 Doc</a>에 있는 내용을 통해 구조를 살펴보면 다음과 같습니다.</p>\n<ul>\n<li>설치 된 <code class=\"language-text\">SparkApplication Controller</code>를 이용하여 SparkApplication Resource를 관리 합니다.</li>\n<li>Controller에서 수신한 spark-submit을 실행하기 위해 <code class=\"language-text\">submisstion runner</code>를 사용합니다.</li>\n<li>Spark Pod 상태를 Monitoring 하는 <code class=\"language-text\">Spark Pod Monitor</code>를 사용 합니다.</li>\n<li>Pod의 Annotation을 바탕으로 Spark Driver와 Executor에 대한 Customization을 수행하는 <code class=\"language-text\">Mutating Admission Webhook</code>이 있습니다.</li>\n</ul>\n<p align=\"center\">\n    <img src=\"/post_image/spark-operator/03.png\" width=\"600px\" />\n    <div align=\"center\" color=\"#aaaaaa\">Kubeflow Kubernetes Operator Architecture</div>\n</p>\n<ol>\n<li>우선 <code class=\"language-text\">kubectl</code>을 이용하여, <code class=\"language-text\">SparkApplication</code> 객체를 생성 합니다.</li>\n<li>이를 SparkApplication Controller에 전송하여 spark-submit을 수행하는 Arguments 들을 작성하고, 이를 <code class=\"language-text\">submission runner</code>로 전송 합니다.</li>\n<li><code class=\"language-text\">submission runner</code>에서는 <code class=\"language-text\">spark-submit</code>을 수행 하며 Driver Pod을 생성 하고, Driver Pod에서는 Executor Pod을 생성 합니다.</li>\n<li><code class=\"language-text\">Spark Pod Monitor</code>는 여기서 생성된 Driver Pod과 Executor Pod을 모니터링 합니다.</li>\n</ol>\n<h3>The CRD Controller</h3>\n<p><strong>SparkApplication Controller</strong>는 Kubernetes 클러스터 내의 <strong>SparkApplication Object</strong>의 생성, 업데이트, 삭제 <strong>Event를 감시</strong>합니다.\n새로운 SparkApplication 객체가 추가되면, 이를 Queue에 삽입하여, <strong>Submission Runner</strong> 단에서 이를 <strong>K8S Cluster 내에 제출</strong>합니다.</p>\n<p>SparkApplication Object가 <strong>Update</strong>되면, Controller는 <strong>Application Spec이 변경</strong>되었을 시에는 Application을 중단 하고 <strong>새로운 Spec으로 다시 Application을 제출</strong> 합니다.</p>\n<p>Controller는 <strong>Spark Pod Monitor</strong>를 통해 <strong>SparkApplication Object의 상태를 관리</strong> 합니다. <strong>Spark Pod Monitor</strong>는 Spark Pod의 생성, 업데이트, 삭제 이벤트를 감시하고, 상태 업데이트 메시지를 Controller에 보냅니다.</p>\n<p>애플리케이션의 최종 상태는 <strong>Driver Pod의 종료 상태에 따라 결정</strong>됩니다. 드라이버 Pod가 완료되면 <code class=\"language-text\">COMPLETED</code>, 실패하면 <code class=\"language-text\">FAILED</code>로 설정됩니다. 제출이 실패하면 <code class=\"language-text\">FAILED_SUBMISSION</code>으로 설정됩니다.</p>\n<p>Controller는 새로운 <strong>SparkApplication Object</strong>를 준비하면서 <strong>Driver Pod</strong> 혹은 <strong>Executor Pod</strong>에 <strong>특정 Annotation을 추가</strong>합니다. 이 <strong>Annotation</strong>은 <strong>Mutating Admission Webhook</strong>에서 사용 되는데요, <strong>Mutating Admission Webhook</strong>에서 <strong>Annotation</strong>을 읽어 Pod이 실행되기 전 <strong>추가적으로 필요한 구성을 적용</strong>합니다. 예를 들어, 특정 ConfigMap을 Pod에 마운트해야 하는 경우, 해당 ConfigMap의 이름을 지정하는 Annotation을 추가합니다.</p>\n<p>이런 식으로 Spark Operator의 Component들은 SparkApplication Object들을 관리합니다.</p>\n<h3>Handling Application Restart And Failures</h3>\n<p>Spark Operator에서는 재시작 관련 정책이 존재 하는데요, Operator는 <strong>Driver Pod의 상태에 Application Status</strong>와 기반한 <strong>Restart Policy</strong>에 따라서, 어플리케이션 재수행 여부를 결정합니다.</p>\n<ul>\n<li><code class=\"language-text\">Never</code>: Task 성공 / 실패 여부와 관계 없이, 이를 실패 시킵니다.</li>\n<li><code class=\"language-text\">Always</code>: Task 성공 / 실패 여부와 관계 없이, 이를 무조건 재시작 시킵니다.</li>\n<li><code class=\"language-text\">OnFailure</code>: Task가 실패 하고, 설정 하였던 재시작 반복 횟수를 넘기지 않았다면, 이를 재시작 합니다.</li>\n</ul>\n<p>Operator 단에서 Application을 재시작 하게 되면, 이전에 종료된 Application과 관련된 <strong>Kubernetes Resource를 정리</strong>하고, 해당하는 <strong>SparkApplication Object를 Queue에 삽입</strong> 합니다.</p>\n<p>이렇게 Spark Operator 관련 Overview를 마쳤습니다. 다음 시간에는 <strong>Spark Operator를 설치</strong>하고, 간단한 <strong>SparkApplication을 제출</strong> 하는 글로 찾아뵙겠습니다.</p>","id":"9ec3e659-5978-5311-b4d5-fc9d0902e008","frontmatter":{"date":"2025-01-19","path":"/data-engineering/spark-operator-1","title":"Spark Operator - 1. Spark Operator란?","tags":["Data-Engineering"],"keyword":"Spark, Spark on K8S, Kubernetes, Spark Operator","summary":"Kubernetes Cluster로의 Spark Job 제출을 도와주는 Spark Operator가 무엇 인지 알아보자.","img":"/post_image/thumbnail/spark-operator.jpg","series":"Spark On Kubernetes"}}},"pageContext":{"postPath":"/data-engineering/spark-operator-1","series":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"24718dd5-aa23-578b-aa81-0ca11fcc0f06","excerpt":"안녕하세요, 박민재입니다. 저번 시간에는 Spark Operator가 무엇인지 간단하게 알아 보았는데요, 이번 시간에는 실제로 Spark Operator Helm Chart를 설치하여, Spark Operator 관련 구동 준비를 한 후, Spark Operator 관련 Resource를 작성 하여 실제 Job을 제출 해 보는 시간을 가져 보도록 하겠습니다. Spark Operator Helm Chart Spark Operator…","frontmatter":{"date":"2025-02-02","tags":["Data-Engineering"],"path":"/data-engineering/spark-operator-2","title":"Spark Operator - 2. Practice","img":"/post_image/thumbnail/spark-operator.jpg","summary":"Spark Operator를 사용 해 보자."}}},{"node":{"id":"9ec3e659-5978-5311-b4d5-fc9d0902e008","excerpt":"안녕하세요, 박민재입니다. 아마 2년 전 즈음에 Spark on Kubernetes 관련 내용을 다뤘었는데요 (이 글 또한, 개정판을 작성 해 볼게요), 이번에는 Spark Job을 Kubernetes Cluster에 편리하게 제출할 수 있게 하는 Spark Operator에 대해 알아 보도록 하겠습니다. Spark on Kubernetes를 사용하는 이유? 그렇다고, 이 글에서 아예 설명 하지 않고 넘어가는 것은 아닌 것 같아, Spark…","frontmatter":{"date":"2025-01-19","tags":["Data-Engineering"],"path":"/data-engineering/spark-operator-1","title":"Spark Operator - 1. Spark Operator란?","img":"/post_image/thumbnail/spark-operator.jpg","summary":"Kubernetes Cluster로의 Spark Job 제출을 도와주는 Spark Operator가 무엇 인지 알아보자."}}},{"node":{"id":"28baf728-0bd2-5147-9ef0-b05da0826d77","excerpt":"저번 시간에는 Spark On Kubernetes에 대한 이론을 배웠습니다. 오늘은 Spark On Kubernetes에 대한 실습을 진행 하도록 하겠습니다. 사전 준비 Docker Minikube (Kubernetes 1.20 버전 이상) kubectl Spark 3.0 버전 이상 최신 버전일 수록 좋습니다. 얼마 전에 구형 Docker가 깔려 있는 맥북에서 진행을 해 봤는데 Pod이 생성이 안되더군요.. Pyspark Image Build…","frontmatter":{"date":"2023-03-30","tags":["Data-Engineering","Cloud-Computing"],"path":"/data-engineering/spark-on-k8s-2","title":"Spark on Kubernetes - Practice","img":"/post_image/thumbnail/spark-on-k8s-2.png","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자."}}},{"node":{"id":"159ef5da-bcc6-5cdb-bb70-0d8a76f3cb69","excerpt":"Spark Apache Spark는 기존 Hadoop의 MapReduce 형태의 클러스터 컴퓨팅의 단점을 보완하기 위해 탄생한 프레임워크 입니다. 기존 하둡의 MapReduce에서는 Disk에서 데이터를 읽은 후, Mapping, Shuffling, Reducing의 과정을 거쳐서, 다시 Disk에 저장하는 형식으로 진행 되는데요, 이는 Disk I/O가 자주 발생 하기 때문에, 속도가 상대적으로 느리다는 단점이 있습니다. 하지만 Apache…","frontmatter":{"date":"2023-03-06","tags":["Data-Engineering","Cloud-Computing"],"path":"/data-engineering/spark-on-k8s-1","title":"Spark on Kubernetes - Concept","img":"/post_image/thumbnail/spark-on-k8s-1.jpeg","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자."}}}]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"ac2612fc-bbdf-504f-94d9-d2bab40e68e6","excerpt":"안녕하세요? 박민재입니다. 오늘날의 Data Engineer…","frontmatter":{"date":"2025-03-26","tags":["Data-Engineering"],"path":"/data-engineering/dbt-intro","title":"dbt란 무엇인가?","img":"/post_image/thumbnail/dbt-intro.webp","summary":"SQL을 바탕으로 Data Transformation Pipeline을 구성해 주는 dbt를 알아보자."}}},{"node":{"id":"dec9e599-9444-556f-99ba-7a1dc27a4dbb","excerpt":"안녕하세요, 박민재입니다. 혹시 Data Discovery에 중요성을 느껴, DataHub를 사용하려고 하시는 분이 있나요? 아마 그렇다면 DataHub를 도입한 사례를 몇 개 읽어 보셨을꺼라 생각합니다. 대표적으로 국내 기업에서는 뱅크샐러드, 소카, 베이글코드 등에서 성공적으로 도입한 사례들을 회사 사이트에 올리는 경우를 확인 할 수 있었어요. SOCAR BankSalad BagelCode DataHub…","frontmatter":{"date":"2025-03-02","tags":["Data-Engineering"],"path":"/data-engineering/to-datahub-user","title":"DataHub 도입을 고려 하시는 분들에게","img":"/post_image/thumbnail/to-datahub-user.webp","summary":"DataHub를 도입 하려고 할 때 알아야 할 점"}}},{"node":{"id":"24718dd5-aa23-578b-aa81-0ca11fcc0f06","excerpt":"안녕하세요, 박민재입니다. 저번 시간에는 Spark Operator가 무엇인지 간단하게 알아 보았는데요, 이번 시간에는 실제로 Spark Operator Helm Chart를 설치하여, Spark Operator 관련 구동 준비를 한 후, Spark Operator 관련 Resource를 작성 하여 실제 Job을 제출 해 보는 시간을 가져 보도록 하겠습니다. Spark Operator Helm Chart Spark Operator…","frontmatter":{"date":"2025-02-02","tags":["Data-Engineering"],"path":"/data-engineering/spark-operator-2","title":"Spark Operator - 2. Practice","img":"/post_image/thumbnail/spark-operator.jpg","summary":"Spark Operator를 사용 해 보자."}}},{"node":{"id":"9ec3e659-5978-5311-b4d5-fc9d0902e008","excerpt":"안녕하세요, 박민재입니다. 아마 2년 전 즈음에 Spark on Kubernetes 관련 내용을 다뤘었는데요 (이 글 또한, 개정판을 작성 해 볼게요), 이번에는 Spark Job을 Kubernetes Cluster에 편리하게 제출할 수 있게 하는 Spark Operator에 대해 알아 보도록 하겠습니다. Spark on Kubernetes를 사용하는 이유? 그렇다고, 이 글에서 아예 설명 하지 않고 넘어가는 것은 아닌 것 같아, Spark…","frontmatter":{"date":"2025-01-19","tags":["Data-Engineering"],"path":"/data-engineering/spark-operator-1","title":"Spark Operator - 1. Spark Operator란?","img":"/post_image/thumbnail/spark-operator.jpg","summary":"Kubernetes Cluster로의 Spark Job 제출을 도와주는 Spark Operator가 무엇 인지 알아보자."}}}]}}}}},"staticQueryHashes":["3819017183","63159454"],"slicesMap":{}}