{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-engineering/spark-on-k8s-2/","result":{"data":{"markdownRemark":{"html":"<p><a href=\"https://justkode.kr/data-engineering/spark-on-k8s-1\">저번 시간</a>에는 <strong>Spark On Kubernetes</strong>에 대한 이론을 배웠습니다. 오늘은 <strong>Spark On Kubernetes</strong>에 대한 실습을 진행 하도록 하겠습니다.</p>\n<h2>사전 준비</h2>\n<ul>\n<li>Docker</li>\n<li>Minikube (Kubernetes 1.20 버전 이상)</li>\n<li>kubectl</li>\n<li>Spark 3.0 버전 이상</li>\n</ul>\n<p>최신 버전일 수록 좋습니다. 얼마 전에 구형 <strong>Docker</strong>가 깔려 있는 맥북에서 진행을 해 봤는데 <strong>Pod</strong>이 생성이 안되더군요..</p>\n<h2>Pyspark Image Build &#x26; Push</h2>\n<p><strong>Kubernetes</strong> 에서 <strong>Spark Application</strong>을 수행 하기 전에, <strong>Spark Docker Image</strong>의 빌드가 선행 되어야 합니다. 일단. <code class=\"language-text\">$SPARK_DIR</code> (Spark가 설치된 경로) 안에, <code class=\"language-text\">./bin/docker-image-tool.sh</code>를 이용 하여, <strong>Spark Base Image</strong>를 <strong>Build</strong> 할 수 있습니다.</p>\n<p>해당 셸 스크립트의 <code class=\"language-text\">build</code> 관련 한 파라미터는 다음과 같습니다.</p>\n<ul>\n<li><code class=\"language-text\">-f file</code>: (Optional) <strong>JVM 기반 Image 빌드를 위한 Dockerfile</strong> 을 입력 합니다. 기본적으로 <strong>Spark와 함께 제공되는 Dockerfile을 빌드</strong>합니다. Java 17의 경우 <code class=\"language-text\">-f kubernetes/dockerfiles/spark/Dockerfile.java17</code>을 사용합니다.</li>\n<li><code class=\"language-text\">-p file</code>: (Optional) <strong>PySpark Image 빌드를 위한 Dockerfile</strong>을 입력 합니다. <strong>Python 종속성을 빌드하고 Spark와 함께 제공</strong>됩니다. 지정하지 않으면 PySpark 도커 이미지 빌드를 건너뜁니다.</li>\n<li><code class=\"language-text\">-R file</code>: (Optional) <strong>SparkR Image 빌드를 위한 Dockerfile</strong>을 입력 합니다. <strong>R 종속성을 빌드하고 Spark와 함께 제공</strong> 됩니다. 지정하지 않으면 SparkR 도커 이미지 빌드를 건너뜁니다.</li>\n<li><code class=\"language-text\">-r repo</code>: <strong>레포지토리 주소</strong>를 입력 합니다.</li>\n<li><code class=\"language-text\">t tag</code>: 빌드 된 이미지의 <strong>Tag</strong>를 입력 합니다,</li>\n</ul>\n<p>일단 <strong>Spark Base Image</strong>를 빌드 해 보겠습니다. <strong>Kubernetes</strong> 에서 <strong>Spark Job</strong>을 구동 시키기 위해 <strong>기본적으로 만들어져 제공 된 Dockerfile</strong>을 사용 합니다. (<code class=\"language-text\">./kubernetes/dockerfiles/spark/bindings/python/Dockerfile</code>, SparkR은 <code class=\"language-text\">./kubernetes/dockerfiles/spark/bindings/R/Dockerfile</code> 입니다.)</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">cd</span> <span class=\"token variable\">$SPARK_DIR</span>  <span class=\"token comment\"># spark directory</span>\n$ <span class=\"token builtin class-name\">eval</span> <span class=\"token variable\"><span class=\"token variable\">$(</span>minikube docker-env<span class=\"token variable\">)</span></span>  <span class=\"token comment\"># minikube docker image storage에 접근 하기 위함.</span>\n$ ./bin/docker-image-tool.sh <span class=\"token parameter variable\">-r</span> k8s <span class=\"token parameter variable\">-t</span> <span class=\"token number\">1.0</span> <span class=\"token parameter variable\">-p</span> ./kubernetes/dockerfiles/spark/bindings/python/Dockerfile build</code></pre></div>\n<p>일단, 폴더를 하나 생성 한 후, 다음과 같이 파일을 생성하여 코드를 입력 해 줍니다.</p>\n<ul>\n<li><code class=\"language-text\">&lt;this repository path>/python/Dockerfile</code></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"dockerfile\"><pre class=\"language-dockerfile\"><code class=\"language-dockerfile\"><span class=\"token instruction\"><span class=\"token keyword\">FROM</span> k8s/spark-py:1.0</span>\n\n<span class=\"token instruction\"><span class=\"token keyword\">COPY</span> ./script /python</span></code></pre></div>\n<ul>\n<li><code class=\"language-text\">&lt;this repository path>/python/script/rdd_example.py</code></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> pyspark <span class=\"token keyword\">import</span> SparkContext<span class=\"token punctuation\">,</span> SparkConf\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    conf <span class=\"token operator\">=</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"calculate_pyspark_example\"</span><span class=\"token punctuation\">)</span>\n    sc <span class=\"token operator\">=</span> SparkContext<span class=\"token punctuation\">(</span>conf<span class=\"token operator\">=</span>conf<span class=\"token punctuation\">)</span>\n\n    data <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>i <span class=\"token operator\">+</span> <span class=\"token number\">1</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">10000000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n    distData <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>parallelize<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"sum :\"</span><span class=\"token punctuation\">,</span> distData<span class=\"token punctuation\">.</span><span class=\"token builtin\">reduce</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">:</span> a <span class=\"token operator\">+</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>그 다음, 방금 만들어진 <strong>Base Image</strong>를 이용 하여, <strong>Application image</strong>를 빌드 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">cd</span> <span class=\"token operator\">&lt;</span>this repository path<span class=\"token operator\">></span>/python\n$ <span class=\"token builtin class-name\">eval</span> <span class=\"token variable\"><span class=\"token variable\">$(</span>minikube docker-env<span class=\"token variable\">)</span></span>\n$ <span class=\"token function\">docker</span> build <span class=\"token parameter variable\">-t</span> pyspark-on-k8s:1.0 <span class=\"token builtin class-name\">.</span>\n$ minikube image load pyspark-on-k8s:1.0</code></pre></div>\n<p>그 이후에 빌드된 모든 이미지를 확인 하기 위해, <code class=\"language-text\">docker image ls</code>를 입력 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">docker</span> image <span class=\"token function\">ls</span>\nREPOSITORY                           TAG       IMAGE ID       CREATED         SIZE\npyspark-on-k8s                       <span class=\"token number\">1.0</span>       00a4af077a09   About a minute ago   938MB\nk8s/spark-py                         <span class=\"token number\">1.0</span>       985cf805549a   <span class=\"token number\">13</span> days ago     938MB\nk8s/spark                            <span class=\"token number\">1.0</span>       bd8ba88688d4   <span class=\"token number\">13</span> days ago     601MB\n<span class=\"token punctuation\">..</span>.</code></pre></div>\n<h2>How To Run Spark Application</h2>\n<p><strong>Kubernetes</strong>에서 <strong>Spark Application</strong>을 실행 하기 전에, <strong>k8s service account, k8s clusterrolebinding</strong>를 생성 하여야 합니다. 왜냐 하면 <strong>Spark on K8S</strong>가 <strong>Driver Pod</strong>에서 <strong>Executor Pod</strong>의 상태를 관리 하는 형식이기 때문에, <strong>Driver Pod</strong>이 <strong>Pod edit 권한</strong>이 있는 <strong>service account</strong>를 가지고 있어야 합니다.</p>\n<p align=\"center\">\n    <img src=\"/post_image/spark-on-k8s/1-4.png\" max-width=\"400px\" />\n    <div align=\"center\" color=\"#aaaaaa\">Spark on K8S</div>\n</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ kubectl create serviceaccount spark\n$ kubectl create clusterrolebinding spark-role <span class=\"token parameter variable\">--clusterrole</span><span class=\"token operator\">=</span>edit <span class=\"token parameter variable\">--serviceaccount</span><span class=\"token operator\">=</span>default:spark <span class=\"token parameter variable\">--namespace</span><span class=\"token operator\">=</span>default</code></pre></div>\n<p><strong>Spark Submit</strong>을 통해, <strong>Spark Job을 K8S에서 구동</strong> 할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ kubectl proxy\nStarting to serve on <span class=\"token number\">127.0</span>.0.1:8001\n\n<span class=\"token comment\"># In another terminal</span>\n$ kubectl create namespace spark-job\n\n<span class=\"token comment\"># rdd_example</span>\n$ ./bin/spark-submit <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--master</span> k8s://http://127.0.0.1:8001 <span class=\"token punctuation\">\\</span>\n    --deploy-mode cluster <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--name</span> rdd-example <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--class</span> org.apache.spark.examples.SparkPi <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.container.image</span><span class=\"token operator\">=</span>pyspark-on-k8s:1.0 <span class=\"token punctuation\">\\</span>  <span class=\"token comment\"># Pyspark Image 지정 </span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.driver.pod.name</span><span class=\"token operator\">=</span>rdd-example-pod <span class=\"token punctuation\">\\</span>  <span class=\"token comment\"># Driver Pod 이름 지정</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.authenticate.driver.serviceAccountName</span><span class=\"token operator\">=</span>spark <span class=\"token punctuation\">\\</span>  <span class=\"token comment\"># Service account 지정</span>\n    <span class=\"token parameter variable\">--verbose</span> <span class=\"token punctuation\">\\</span>\n    <span class=\"token string\">\"local:///python/rdd_example.py\"</span>  <span class=\"token comment\"># Docker file 기준의 Local 입니다.</span>\n\n$ kubectl logs rdd-example-pod  <span class=\"token comment\"># log check</span>\n\n<span class=\"token comment\"># dataframe_example</span>\n$ ./bin/spark-submit <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--master</span> k8s://http://127.0.0.1:8001 <span class=\"token punctuation\">\\</span>\n    --deploy-mode cluster <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--name</span> dataframe-example <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--class</span> org.apache.spark.examples.SparkPi <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.container.image</span><span class=\"token operator\">=</span>pyspark-on-k8s:1.0 <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.driver.pod.name</span><span class=\"token operator\">=</span>dataframe-example-pod <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.authenticate.driver.serviceAccountName</span><span class=\"token operator\">=</span>spark <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--verbose</span> <span class=\"token punctuation\">\\</span>\n    <span class=\"token string\">\"local:///python/dataframe_example.py\"</span>\n\n$ kubectl logs dataframe-example-pod  <span class=\"token comment\"># log check</span></code></pre></div>\n<p>기타 자잘한 옵션들은 <a href=\"https://spark.apache.org/docs/3.3.2/running-on-kubernetes.html#spark-properties\">공식 문서</a>에서 확인 할 수 있습니다.</p>\n<h2>client mode?</h2>\n<p><code class=\"language-text\">--deploy-mode client</code> 옵션을 지정하여, <strong>Driver</strong>는 Spark Submit을 수행 하는 <strong>로컬</strong>에서, <strong>Executor</strong>는 <strong>Cluster</strong> 내에서 작동하게 할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ ./bin/spark-submit <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--master</span> k8s://http://127.0.0.1:8001 <span class=\"token punctuation\">\\</span>\n    --deploy-mode client <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--name</span> dataframe-example <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--class</span> org.apache.spark.examples.SparkPi <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.container.image</span><span class=\"token operator\">=</span>pyspark-on-k8s:1.0 <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.driver.pod.name</span><span class=\"token operator\">=</span>dataframe-example-pod <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.authenticate.driver.serviceAccountName</span><span class=\"token operator\">=</span>spark <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--verbose</span> <span class=\"token punctuation\">\\</span>\n    <span class=\"token string\">\"local://&lt;this repository path>/python/script/rdd_example.py\"</span>  <span class=\"token comment\"># Spark-submit에 있는 로컬에서 구동</span></code></pre></div>\n<p align=\"center\">\n    <img src=\"/post_image/spark-on-k8s/2-1.png\" max-width=\"400px\" />\n    <div align=\"center\" color=\"#aaaaaa\">Spark on K8S Client Mode</div>\n</p>","id":"28baf728-0bd2-5147-9ef0-b05da0826d77","frontmatter":{"date":"2023-03-30","path":"/data-engineering/spark-on-k8s-2","title":"Spark on Kubernetes - Practice","tags":["Data-Engineering","Cloud-Computing"],"keyword":"Spark, Kubernetes","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자.","img":"/post_image/thumbnail/spark-on-k8s-2.png","series":"Spark On Kubernetes"}}},"pageContext":{"postPath":"/data-engineering/spark-on-k8s-2","series":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"28baf728-0bd2-5147-9ef0-b05da0826d77","excerpt":"저번 시간에는 Spark On Kubernetes에 대한 이론을 배웠습니다. 오늘은 Spark On Kubernetes에 대한 실습을 진행 하도록 하겠습니다. 사전 준비 Docker Minikube (Kubernetes 1.20 버전 이상) kubectl Spark 3.0 버전 이상 최신 버전일 수록 좋습니다. 얼마 전에 구형 Docker가 깔려 있는 맥북에서 진행을 해 봤는데 Pod이 생성이 안되더군요.. Pyspark Image Build…","frontmatter":{"date":"2023-03-30","tags":["Data-Engineering","Cloud-Computing"],"path":"/data-engineering/spark-on-k8s-2","title":"Spark on Kubernetes - Practice","img":"/post_image/thumbnail/spark-on-k8s-2.png","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자."}}},{"node":{"id":"159ef5da-bcc6-5cdb-bb70-0d8a76f3cb69","excerpt":"Spark Apache Spark는 기존 Hadoop의 MapReduce 형태의 클러스터 컴퓨팅의 단점을 보완하기 위해 탄생한 프레임워크 입니다. 기존 하둡의 MapReduce에서는 Disk에서 데이터를 읽은 후, Mapping, Shuffling, Reducing의 과정을 거쳐서, 다시 Disk에 저장하는 형식으로 진행 되는데요, 이는 Disk I/O가 자주 발생 하기 때문에, 속도가 상대적으로 느리다는 단점이 있습니다. 하지만 Apache…","frontmatter":{"date":"2023-03-06","tags":["Data-Engineering","Cloud-Computing"],"path":"/data-engineering/spark-on-k8s-1","title":"Spark on Kubernetes - Concept","img":"/post_image/thumbnail/spark-on-k8s-1.jpeg","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자."}}}]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"3c44d6b1-b341-5256-bb40-e6a58835b474","excerpt":"Intro 안녕하세요, 박민재입니다. 오늘은 Apache Iceberg의 Table에 수행 되는 쿼리가 최적의 성능으로 작동 될 수 있도록, File Compaction을 통해 이를 수행하는 방법에 대해 이야기 하는 시간을 가져 보도록 하겠습니다. File Compaction 우리가 쿼리를 수행 시, Hive Metastore의 정보를 이용하더라도, 혹은 Iceberg의 Metadata…","frontmatter":{"date":"2024-11-10","tags":["Data-Engineering"],"path":"/data-engineering/iceberg-table-optimization-1","title":"Iceberg Table의 성능 최적화 - 1. 압축","img":"/post_image/thumbnail/iceberg-table-optimization-1.webp","summary":"File Merge를 통한 성능 최적화에 대해 알아보자."}}},{"node":{"id":"6eaa7aeb-a4fe-5cd9-bbe5-309dde97514b","excerpt":"안녕하세요, 박민재입니다. 오늘은 Airflow DB를 관리하는 방법에 대해서 이야기 나눠 보도록 하겠습니다. Airflow Backend Database Airflow에서 Backend Database는 어떤 역할을 할까요? Airflow에서 DAG을 실행 하기 위해서, Airflow는 다음과 같은 정보들을 Backend Database에 저장하여 정합성을 유지 합니다. DagRun: 특정 Interval에 실행 된 DagRun…","frontmatter":{"date":"2024-10-27","tags":["Data-Engineering"],"path":"/data-engineering/airflow-db-management","title":"Airflow Backend Database Management (airflow db clean)","img":"/post_image/thumbnail/airflow-db-management.webp","summary":"Airflow의 Backend Database를 관리 하는 법"}}},{"node":{"id":"b595b168-8160-5abf-9641-39746d2f9e82","excerpt":"안녕하세요, 박민재입니다. 오늘은 Spark Application내의 각 Executor 내의 Task에 제한적으로 변수를 공유하는 두 가지 방법에 대해서 알아 보도록 하겠습니다. 시작하기에 앞서 단편적으로 생각 해 보면, Spark Application에서 연산 과정의 변수를 공유 한다는 것은 어려운 일인가? 라는 질문을 던져 볼 수 있습니다. 우리는 Task…","frontmatter":{"date":"2024-10-11","tags":["Data-Engineering"],"path":"/data-engineering/spark-sharing-variables","title":"Sharing Variables in Spark - Broadcast, Accumulator","img":"/post_image/thumbnail/spark-sharing-variables.png","summary":"Spark Application에서 변수를 공유 하는 방법"}}},{"node":{"id":"5effd6a1-bfd8-5a86-b718-5eb1e534601e","excerpt":"Intro 안녕하세요, 박민재입니다. 오늘은 Spark Memory에 관해 Deep Dive를 해 보도록 하겠습니다. Spark는 In-Memory를 이용하여, 빠른 연산을 할 수 있도록 보장합니다. 하지만, In-Memory 연산은 빠른 대신, 비싼 관계로 적은 리소스 만을 활용할 수 있습니다. 그렇기 때문에 우리는 효율적으로 Memory를 관리 하여, Spark Application이 빠르고, 안정적으로 Task…","frontmatter":{"date":"2024-04-12","tags":["Data-Engineering"],"path":"/data-engineering/spark-memory-deep-dive","title":"Deep Dive of Spark Memory","img":"/post_image/thumbnail/spark-memory-deep-dive.jpeg","summary":"Spark Memory의 깊은 이해를 위해 Deep Dive를 해 보자."}}}]}}}}},"staticQueryHashes":["3819017183","63159454"],"slicesMap":{}}