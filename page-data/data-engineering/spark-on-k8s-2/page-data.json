{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-engineering/spark-on-k8s-2/","result":{"data":{"markdownRemark":{"html":"<p><a href=\"https://justkode.kr/data-engineering/spark-on-k8s-1\">저번 시간</a>에는 <strong>Spark On Kubernetes</strong>에 대한 이론을 배웠습니다. 오늘은 <strong>Spark On Kubernetes</strong>에 대한 실습을 진행 하도록 하겠습니다.</p>\n<h2>사전 준비</h2>\n<ul>\n<li>Docker</li>\n<li>Minikube (Kubernetes 1.20 버전 이상)</li>\n<li>kubectl</li>\n<li>Spark 3.0 버전 이상</li>\n</ul>\n<p>최신 버전일 수록 좋습니다. 얼마 전에 구형 <strong>Docker</strong>가 깔려 있는 맥북에서 진행을 해 봤는데 <strong>Pod</strong>이 생성이 안되더군요..</p>\n<h2>Pyspark Image Build &#x26; Push</h2>\n<p><strong>Kubernetes</strong> 에서 <strong>Spark Application</strong>을 수행 하기 전에, <strong>Spark Docker Image</strong>의 빌드가 선행 되어야 합니다. 일단. <code class=\"language-text\">$SPARK_DIR</code> (Spark가 설치된 경로) 안에, <code class=\"language-text\">./bin/docker-image-tool.sh</code>를 이용 하여, <strong>Spark Base Image</strong>를 <strong>Build</strong> 할 수 있습니다.</p>\n<p>해당 셸 스크립트의 <code class=\"language-text\">build</code> 관련 한 파라미터는 다음과 같습니다.</p>\n<ul>\n<li><code class=\"language-text\">-f file</code>: (Optional) <strong>JVM 기반 Image 빌드를 위한 Dockerfile</strong> 을 입력 합니다. 기본적으로 <strong>Spark와 함께 제공되는 Dockerfile을 빌드</strong>합니다. Java 17의 경우 <code class=\"language-text\">-f kubernetes/dockerfiles/spark/Dockerfile.java17</code>을 사용합니다.</li>\n<li><code class=\"language-text\">-p file</code>: (Optional) <strong>PySpark Image 빌드를 위한 Dockerfile</strong>을 입력 합니다. <strong>Python 종속성을 빌드하고 Spark와 함께 제공</strong>됩니다. 지정하지 않으면 PySpark 도커 이미지 빌드를 건너뜁니다.</li>\n<li><code class=\"language-text\">-R file</code>: (Optional) <strong>SparkR Image 빌드를 위한 Dockerfile</strong>을 입력 합니다. <strong>R 종속성을 빌드하고 Spark와 함께 제공</strong> 됩니다. 지정하지 않으면 SparkR 도커 이미지 빌드를 건너뜁니다.</li>\n<li><code class=\"language-text\">-r repo</code>: <strong>레포지토리 주소</strong>를 입력 합니다.</li>\n<li><code class=\"language-text\">t tag</code>: 빌드 된 이미지의 <strong>Tag</strong>를 입력 합니다,</li>\n</ul>\n<p>일단 <strong>Spark Base Image</strong>를 빌드 해 보겠습니다. <strong>Kubernetes</strong> 에서 <strong>Spark Job</strong>을 구동 시키기 위해 <strong>기본적으로 만들어져 제공 된 Dockerfile</strong>을 사용 합니다. (<code class=\"language-text\">./kubernetes/dockerfiles/spark/bindings/python/Dockerfile</code>, SparkR은 <code class=\"language-text\">./kubernetes/dockerfiles/spark/bindings/R/Dockerfile</code> 입니다.)</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">cd</span> <span class=\"token variable\">$SPARK_DIR</span>  <span class=\"token comment\"># spark directory</span>\n$ <span class=\"token builtin class-name\">eval</span> <span class=\"token variable\"><span class=\"token variable\">$(</span>minikube docker-env<span class=\"token variable\">)</span></span>  <span class=\"token comment\"># minikube docker image storage에 접근 하기 위함.</span>\n$ ./bin/docker-image-tool.sh <span class=\"token parameter variable\">-r</span> k8s <span class=\"token parameter variable\">-t</span> <span class=\"token number\">1.0</span> <span class=\"token parameter variable\">-p</span> ./kubernetes/dockerfiles/spark/bindings/python/Dockerfile build</code></pre></div>\n<p>일단, 폴더를 하나 생성 한 후, 다음과 같이 파일을 생성하여 코드를 입력 해 줍니다.</p>\n<ul>\n<li><code class=\"language-text\">&lt;this repository path>/python/Dockerfile</code></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"dockerfile\"><pre class=\"language-dockerfile\"><code class=\"language-dockerfile\"><span class=\"token instruction\"><span class=\"token keyword\">FROM</span> k8s/spark-py:1.0</span>\n\n<span class=\"token instruction\"><span class=\"token keyword\">COPY</span> ./script /python</span></code></pre></div>\n<ul>\n<li><code class=\"language-text\">&lt;this repository path>/python/script/rdd_example.py</code></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> pyspark <span class=\"token keyword\">import</span> SparkContext<span class=\"token punctuation\">,</span> SparkConf\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    conf <span class=\"token operator\">=</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"calculate_pyspark_example\"</span><span class=\"token punctuation\">)</span>\n    sc <span class=\"token operator\">=</span> SparkContext<span class=\"token punctuation\">(</span>conf<span class=\"token operator\">=</span>conf<span class=\"token punctuation\">)</span>\n\n    data <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>i <span class=\"token operator\">+</span> <span class=\"token number\">1</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">10000000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n    distData <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>parallelize<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"sum :\"</span><span class=\"token punctuation\">,</span> distData<span class=\"token punctuation\">.</span><span class=\"token builtin\">reduce</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">:</span> a <span class=\"token operator\">+</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>그 다음, 방금 만들어진 <strong>Base Image</strong>를 이용 하여, <strong>Application image</strong>를 빌드 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">cd</span> <span class=\"token operator\">&lt;</span>this repository path<span class=\"token operator\">></span>/python\n$ <span class=\"token builtin class-name\">eval</span> <span class=\"token variable\"><span class=\"token variable\">$(</span>minikube docker-env<span class=\"token variable\">)</span></span>\n$ <span class=\"token function\">docker</span> build <span class=\"token parameter variable\">-t</span> pyspark-on-k8s:1.0 <span class=\"token builtin class-name\">.</span>\n$ minikube image load pyspark-on-k8s:1.0</code></pre></div>\n<p>그 이후에 빌드된 모든 이미지를 확인 하기 위해, <code class=\"language-text\">docker image ls</code>를 입력 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">docker</span> image <span class=\"token function\">ls</span>\nREPOSITORY                           TAG       IMAGE ID       CREATED         SIZE\npyspark-on-k8s                       <span class=\"token number\">1.0</span>       00a4af077a09   About a minute ago   938MB\nk8s/spark-py                         <span class=\"token number\">1.0</span>       985cf805549a   <span class=\"token number\">13</span> days ago     938MB\nk8s/spark                            <span class=\"token number\">1.0</span>       bd8ba88688d4   <span class=\"token number\">13</span> days ago     601MB\n<span class=\"token punctuation\">..</span>.</code></pre></div>\n<h2>How To Run Spark Application</h2>\n<p><strong>Kubernetes</strong>에서 <strong>Spark Application</strong>을 실행 하기 전에, <strong>k8s service account, k8s clusterrolebinding</strong>를 생성 하여야 합니다. 왜냐 하면 <strong>Spark on K8S</strong>가 <strong>Driver Pod</strong>에서 <strong>Executor Pod</strong>의 상태를 관리 하는 형식이기 때문에, <strong>Driver Pod</strong>이 <strong>Pod edit 권한</strong>이 있는 <strong>service account</strong>를 가지고 있어야 합니다.</p>\n<p align=\"center\">\n    <img src=\"/post_image/spark-on-k8s/1-4.png\" max-width=\"400px\" />\n    <div align=\"center\" color=\"#aaaaaa\">Spark on K8S</div>\n</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ kubectl create serviceaccount spark\n$ kubectl create clusterrolebinding spark-role <span class=\"token parameter variable\">--clusterrole</span><span class=\"token operator\">=</span>edit <span class=\"token parameter variable\">--serviceaccount</span><span class=\"token operator\">=</span>default:spark <span class=\"token parameter variable\">--namespace</span><span class=\"token operator\">=</span>default</code></pre></div>\n<p><strong>Spark Submit</strong>을 통해, <strong>Spark Job을 K8S에서 구동</strong> 할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ kubectl proxy\nStarting to serve on <span class=\"token number\">127.0</span>.0.1:8001\n\n<span class=\"token comment\"># In another terminal</span>\n$ kubectl create namespace spark-job\n\n<span class=\"token comment\"># rdd_example</span>\n$ ./bin/spark-submit <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--master</span> k8s://http://127.0.0.1:8001 <span class=\"token punctuation\">\\</span>\n    --deploy-mode cluster <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--name</span> rdd-example <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--class</span> org.apache.spark.examples.SparkPi <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.container.image</span><span class=\"token operator\">=</span>pyspark-on-k8s:1.0 <span class=\"token punctuation\">\\</span>  <span class=\"token comment\"># Pyspark Image 지정 </span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.driver.pod.name</span><span class=\"token operator\">=</span>rdd-example-pod <span class=\"token punctuation\">\\</span>  <span class=\"token comment\"># Driver Pod 이름 지정</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.authenticate.driver.serviceAccountName</span><span class=\"token operator\">=</span>spark <span class=\"token punctuation\">\\</span>  <span class=\"token comment\"># Service account 지정</span>\n    <span class=\"token parameter variable\">--verbose</span> <span class=\"token punctuation\">\\</span>\n    <span class=\"token string\">\"local:///python/rdd_example.py\"</span>  <span class=\"token comment\"># Docker file 기준의 Local 입니다.</span>\n\n$ kubectl logs rdd-example-pod  <span class=\"token comment\"># log check</span>\n\n<span class=\"token comment\"># dataframe_example</span>\n$ ./bin/spark-submit <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--master</span> k8s://http://127.0.0.1:8001 <span class=\"token punctuation\">\\</span>\n    --deploy-mode cluster <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--name</span> dataframe-example <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--class</span> org.apache.spark.examples.SparkPi <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.container.image</span><span class=\"token operator\">=</span>pyspark-on-k8s:1.0 <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.driver.pod.name</span><span class=\"token operator\">=</span>dataframe-example-pod <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.authenticate.driver.serviceAccountName</span><span class=\"token operator\">=</span>spark <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--verbose</span> <span class=\"token punctuation\">\\</span>\n    <span class=\"token string\">\"local:///python/dataframe_example.py\"</span>\n\n$ kubectl logs dataframe-example-pod  <span class=\"token comment\"># log check</span></code></pre></div>\n<p>기타 자잘한 옵션들은 <a href=\"https://spark.apache.org/docs/3.3.2/running-on-kubernetes.html#spark-properties\">공식 문서</a>에서 확인 할 수 있습니다.</p>\n<h2>client mode?</h2>\n<p><code class=\"language-text\">--deploy-mode client</code> 옵션을 지정하여, <strong>Driver</strong>는 Spark Submit을 수행 하는 <strong>로컬</strong>에서, <strong>Executor</strong>는 <strong>Cluster</strong> 내에서 작동하게 할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ ./bin/spark-submit <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--master</span> k8s://http://127.0.0.1:8001 <span class=\"token punctuation\">\\</span>\n    --deploy-mode client <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--name</span> dataframe-example <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--class</span> org.apache.spark.examples.SparkPi <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.container.image</span><span class=\"token operator\">=</span>pyspark-on-k8s:1.0 <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.driver.pod.name</span><span class=\"token operator\">=</span>dataframe-example-pod <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.authenticate.driver.serviceAccountName</span><span class=\"token operator\">=</span>spark <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--verbose</span> <span class=\"token punctuation\">\\</span>\n    <span class=\"token string\">\"local://&lt;this repository path>/python/script/rdd_example.py\"</span>  <span class=\"token comment\"># Spark-submit에 있는 로컬에서 구동</span></code></pre></div>\n<p align=\"center\">\n    <img src=\"/post_image/spark-on-k8s/2-1.png\" max-width=\"400px\" />\n    <div align=\"center\" color=\"#aaaaaa\">Spark on K8S Client Mode</div>\n</p>","id":"7611f6af-dc48-595b-8866-23beee4d5cda","frontmatter":{"date":"2023-03-30","path":"/data-engineering/spark-on-k8s-2","title":"Spark on Kubernetes - Practice","tags":["Data-Engineering","Cloud-Computing"],"keyword":"Spark, Kubernetes","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자.","img":"/post_image/thumbnail/spark-on-k8s-2.png","series":"Spark On Kubernetes"}}},"pageContext":{"postPath":"/data-engineering/spark-on-k8s-2","series":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"7611f6af-dc48-595b-8866-23beee4d5cda","excerpt":"저번 시간에는 Spark On Kubernetes에 대한 이론을 배웠습니다. 오늘은 Spark On Kubernetes에 대한 실습을 진행 하도록 하겠습니다. 사전 준비 Docker Minikube (Kubernetes 1.20 버전 이상) kubectl Spark 3.0 버전 이상 최신 버전일 수록 좋습니다. 얼마 전에 구형 Docker가 깔려 있는 맥북에서 진행을 해 봤는데 Pod이 생성이 안되더군요.. Pyspark Image Build…","frontmatter":{"date":"2023-03-30","tags":["Data-Engineering","Cloud-Computing"],"path":"/data-engineering/spark-on-k8s-2","title":"Spark on Kubernetes - Practice","img":"/post_image/thumbnail/spark-on-k8s-2.png","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자."}}},{"node":{"id":"6108ea9c-22bb-5693-995b-aebd5cfb3bcf","excerpt":"Spark Apache Spark는 기존 Hadoop의 MapReduce 형태의 클러스터 컴퓨팅의 단점을 보완하기 위해 탄생한 프레임워크 입니다. 기존 하둡의 MapReduce에서는 Disk에서 데이터를 읽은 후, Mapping, Shuffling, Reducing의 과정을 거쳐서, 다시 Disk에 저장하는 형식으로 진행 되는데요, 이는 Disk I/O가 자주 발생 하기 때문에, 속도가 상대적으로 느리다는 단점이 있습니다. 하지만 Apache…","frontmatter":{"date":"2023-03-06","tags":["Data-Engineering","Cloud-Computing"],"path":"/data-engineering/spark-on-k8s-1","title":"Spark on Kubernetes - Concept","img":"/post_image/thumbnail/spark-on-k8s-1.jpeg","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자."}}}]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"2f3abeaf-1ba1-5817-8329-0ef461b07b9c","excerpt":"오늘은 Spark 성능 튜닝에 필요한, 와  에 대해서 알아 보도록 하겠습니다. RDD는 Transformation (ex: , ,  등)을 이용 하여 새로운 RDD를 만들 수 있습니다. 하지만, Action (ex: , ,  등)이 호출 되기 전까지는, 실제 연산을 수행 하지 않죠. 다음 예제를 함께 봅시다! 하지만, 우리가 다음과 같은 상황을 가정해 보죠. 만약, 동일하게 Transformation 된 RDD에 대해, 여러 개의 Action…","frontmatter":{"date":"2023-05-24","tags":["Data-Engineering"],"path":"/data-engineering/spark-performance-tuning-2","title":"Spark 성능 튜닝 - 2. cache(), persist(), unpersist()","img":"/post_image/thumbnail/spark-performance-tuning-2.jpeg","summary":"Spark의 Performance 튜닝을 수행 해 보자."}}},{"node":{"id":"9dbd0b47-b274-5813-960b-805e0f92e2d0","excerpt":"안녕하세요? 오늘은 HDFS의 Architecture에 대해서 알아 보도록 하겠습니다. Hadoop Distributed File System(HDFS) 는 상용 하드웨어에서 동작하게 만든 오픈소스 SW입니다. 장애 발생에 강하며, 저비용 하드웨어 안에서도, 잘 작동 하게 설계 되었습니다. 또한, 많은 데이터 셋을 지닌 어플리케이션에 적합하며, 높은 throughput을 가지고 있습니다. Assumptions and Goals HDFS…","frontmatter":{"date":"2023-05-16","tags":["Data-Engineering"],"path":"/data-engineering/hdfs-architecture","title":"HDFS Architectrue","img":"/post_image/thumbnail/hdfs-architecture.png","summary":"HDFS의 구조에 대해서 알아보자."}}},{"node":{"id":"c7182a1e-4786-5112-9048-54cca7467f6d","excerpt":"안녕하세요? 오늘은 Spark Structured Streaming에 대해서 알아 보도록 하겠습니다. Spark Structured Streaming이란? Spark Structured Streaming은, Spark SQL (Dataset/DataFrame) 엔진 기반의, 확장 가능하고, 내결함성이 있는 Stream Processing Engine 입니다. 이는 Batch 작업에서 구조화된 데이터를 처리 하는 것 처럼, Streaming…","frontmatter":{"date":"2023-05-13","tags":["Data-Engineering"],"path":"/data-engineering/spark-structured-streaming","title":"Spark Structured Streaming이란?","img":"/post_image/thumbnail/spark-structured-streaming.png","summary":"Spark로 Streaming Job을 수행 해 보자."}}},{"node":{"id":"fb3c924f-4a7c-50c2-8404-09a28f1e98ec","excerpt":"오늘은 Spark의 성능 튜닝에 대해서 이야기 해 보겠습니다. Spark는 요약해서 말하면, **in-memory(RAM 위에서)**에서 작동 하는 분산 컴퓨팅을 쉽게 지원해 주는 프레임워크 입니다. in-memory 연산은 빠르지만, 불안정 합니다. 메모리 관리, CPU Core 수의 관리를 통해 Out of memory가 발생 하지 않는 선에서, Job…","frontmatter":{"date":"2023-04-07","tags":["Data-Engineering"],"path":"/data-engineering/spark-performance-tuning-1","title":"Spark 성능 튜닝 - 1. Partition, Shuffle","img":"/post_image/thumbnail/spark-performance-tuning-1.png","summary":"Spark에 성능 튜닝을 시도 해 보자."}}}]}}}}},"staticQueryHashes":["2876327880","63159454"],"slicesMap":{}}