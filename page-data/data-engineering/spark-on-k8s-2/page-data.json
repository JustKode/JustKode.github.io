{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-engineering/spark-on-k8s-2/","result":{"data":{"markdownRemark":{"html":"<p><a href=\"https://justkode.kr/data-engineering/spark-on-k8s-1\">저번 시간</a>에는 <strong>Spark On Kubernetes</strong>에 대한 이론을 배웠습니다. 오늘은 <strong>Spark On Kubernetes</strong>에 대한 실습을 진행 하도록 하겠습니다.</p>\n<h2>사전 준비</h2>\n<ul>\n<li>Docker</li>\n<li>Minikube (Kubernetes 1.20 버전 이상)</li>\n<li>kubectl</li>\n<li>Spark 3.0 버전 이상</li>\n</ul>\n<p>최신 버전일 수록 좋습니다. 얼마 전에 구형 <strong>Docker</strong>가 깔려 있는 맥북에서 진행을 해 봤는데 <strong>Pod</strong>이 생성이 안되더군요..</p>\n<h2>Pyspark Image Build &#x26; Push</h2>\n<p><strong>Kubernetes</strong> 에서 <strong>Spark Application</strong>을 수행 하기 전에, <strong>Spark Docker Image</strong>의 빌드가 선행 되어야 합니다. 일단. <code class=\"language-text\">$SPARK_DIR</code> (Spark가 설치된 경로) 안에, <code class=\"language-text\">./bin/docker-image-tool.sh</code>를 이용 하여, <strong>Spark Base Image</strong>를 <strong>Build</strong> 할 수 있습니다.</p>\n<p>해당 셸 스크립트의 <code class=\"language-text\">build</code> 관련 한 파라미터는 다음과 같습니다.</p>\n<ul>\n<li><code class=\"language-text\">-f file</code>: (Optional) <strong>JVM 기반 Image 빌드를 위한 Dockerfile</strong> 을 입력 합니다. 기본적으로 <strong>Spark와 함께 제공되는 Dockerfile을 빌드</strong>합니다. Java 17의 경우 <code class=\"language-text\">-f kubernetes/dockerfiles/spark/Dockerfile.java17</code>을 사용합니다.</li>\n<li><code class=\"language-text\">-p file</code>: (Optional) <strong>PySpark Image 빌드를 위한 Dockerfile</strong>을 입력 합니다. <strong>Python 종속성을 빌드하고 Spark와 함께 제공</strong>됩니다. 지정하지 않으면 PySpark 도커 이미지 빌드를 건너뜁니다.</li>\n<li><code class=\"language-text\">-R file</code>: (Optional) <strong>SparkR Image 빌드를 위한 Dockerfile</strong>을 입력 합니다. <strong>R 종속성을 빌드하고 Spark와 함께 제공</strong> 됩니다. 지정하지 않으면 SparkR 도커 이미지 빌드를 건너뜁니다.</li>\n<li><code class=\"language-text\">-r repo</code>: <strong>레포지토리 주소</strong>를 입력 합니다.</li>\n<li><code class=\"language-text\">t tag</code>: 빌드 된 이미지의 <strong>Tag</strong>를 입력 합니다,</li>\n</ul>\n<p>일단 <strong>Spark Base Image</strong>를 빌드 해 보겠습니다. <strong>Kubernetes</strong> 에서 <strong>Spark Job</strong>을 구동 시키기 위해 <strong>기본적으로 만들어져 제공 된 Dockerfile</strong>을 사용 합니다. (<code class=\"language-text\">./kubernetes/dockerfiles/spark/bindings/python/Dockerfile</code>, SparkR은 <code class=\"language-text\">./kubernetes/dockerfiles/spark/bindings/R/Dockerfile</code> 입니다.)</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">cd</span> <span class=\"token variable\">$SPARK_DIR</span>  <span class=\"token comment\"># spark directory</span>\n$ <span class=\"token builtin class-name\">eval</span> <span class=\"token variable\"><span class=\"token variable\">$(</span>minikube docker-env<span class=\"token variable\">)</span></span>  <span class=\"token comment\"># minikube docker image storage에 접근 하기 위함.</span>\n$ ./bin/docker-image-tool.sh <span class=\"token parameter variable\">-r</span> k8s <span class=\"token parameter variable\">-t</span> <span class=\"token number\">1.0</span> <span class=\"token parameter variable\">-p</span> ./kubernetes/dockerfiles/spark/bindings/python/Dockerfile build</code></pre></div>\n<p>일단, 폴더를 하나 생성 한 후, 다음과 같이 파일을 생성하여 코드를 입력 해 줍니다.</p>\n<ul>\n<li><code class=\"language-text\">&lt;this repository path>/python/Dockerfile</code></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"dockerfile\"><pre class=\"language-dockerfile\"><code class=\"language-dockerfile\"><span class=\"token instruction\"><span class=\"token keyword\">FROM</span> k8s/spark-py:1.0</span>\n\n<span class=\"token instruction\"><span class=\"token keyword\">COPY</span> ./script /python</span></code></pre></div>\n<ul>\n<li><code class=\"language-text\">&lt;this repository path>/python/script/rdd_example.py</code></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> pyspark <span class=\"token keyword\">import</span> SparkContext<span class=\"token punctuation\">,</span> SparkConf\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    conf <span class=\"token operator\">=</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"calculate_pyspark_example\"</span><span class=\"token punctuation\">)</span>\n    sc <span class=\"token operator\">=</span> SparkContext<span class=\"token punctuation\">(</span>conf<span class=\"token operator\">=</span>conf<span class=\"token punctuation\">)</span>\n\n    data <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>i <span class=\"token operator\">+</span> <span class=\"token number\">1</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">10000000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n    distData <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>parallelize<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"sum :\"</span><span class=\"token punctuation\">,</span> distData<span class=\"token punctuation\">.</span><span class=\"token builtin\">reduce</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">:</span> a <span class=\"token operator\">+</span> b<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>그 다음, 방금 만들어진 <strong>Base Image</strong>를 이용 하여, <strong>Application image</strong>를 빌드 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">cd</span> <span class=\"token operator\">&lt;</span>this repository path<span class=\"token operator\">></span>/python\n$ <span class=\"token builtin class-name\">eval</span> <span class=\"token variable\"><span class=\"token variable\">$(</span>minikube docker-env<span class=\"token variable\">)</span></span>\n$ <span class=\"token function\">docker</span> build <span class=\"token parameter variable\">-t</span> pyspark-on-k8s:1.0 <span class=\"token builtin class-name\">.</span>\n$ minikube image load pyspark-on-k8s:1.0</code></pre></div>\n<p>그 이후에 빌드된 모든 이미지를 확인 하기 위해, <code class=\"language-text\">docker image ls</code>를 입력 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">docker</span> image <span class=\"token function\">ls</span>\nREPOSITORY                           TAG       IMAGE ID       CREATED         SIZE\npyspark-on-k8s                       <span class=\"token number\">1.0</span>       00a4af077a09   About a minute ago   938MB\nk8s/spark-py                         <span class=\"token number\">1.0</span>       985cf805549a   <span class=\"token number\">13</span> days ago     938MB\nk8s/spark                            <span class=\"token number\">1.0</span>       bd8ba88688d4   <span class=\"token number\">13</span> days ago     601MB\n<span class=\"token punctuation\">..</span>.</code></pre></div>\n<h2>How To Run Spark Application</h2>\n<p><strong>Kubernetes</strong>에서 <strong>Spark Application</strong>을 실행 하기 전에, <strong>k8s service account, k8s clusterrolebinding</strong>를 생성 하여야 합니다. 왜냐 하면 <strong>Spark on K8S</strong>가 <strong>Driver Pod</strong>에서 <strong>Executor Pod</strong>의 상태를 관리 하는 형식이기 때문에, <strong>Driver Pod</strong>이 <strong>Pod edit 권한</strong>이 있는 <strong>service account</strong>를 가지고 있어야 합니다.</p>\n<p align=\"center\">\n    <img src=\"/post_image/spark-on-k8s/1-4.png\" max-width=\"400px\" />\n    <div align=\"center\" color=\"#aaaaaa\">Spark on K8S</div>\n</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ kubectl create serviceaccount spark\n$ kubectl create clusterrolebinding spark-role <span class=\"token parameter variable\">--clusterrole</span><span class=\"token operator\">=</span>edit <span class=\"token parameter variable\">--serviceaccount</span><span class=\"token operator\">=</span>default:spark <span class=\"token parameter variable\">--namespace</span><span class=\"token operator\">=</span>default</code></pre></div>\n<p><strong>Spark Submit</strong>을 통해, <strong>Spark Job을 K8S에서 구동</strong> 할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ kubectl proxy\nStarting to serve on <span class=\"token number\">127.0</span>.0.1:8001\n\n<span class=\"token comment\"># In another terminal</span>\n$ kubectl create namespace spark-job\n\n<span class=\"token comment\"># rdd_example</span>\n$ ./bin/spark-submit <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--master</span> k8s://http://127.0.0.1:8001 <span class=\"token punctuation\">\\</span>\n    --deploy-mode cluster <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--name</span> rdd-example <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--class</span> org.apache.spark.examples.SparkPi <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.container.image</span><span class=\"token operator\">=</span>pyspark-on-k8s:1.0 <span class=\"token punctuation\">\\</span>  <span class=\"token comment\"># Pyspark Image 지정 </span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.driver.pod.name</span><span class=\"token operator\">=</span>rdd-example-pod <span class=\"token punctuation\">\\</span>  <span class=\"token comment\"># Driver Pod 이름 지정</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.authenticate.driver.serviceAccountName</span><span class=\"token operator\">=</span>spark <span class=\"token punctuation\">\\</span>  <span class=\"token comment\"># Service account 지정</span>\n    <span class=\"token parameter variable\">--verbose</span> <span class=\"token punctuation\">\\</span>\n    <span class=\"token string\">\"local:///python/rdd_example.py\"</span>  <span class=\"token comment\"># Docker file 기준의 Local 입니다.</span>\n\n$ kubectl logs rdd-example-pod  <span class=\"token comment\"># log check</span>\n\n<span class=\"token comment\"># dataframe_example</span>\n$ ./bin/spark-submit <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--master</span> k8s://http://127.0.0.1:8001 <span class=\"token punctuation\">\\</span>\n    --deploy-mode cluster <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--name</span> dataframe-example <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--class</span> org.apache.spark.examples.SparkPi <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.container.image</span><span class=\"token operator\">=</span>pyspark-on-k8s:1.0 <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.driver.pod.name</span><span class=\"token operator\">=</span>dataframe-example-pod <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.authenticate.driver.serviceAccountName</span><span class=\"token operator\">=</span>spark <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--verbose</span> <span class=\"token punctuation\">\\</span>\n    <span class=\"token string\">\"local:///python/dataframe_example.py\"</span>\n\n$ kubectl logs dataframe-example-pod  <span class=\"token comment\"># log check</span></code></pre></div>\n<p>기타 자잘한 옵션들은 <a href=\"https://spark.apache.org/docs/3.3.2/running-on-kubernetes.html#spark-properties\">공식 문서</a>에서 확인 할 수 있습니다.</p>\n<h2>client mode?</h2>\n<p><code class=\"language-text\">--deploy-mode client</code> 옵션을 지정하여, <strong>Driver</strong>는 Spark Submit을 수행 하는 <strong>로컬</strong>에서, <strong>Executor</strong>는 <strong>Cluster</strong> 내에서 작동하게 할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ ./bin/spark-submit <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--master</span> k8s://http://127.0.0.1:8001 <span class=\"token punctuation\">\\</span>\n    --deploy-mode client <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--name</span> dataframe-example <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--class</span> org.apache.spark.examples.SparkPi <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.container.image</span><span class=\"token operator\">=</span>pyspark-on-k8s:1.0 <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.driver.pod.name</span><span class=\"token operator\">=</span>dataframe-example-pod <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--conf</span> <span class=\"token assign-left variable\">spark.kubernetes.authenticate.driver.serviceAccountName</span><span class=\"token operator\">=</span>spark <span class=\"token punctuation\">\\</span>\n    <span class=\"token parameter variable\">--verbose</span> <span class=\"token punctuation\">\\</span>\n    <span class=\"token string\">\"local://&lt;this repository path>/python/script/rdd_example.py\"</span>  <span class=\"token comment\"># Spark-submit에 있는 로컬에서 구동</span></code></pre></div>\n<p align=\"center\">\n    <img src=\"/post_image/spark-on-k8s/2-1.png\" max-width=\"400px\" />\n    <div align=\"center\" color=\"#aaaaaa\">Spark on K8S Client Mode</div>\n</p>","id":"28baf728-0bd2-5147-9ef0-b05da0826d77","frontmatter":{"date":"2023-03-30","path":"/data-engineering/spark-on-k8s-2","title":"Spark on Kubernetes - Practice","tags":["Data-Engineering","Cloud-Computing"],"keyword":"Spark, Kubernetes","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자.","img":"/post_image/thumbnail/spark-on-k8s-2.png","series":"Spark On Kubernetes"}}},"pageContext":{"postPath":"/data-engineering/spark-on-k8s-2","series":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"9ec3e659-5978-5311-b4d5-fc9d0902e008","excerpt":"안녕하세요, 박민재입니다. 아마 2년 전 즈음에 Spark on Kubernetes 관련 내용을 다뤘었는데요 (이 글 또한, 개정판을 작성 해 볼게요), 이번에는 Spark Job을 Kubernetes Cluster에 편리하게 제출할 수 있게 하는 Spark Operator에 대해 알아 보도록 하겠습니다. Spark on Kubernetes를 사용하는 이유? 그렇다고, 이 글에서 아예 설명 하지 않고 넘어가는 것은 아닌 것 같아, Spark…","frontmatter":{"date":"2025-01-19","tags":["Data-Engineering"],"path":"/data-engineering/spark-operator-1","title":"Spark Operator - 1. Spark Operator란?","img":"/post_image/thumbnail/spark-operator.jpg","summary":"Kubernetes Cluster로의 Spark Job 제출을 도와주는 Spark Operator가 무엇 인지 알아보자."}}},{"node":{"id":"28baf728-0bd2-5147-9ef0-b05da0826d77","excerpt":"저번 시간에는 Spark On Kubernetes에 대한 이론을 배웠습니다. 오늘은 Spark On Kubernetes에 대한 실습을 진행 하도록 하겠습니다. 사전 준비 Docker Minikube (Kubernetes 1.20 버전 이상) kubectl Spark 3.0 버전 이상 최신 버전일 수록 좋습니다. 얼마 전에 구형 Docker가 깔려 있는 맥북에서 진행을 해 봤는데 Pod이 생성이 안되더군요.. Pyspark Image Build…","frontmatter":{"date":"2023-03-30","tags":["Data-Engineering","Cloud-Computing"],"path":"/data-engineering/spark-on-k8s-2","title":"Spark on Kubernetes - Practice","img":"/post_image/thumbnail/spark-on-k8s-2.png","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자."}}},{"node":{"id":"159ef5da-bcc6-5cdb-bb70-0d8a76f3cb69","excerpt":"Spark Apache Spark는 기존 Hadoop의 MapReduce 형태의 클러스터 컴퓨팅의 단점을 보완하기 위해 탄생한 프레임워크 입니다. 기존 하둡의 MapReduce에서는 Disk에서 데이터를 읽은 후, Mapping, Shuffling, Reducing의 과정을 거쳐서, 다시 Disk에 저장하는 형식으로 진행 되는데요, 이는 Disk I/O가 자주 발생 하기 때문에, 속도가 상대적으로 느리다는 단점이 있습니다. 하지만 Apache…","frontmatter":{"date":"2023-03-06","tags":["Data-Engineering","Cloud-Computing"],"path":"/data-engineering/spark-on-k8s-1","title":"Spark on Kubernetes - Concept","img":"/post_image/thumbnail/spark-on-k8s-1.jpeg","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자."}}}]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"9ec3e659-5978-5311-b4d5-fc9d0902e008","excerpt":"안녕하세요, 박민재입니다. 아마 2년 전 즈음에 Spark on Kubernetes 관련 내용을 다뤘었는데요 (이 글 또한, 개정판을 작성 해 볼게요), 이번에는 Spark Job을 Kubernetes Cluster에 편리하게 제출할 수 있게 하는 Spark Operator에 대해 알아 보도록 하겠습니다. Spark on Kubernetes를 사용하는 이유? 그렇다고, 이 글에서 아예 설명 하지 않고 넘어가는 것은 아닌 것 같아, Spark…","frontmatter":{"date":"2025-01-19","tags":["Data-Engineering"],"path":"/data-engineering/spark-operator-1","title":"Spark Operator - 1. Spark Operator란?","img":"/post_image/thumbnail/spark-operator.jpg","summary":"Kubernetes Cluster로의 Spark Job 제출을 도와주는 Spark Operator가 무엇 인지 알아보자."}}},{"node":{"id":"2001438a-fe37-5b3c-8954-bce7d5e18a7a","excerpt":"안녕하세요? 박민재입니다. 오늘은 Iceberg Table을 관리하는 방법 중 하나인, Branching & Tagging 그리고 Rollback Action에 대해서 알아 보도록 하겠습니다. Isolation of Changes with Branches Iceberg에서는 git과 같은 방식으로 Branch를 만들어, 데이터 변경 사항을 관리 할 수 있습니다. 우리의 사례로 빗대어 보면 H/W 이슈, 혹은 Application…","frontmatter":{"date":"2025-01-03","tags":["Data-Engineering"],"path":"/data-engineering/iceberg-table-management-2","title":"Iceberg Table Management - 2. Branching, Tagging & Rollback","img":"/post_image/thumbnail/iceberg-table-management.png","summary":"Branching, Tagging & Rollback을 통해 Iceberg Table을 관리 해 보자"}}},{"node":{"id":"dcd44de2-0eff-56f8-ac2d-2a99250ab9cf","excerpt":"안녕하세요? 박민재입니다. 오늘은 Iceberg Table을 관리하는 방법을 Metadata Table의 사용을 중심으로 깊게 알아 보도록 하겠습니다. Apache Iceberg의 경우에는 Metadata Table 기능을 매우 강력하게 지원합니다. 이를 통해 Iceberg Table을 운영을 쉽게 수행 할 수 있죠. 예를 들어, Table의 Evolution이 어떻게 진행 되었는지, 파일들이 어떻게 Partitioning…","frontmatter":{"date":"2024-12-05","tags":["Data-Engineering"],"path":"/data-engineering/iceberg-table-management-1","title":"Iceberg Table Management - 1. Metadata Table ","img":"/post_image/thumbnail/iceberg-table-management.png","summary":"Metadata Table을 통해 Iceberg Table을 관리 해 보자"}}},{"node":{"id":"cbb6e851-d864-5552-86d7-08c81b4a54cc","excerpt":"Intro 안녕하세요, 박민재입니다. 저번 시간에는 Table Optimization을 위한 압축 기법에 대해 배웠습니다. 이번 시간에는 압축을 제외한 Table Optimization 기법을 알아 보도록 하겠습니다. Partitioning 역시, 기존의 방법을 꺼낼 때가 왔습니다. 바로 Partitioning입니다. 동일한 Column의 동일한 Value를 가진 친구들은 같은 File로 묶어 주는 방식이죠. 어? 왜 Directory…","frontmatter":{"date":"2024-11-24","tags":["Data-Engineering"],"path":"/data-engineering/iceberg-table-optimization-2","title":"Iceberg Table의 성능 최적화 - 2. Partitioning, MOR, Others","img":"/post_image/thumbnail/iceberg-table-optimization-1.webp","summary":"File Merge를 통한 성능 최적화에 대해 알아보자."}}}]}}}}},"staticQueryHashes":["3819017183","63159454"],"slicesMap":{}}