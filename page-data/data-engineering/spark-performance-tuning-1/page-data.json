{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-engineering/spark-performance-tuning-1/","result":{"data":{"markdownRemark":{"html":"<p>오늘은 <strong>Spark</strong>의 성능 튜닝에 대해서 이야기 해 보겠습니다. <strong>Spark</strong>는 요약해서 말하면, **in-memory(RAM 위에서)**에서 작동 하는 <strong>분산 컴퓨팅</strong>을 쉽게 지원해 주는 프레임워크 입니다.</p>\n<p><strong>in-memory</strong> 연산은 <strong>빠르지만, 불안정</strong> 합니다. <strong>메모리 관리, CPU Core 수의 관리</strong>를 통해 <strong>Out of memory</strong>가 발생 하지 않는 선에서, <strong>Job</strong>이 성공적으로 수행 될 수 있도록 하여야 하며, <strong>적절한 캐싱 전략, 직렬화, Executor 파티션 갯수 선정</strong>을 통해, <strong>많은 컴퓨팅 자원을 점유하지 않도록</strong> 해야 합니다.</p>\n<p>이제 하나씩 알아 보도록 하겠습니다.</p>\n<h3>Executor</h3>\n<p><strong>Spark</strong>에서 <strong>Executor</strong>는 <strong>Spark Cluster</strong> 내에서 데이터를 처리하는 단위이며, 독립된 <strong>JVM</strong> 프로세스로 실행 됩니다. <strong>Executor</strong>는 클러스터 내, <strong>여러 개의 인스턴스에서 실행</strong> 될 수 있으며, 각 <strong>인스턴스</strong>는 <strong>다수의 CPU 코어로 작업을 병렬로 실행</strong> 될 수 있습니다. 또한, 각 <strong>인스턴스의 메모리</strong>는 다음과 같이 구성 되어 있습니다,</p>\n<p align=\"center\">\n    <img src=\"/post_image/spark-performance-tuning/1-2.jpeg\" max-width=\"400px\" />\n    <div align=\"center\" color=\"#aaaaaa\">Executor Memory</div>\n</p>\n<p><strong>Spark Executor Memory</strong>는 세 가지 영역으로 나눌 수 있습니다. 이 세 가지 영역은 다음과 같습니다.</p>\n<ul>\n<li><strong>Reserved Memory</strong>: Executor의 기타 기능 및 운영체제에서 사용 하는 메모리 등을 위해 예약된 메모리 영역입니다. 예로 <strong>JVM 내에서 사용</strong> 하는 메모리, Java의 <strong>Garbage Collection</strong>에서 발생 하는 메모리 등이 저장 됩니다. <strong>300MB</strong>가 고정 되어 있으며, <code class=\"language-text\">spark.testing.reservedMemory</code>로 설정을 변경 할 수 있으나, <strong>오로지 테스트 용도</strong> 입니다. <code class=\"language-text\">전체 Executor Memory - Reserved Memory</code>는 <strong>Usable Memory</strong>가 됩니다.</li>\n<li><strong>Spark Memory</strong>: Spark에서 사용하는 메모리 영역으로, <strong>RDD Cache, Broadcast 변수, 실행 계획</strong> 등이 이 영역에 저장 됩니다. <code class=\"language-text\">Usable Memory * spark.memory.fraction</code>이 <strong>Spark Memory</strong>가 됩니다.\n<ul>\n<li><strong>Storage Memory</strong>: <strong>Cache 데이터, Broadcast 변수</strong>가 저장 됩니다. 캐싱할 공간이 부족 하면, <strong>LRU(Least Recently Used) 방식으로 제거</strong>합니다. <code class=\"language-text\">Spark Memory * spark.memory.storageFraction</code> 이 <strong>Storage Memory</strong>가 됩니다.</li>\n<li><strong>Execution Memory</strong>: Spark가 task를 실행 하는 동안 생성되는 object들인 Map 수행 시 <strong>Shuffle Intermediate Buffer</strong>, Hash aggregation step에서의 <strong>Hash Table</strong> 등이 저장 됩니다. 메모리가 충분 하지 않으면, <strong>디스크로 Spill</strong>을 하기 때문에 <strong>디스크 I/O를 줄이기 위해서 고려</strong> 하여야 합니다 <code class=\"language-text\">Spark Memory * (1 - spark.memory.storageFraction)</code> 이 <strong>Execution Memory</strong>가 됩니다.</li>\n<li>참고 사항: <strong>Storage Memory와 Execution Memory는 필요 시 서로의 메모리를 점유</strong> 할 수 있습니다. 여기서 Storage Memory는 Execution Memory로부터 쫓겨날 수 있지만, Execution Memory는 Storage Memory로부터 쫓겨 날 수 없습니다.</li>\n</ul>\n</li>\n<li><strong>User Memory</strong>: <strong>사용자 코드에서 직접 할당</strong> 되는 메모리 영역입니다. Spark 내부 메타데이터, 사용자 정의 데이터 구조, UDF, RDD 종속성 정보 등, 요약하면 <strong>사용자가 정의한 데이터구조, UDF가 저장되는 공간</strong>입니다. <code class=\"language-text\">Usable Memory * (1 - spark.memory.fraction)</code> 이 <strong>User Memory</strong>가 됩니다.</li>\n</ul>\n<h3>Partition</h3>\n<p>그 다음으로는 Spark의 <strong>Partition</strong>에 대해서 알아 보도록 하겠습니다.</p>\n<p><strong>Spark</strong>에서 <strong>파티션</strong>은 <strong>데이터를 분할하는 단위</strong>로, <strong>Spark</strong>에서 처리 하는 최소 단위라고 볼 수 있습니다. <strong>RDD(Resilient Distributed Dataset)</strong> 를 구성하는 최소 단위 객체이며, 각 파티션은 클러스터의 <strong>노드</strong>에서 분산 되어 처리 됩니다.</p>\n<p>각 <strong>Partition</strong>은 서로 다른 노드에서 분산 처리 되며, <strong>1개의 CPU Core가, 1개의 Partion에 대해, 1개의 최소 연산인 Task</strong>를 수행 합니다.</p>\n<p>똑같은 크기의 데이터 입력 이라면 <strong>설정된 Partition 수에 따가 각 Partiton의 크기가 결정</strong>되는 것이죠!</p>\n<ul>\n<li>Partiton 수가 적어요 -> Partition의 크기가 커져요!</li>\n<li>Partiton 수가 많아요 -> Partition의 크기가 작아져요!</li>\n</ul>\n<p align=\"center\">\n    <img src=\"/post_image/spark-performance-tuning/1-1.gif\" max-width=\"400px\" />\n    <div align=\"center\" color=\"#aaaaaa\">Data Partitioning</div>\n</p>\n<p>파티션을 작게 만들면, 더 작은 파일 단위로 쪼개어, <strong>Task당 필요한 메모리를 줄이고, 병렬화의 정도를 늘릴 수 있기 때문</strong>에 좋지 않을까요? 이는 <strong>정답이 아닙니다.</strong> 너무 많은 파티션으로 쪼개게 되면, <strong>파티션 간 통신 비용</strong>이 증가 하게 되고, 저장 시에는 <strong>Small File Problem</strong>이 발생 하여, <strong>Disk I/O 비용</strong>이 증가 하게 되는 단점이 있습니다.</p>\n<p>그렇다면 크게 만드는 것이 답일까요? <strong>그것 또한 아닙니다.</strong> 너무 작은 수의 파티션은 <strong>적은 Task 수</strong>로 이어져, 병렬 처리에 불리합니다. 또한, <strong>Executor 메모리 사용량</strong> 증가, Partition의 데이터 분포가 고르지 않음으로 발생 하는, <strong>Data Skew</strong>현상 또한 발생 할 수 있습니다.</p>\n<p>Partition의 종류는 3개로 나눌 수 있습니다.</p>\n<ul>\n<li><strong>Input Partition</strong>: 처음 파일을 읽을 때 생성하는 Partition으로, 관련 설정 값은 <code class=\"language-text\">spark.sql.files.maxpartitionBytes</code> 입니다.</li>\n<li><strong>Output Partition</strong>: <strong>파일을 저장할 때 생성하는 Partition</strong>으로, 이 수가 <strong>HDFS 상의 마지막 경로의 파일 수</strong>를 지정합니다. <strong>파일 하나의 크기를 HDFS Blocksize에 일치</strong> 하도록 생성 하는 것이 권장 됩니다. <code class=\"language-text\">df.repartition(cnt)</code>, <code class=\"language-text\">df.coalesce(cnt)</code>를 통해 수정 할 수 있습니다.</li>\n<li><strong>Shuffle Partition</strong>: <strong>Join, groupBy 등의 연산</strong>을 수행할 때 사용 됩니다. <code class=\"language-text\">spark.sql.shuffle.partitions</code>로 설정을 변경 할 수 있습니다.</li>\n</ul>\n<p>이 설정들을 적절히 활용 하여, Shuffle 과정에서 <strong>Shuffle Spill</strong>이 일어 나지 않도록 최적화를 하는 것이 중요합니다.</p>\n<h3>그러면 파티션과 Executor 설정을 어떻게 해야 할까요?</h3>\n<p>일단 통상 적으로 알려진 사항은 <strong>Shuffle Partition</strong> 크기가 <strong>100 ~ 200MB</strong> 정도 나오게 끔 쿼리를 조정 해 주는 것이 좋습니다. <strong>Shuffle Partition</strong>이 너무 커져서 <strong>Memory Spill</strong>을 방지 하기 위함 입니다. 또한, Core를 최대한 효율적으로 활용 하기 위해, <strong>Instance * Executor Core</strong>의 배수로 <strong>Shuffle Partition</strong>을 지정 하는 것이 좋습니다.</p>\n<p>결론적으로는 최적화는 제일 먼저 쿼리를 통해, <strong>Shuffle Partiton 크기</strong>가 커지지 않도록 조정 하고, <strong>Partition 수</strong>를 <strong>Shuffle Spill</strong>이 발생하지 않으면서, 가용 가능한 <strong>CPU Core</strong> 리소스 안에서 증가 시키고, <strong>Core 당 메모리</strong> 또한, <strong>Shuffle Partition 크기</strong> 를 감당 할 수 있는 수준으로 조정 할 수 있게 하여야 합니다. 즉, <strong>Executor당 Core, Instance당 Memory, Instance 수</strong>를 잘 조정 하여야 한다는 이야기 입니다.</p>\n<p>다음 시간에는 쿼리 최적화를 하는 방법을 한 번 가져 보도록 하겠습니다. 감사합니다.</p>\n<h3>Reference</h3>\n<ul>\n<li><a href=\"https://spark.apache.org/docs/latest/configuration.html\">https://spark.apache.org/docs/latest/configuration.html</a></li>\n<li><a href=\"https://tech.kakao.com/2021/10/08/spark-shuffle-partition/\">https://tech.kakao.com/2021/10/08/spark-shuffle-partition/</a></li>\n<li><a href=\"https://velog.io/@busybean3/Apache-Spark-%EC%95%84%ED%8C%8C%EC%B9%98-%EC%8A%A4%ED%8C%8C%ED%81%AC%EC%9D%98-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B4%80%EB%A6%AC%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C\">https://velog.io/@busybean3/Apache-Spark-%EC%95%84%ED%8C%8C%EC%B9%98-%EC%8A%A4%ED%8C%8C%ED%81%AC%EC%9D%98-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B4%80%EB%A6%AC%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C</a></li>\n</ul>","id":"6ac732dc-2528-5e90-b1f8-2d142ca3af25","frontmatter":{"date":"2023-04-07","path":"/data-engineering/spark-performance-tuning-1","title":"Spark 성능 튜닝 - 1. Partition, Shuffle","tags":["Data-Engineering"],"keyword":"Spark, 성능 튜닝, Partition, Shuffle","summary":"Spark에 성능 튜닝을 시도 해 보자.","img":"/post_image/thumbnail/spark-performance-tuning-1.png","series":"Spark Performance Tuning"}}},"pageContext":{"postPath":"/data-engineering/spark-performance-tuning-1","series":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"e4d8d6bf-2f58-5ff8-b46f-c47daed191dd","excerpt":"오늘은 Spark 성능 튜닝에서 가장 중요한 SQL Tuning에 대해서 알아 보도록 하겠습니다. 사실 파라미터(Shuffle Partition 갯수, Executor Instance, Core, Memory 조정) 튜닝 또한, 도움이 될 수 있겠습니다만, 그 전에 Execution Plan이 잘 짜여져 있지 않다면, 파라미터 튜닝이 큰 영향을 주지는 못할 것 입니다. What is Execution Plan? Exection Plan…","frontmatter":{"date":"2023-08-22","tags":["Data-Engineering"],"path":"/data-engineering/spark-performance-tuning-3","title":"Spark 성능 튜닝 - 3. Spark SQL Tuning","img":"/post_image/thumbnail/spark-performance-tuning-3.jpeg","summary":"Spark의 쿼리를 튜닝 해 보자"}}},{"node":{"id":"6466dd9e-f217-5113-909a-150f27b482f3","excerpt":"오늘은 Spark 성능 튜닝에 필요한, 와  에 대해서 알아 보도록 하겠습니다. RDD는 Transformation (ex: , ,  등)을 이용 하여 새로운 RDD를 만들 수 있습니다. 하지만, Action (ex: , ,  등)이 호출 되기 전까지는, 실제 연산을 수행 하지 않죠. 다음 예제를 함께 봅시다! 하지만, 우리가 다음과 같은 상황을 가정해 보죠. 만약, 동일하게 Transformation 된 RDD에 대해, 여러 개의 Action…","frontmatter":{"date":"2023-05-24","tags":["Data-Engineering"],"path":"/data-engineering/spark-performance-tuning-2","title":"Spark 성능 튜닝 - 2. cache(), persist(), unpersist()","img":"/post_image/thumbnail/spark-performance-tuning-2.jpeg","summary":"Spark의 Performance 튜닝을 수행 해 보자."}}},{"node":{"id":"6ac732dc-2528-5e90-b1f8-2d142ca3af25","excerpt":"오늘은 Spark의 성능 튜닝에 대해서 이야기 해 보겠습니다. Spark는 요약해서 말하면, **in-memory(RAM 위에서)**에서 작동 하는 분산 컴퓨팅을 쉽게 지원해 주는 프레임워크 입니다. in-memory 연산은 빠르지만, 불안정 합니다. 메모리 관리, CPU Core 수의 관리를 통해 Out of memory가 발생 하지 않는 선에서, Job…","frontmatter":{"date":"2023-04-07","tags":["Data-Engineering"],"path":"/data-engineering/spark-performance-tuning-1","title":"Spark 성능 튜닝 - 1. Partition, Shuffle","img":"/post_image/thumbnail/spark-performance-tuning-1.png","summary":"Spark에 성능 튜닝을 시도 해 보자."}}}]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"3c44d6b1-b341-5256-bb40-e6a58835b474","excerpt":"Intro 안녕하세요, 박민재입니다. 오늘은 Apache Iceberg의 Table에 수행 되는 쿼리가 최적의 성능으로 작동 될 수 있도록, File Compaction을 통해 이를 수행하는 방법에 대해 이야기 하는 시간을 가져 보도록 하겠습니다. File Compaction 우리가 쿼리를 수행 시, Hive Metastore의 정보를 이용하더라도, 혹은 Iceberg의 Metadata…","frontmatter":{"date":"2024-11-10","tags":["Data-Engineering"],"path":"/data-engineering/iceberg-table-optimization-1","title":"Iceberg Table의 성능 최적화 - 1. 압축","img":"/post_image/thumbnail/iceberg-table-optimization-1.webp","summary":"File Merge를 통한 성능 최적화에 대해 알아보자."}}},{"node":{"id":"6eaa7aeb-a4fe-5cd9-bbe5-309dde97514b","excerpt":"안녕하세요, 박민재입니다. 오늘은 Airflow DB를 관리하는 방법에 대해서 이야기 나눠 보도록 하겠습니다. Airflow Backend Database Airflow에서 Backend Database는 어떤 역할을 할까요? Airflow에서 DAG을 실행 하기 위해서, Airflow는 다음과 같은 정보들을 Backend Database에 저장하여 정합성을 유지 합니다. DagRun: 특정 Interval에 실행 된 DagRun…","frontmatter":{"date":"2024-10-27","tags":["Data-Engineering"],"path":"/data-engineering/airflow-db-management","title":"Airflow Backend Database Management (airflow db clean)","img":"/post_image/thumbnail/airflow-db-management.webp","summary":"Airflow의 Backend Database를 관리 하는 법"}}},{"node":{"id":"b595b168-8160-5abf-9641-39746d2f9e82","excerpt":"안녕하세요, 박민재입니다. 오늘은 Spark Application내의 각 Executor 내의 Task에 제한적으로 변수를 공유하는 두 가지 방법에 대해서 알아 보도록 하겠습니다. 시작하기에 앞서 단편적으로 생각 해 보면, Spark Application에서 연산 과정의 변수를 공유 한다는 것은 어려운 일인가? 라는 질문을 던져 볼 수 있습니다. 우리는 Task…","frontmatter":{"date":"2024-10-11","tags":["Data-Engineering"],"path":"/data-engineering/spark-sharing-variables","title":"Sharing Variables in Spark - Broadcast, Accumulator","img":"/post_image/thumbnail/spark-sharing-variables.png","summary":"Spark Application에서 변수를 공유 하는 방법"}}},{"node":{"id":"5effd6a1-bfd8-5a86-b718-5eb1e534601e","excerpt":"Intro 안녕하세요, 박민재입니다. 오늘은 Spark Memory에 관해 Deep Dive를 해 보도록 하겠습니다. Spark는 In-Memory를 이용하여, 빠른 연산을 할 수 있도록 보장합니다. 하지만, In-Memory 연산은 빠른 대신, 비싼 관계로 적은 리소스 만을 활용할 수 있습니다. 그렇기 때문에 우리는 효율적으로 Memory를 관리 하여, Spark Application이 빠르고, 안정적으로 Task…","frontmatter":{"date":"2024-04-12","tags":["Data-Engineering"],"path":"/data-engineering/spark-memory-deep-dive","title":"Deep Dive of Spark Memory","img":"/post_image/thumbnail/spark-memory-deep-dive.jpeg","summary":"Spark Memory의 깊은 이해를 위해 Deep Dive를 해 보자."}}}]}}}}},"staticQueryHashes":["3819017183","63159454"],"slicesMap":{}}