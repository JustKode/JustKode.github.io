{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-engineering/spark-performance-tuning-3/","result":{"data":{"markdownRemark":{"html":"<p>오늘은 <strong>Spark</strong> 성능 튜닝에서 가장 중요한 <strong>SQL Tuning</strong>에 대해서 알아 보도록 하겠습니다.</p>\n<p>사실 파라미터(Shuffle Partition 갯수, Executor Instance, Core, Memory 조정) 튜닝 또한, 도움이 될 수 있겠습니다만, 그 전에 <strong>Execution Plan</strong>이 잘 짜여져 있지 않다면, 파라미터 튜닝이 큰 영향을 주지는 못할 것 입니다.</p>\n<h3>What is Execution Plan?</h3>\n<p><strong>Exection Plan</strong>은 뭘까요? 우리가 <strong>Spark SQL API</strong>인 <strong>Dataframe Aggregation Code</strong>를 작성 했다고 가정 하겠습니다. 그렇게 되면, Spark 내부의 <strong>Catalyst Optimizer</strong>는 다음과 같은 동작을 수행 합니다.</p>\n<ul>\n<li>DataFrame, SQL, RDD로 작성 된 코드를 최적화 되지 않은 <strong>Unresolved Logical Plan</strong>으로 변환 합니다.</li>\n<li>Schema 등을 확인 하여, 해당 <strong>Unresolved Logical Plan</strong>이 Spark 상에서 가동 가능 하다는 판단이 되면, 이를 <strong>Logical Plan</strong>으로 전환 하고, 내부에 구현되어 있는 <strong>Optimizing Rules</strong>에 기반하여, 이를 최적화된 <strong>Optimized Logical Plan</strong>으로 구현 합니다.</li>\n<li>최적화 된 <strong>Optimized Logical Plan</strong>을 각 Executor에 전달하여 수행 합니다.</li>\n</ul>\n<p align=\"center\">\n    <img src=\"/post_image/spark-performance-tuning/3-1.jpeg\" max-width=\"400px\" />\n    <div align=\"center\" color=\"#aaaaaa\">Execution Plan이 생성되는 과정</div>\n</p>\n<p>우리는 실제로 연산이 되는 것을 어떻게 확인 할 수 있을까요? 우리는 <code class=\"language-text\">explain()</code> 메서드를 통해, 논리적으로 어떻게 연산이 진행 되는지 확인 할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre class=\"language-scala\"><code class=\"language-scala\"><span class=\"token keyword\">import</span> <span class=\"token namespace\">spark<span class=\"token punctuation\">.</span>implicits<span class=\"token punctuation\">.</span></span>_\n\n<span class=\"token keyword\">val</span> data <span class=\"token operator\">=</span> Seq<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">20000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">30000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"2\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"2\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">20000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"3\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"3\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">val</span> testDf <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>createDataFrame<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>toDF<span class=\"token punctuation\">(</span><span class=\"token string\">\"id\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"score\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">val</span> resultDf <span class=\"token operator\">=</span> testDf<span class=\"token punctuation\">.</span>groupBy<span class=\"token punctuation\">(</span>col<span class=\"token punctuation\">(</span><span class=\"token string\">\"id\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>agg<span class=\"token punctuation\">(</span>sum<span class=\"token punctuation\">(</span><span class=\"token string\">\"score\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nresultDf<span class=\"token punctuation\">.</span>explain<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- HashAggregate(keys=[id#16], functions=[sum(score#17)])\n   +- Exchange hashpartitioning(id#16, 200), ENSURE_REQUIREMENTS, [plan_id=11]\n      +- HashAggregate(keys=[id#16], functions=[partial_sum(score#17)])\n         +- LocalTableScan [id#16, score#17]</code></pre></div>\n<p>혹은 실제로 Physical Plan (Execution Plan)이 실행 된 이후, Spark Web UI의 SQL에서 확인 해 볼 수도 있습니다.</p>\n<p>실제로 Web UI를 잘 이용하면 좋은 것이, 각 연산 Job, Stage 별로 각 Executor 마다 얼마 만큼의 <strong>Data Input / Output</strong>이 발생 했고, <strong>Shuffle</strong>이 얼마나 발생 했는지, <strong>Data Spill</strong>은 얼마나 있었는지를 확인 할 수 있기 때문에, 튜닝 포인트를 찾을 때 유용 합니다.</p>\n<p align=\"center\">\n    <img src=\"/post_image/spark-performance-tuning/3-2.png\" width=\"400px\" />\n    <div align=\"center\" color=\"#aaaaaa\">Spark Web UI - SQL</div>\n</p>\n<p align=\"center\">\n    <img src=\"/post_image/spark-performance-tuning/3-2.png\" width=\"400px\" />\n    <div align=\"center\" color=\"#aaaaaa\">Spark Web UI - Stages</div>\n</p>\n<h3>How To Optimize Query</h3>\n<p>일단 일차적으로, 알고리즘 문제를 푼다고 생각하고, <strong>어떻게 해야 연산량을 줄일 수 있을까?</strong> 라는 생각으로 접근 하셔야 합니다. 도움이 될 만한 몇 가지 테크닉이 있습니다.</p>\n<h4>Select Column &#x26; Filtering First</h4>\n<p>Spark Application에서 <strong>Memory 점유율을 낮추기 위해</strong>, <strong>Shuffle Data의 크기를 줄이기 위해</strong> <strong>필요한 Column만 추출</strong> 하는 것이 중요 합니다., 또한, 데이터의 Record 갯수를 줄일 수 있는 <strong>Filtering</strong>은 맨 앞단에서 진행을 시켜 주는 것이 중요 합니다.</p>\n<h4>Adaptive Query Execution</h4>\n<p><strong>Adaptive Query Execution</strong>을 이용하면, Spark가 Runtime에 <strong>Execution Plan</strong>을 변경 하게 할 수 있습니다. 이는 <strong>Spark Application</strong>에서 Runtime 도중의 Data 통계를 수집하여 다음과 같은 효과를 얻을 수 있습니다.</p>\n<ul>\n<li>Query 수행 간 <strong>효율적인 Partition 갯수를 설정</strong>하여 줌</li>\n<li><strong>Skew(특정 Partition에 데이터가 몰리는 현상) data</strong> 같은 경우에 대해 <strong>Partition 증설</strong></li>\n<li>Join시 <strong>Broadcast Join</strong> 혹은 <strong>Sort Merge Join</strong>의 사용을 결정</li>\n</ul>\n<p>이는 <code class=\"language-text\">spark.sql.adaptive.enabled</code> 설정을 <code class=\"language-text\">true</code> 로 지정 하여 주면 됩니다.</p>\n<h4>Use Only Spark SQL API</h4>\n<p>가능한 UDF 함수를 사용 하지 않고, <strong>Spark SQL 내부의 함수</strong>를 이용하여, Logical Logic이 <strong>Optimizer를 태울 수</strong> 있도록 해 주는 것이 중요 합니다. 또한, 일반 <strong>Dataset, RDD</strong>를 사용 하는 것 보다는 <strong>Catalyst Optimzer</strong>에 최적화 된 <strong>DataFrame</strong>을 사용 하는 것이 <strong>Memory와 CPU의 효율성을 극대화</strong> 할 수 있습니다.</p>\n<h4>coalesce() vs repartition()</h4>\n<p>Partition 갯수를 늘리는 것이 아니라면, <code class=\"language-text\">coalesce()</code>를 사용 하는 것이 더 좋습니다. <code class=\"language-text\">coalesce()</code>는 Partition 갯수를 줄이는 데 있어, <code class=\"language-text\">repartiton()</code>의 최적화 된 버전입니다.</p>\n<h4>Etc</h4>\n<p>기타 중요한 테크닉은 다음과 같습니다.</p>\n<ul>\n<li>Network I/O를 많이 사용하게 되는 <strong>Shuffle 연산을 최소화</strong> 할 것.</li>\n<li>만들어진 <strong>DataFrame을 재사용</strong> 하게 된다면, <strong>Cache를 잘 사용</strong> 할 것.</li>\n</ul>\n<h3>Reference</h3>\n<ul>\n<li><a href=\"https://sparkbyexamples.com/spark/spark-execution-plan/\">https://sparkbyexamples.com/spark/spark-execution-plan/</a></li>\n<li><a href=\"https://sparkbyexamples.com/spark/spark-performance-tuning/\">https://sparkbyexamples.com/spark/spark-performance-tuning/</a></li>\n</ul>","id":"e4d8d6bf-2f58-5ff8-b46f-c47daed191dd","frontmatter":{"date":"2023-08-22","path":"/data-engineering/spark-performance-tuning-3","title":"Spark 성능 튜닝 - 3. Spark SQL Tuning","tags":["Data-Engineering"],"keyword":"Spark, 성능 튜닝, spark cache, spark SQL, spark query","summary":"Spark의 쿼리를 튜닝 해 보자","img":"/post_image/thumbnail/spark-performance-tuning-3.jpeg","series":"Spark Performance Tuning"}}},"pageContext":{"postPath":"/data-engineering/spark-performance-tuning-3","series":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"e4d8d6bf-2f58-5ff8-b46f-c47daed191dd","excerpt":"오늘은 Spark 성능 튜닝에서 가장 중요한 SQL Tuning에 대해서 알아 보도록 하겠습니다. 사실 파라미터(Shuffle Partition 갯수, Executor Instance, Core, Memory 조정) 튜닝 또한, 도움이 될 수 있겠습니다만, 그 전에 Execution Plan이 잘 짜여져 있지 않다면, 파라미터 튜닝이 큰 영향을 주지는 못할 것 입니다. What is Execution Plan? Exection Plan…","frontmatter":{"date":"2023-08-22","tags":["Data-Engineering"],"path":"/data-engineering/spark-performance-tuning-3","title":"Spark 성능 튜닝 - 3. Spark SQL Tuning","img":"/post_image/thumbnail/spark-performance-tuning-3.jpeg","summary":"Spark의 쿼리를 튜닝 해 보자"}}},{"node":{"id":"6466dd9e-f217-5113-909a-150f27b482f3","excerpt":"오늘은 Spark 성능 튜닝에 필요한, 와  에 대해서 알아 보도록 하겠습니다. RDD는 Transformation (ex: , ,  등)을 이용 하여 새로운 RDD를 만들 수 있습니다. 하지만, Action (ex: , ,  등)이 호출 되기 전까지는, 실제 연산을 수행 하지 않죠. 다음 예제를 함께 봅시다! 하지만, 우리가 다음과 같은 상황을 가정해 보죠. 만약, 동일하게 Transformation 된 RDD에 대해, 여러 개의 Action…","frontmatter":{"date":"2023-05-24","tags":["Data-Engineering"],"path":"/data-engineering/spark-performance-tuning-2","title":"Spark 성능 튜닝 - 2. cache(), persist(), unpersist()","img":"/post_image/thumbnail/spark-performance-tuning-2.jpeg","summary":"Spark의 Performance 튜닝을 수행 해 보자."}}},{"node":{"id":"6ac732dc-2528-5e90-b1f8-2d142ca3af25","excerpt":"오늘은 Spark의 성능 튜닝에 대해서 이야기 해 보겠습니다. Spark는 요약해서 말하면, **in-memory(RAM 위에서)**에서 작동 하는 분산 컴퓨팅을 쉽게 지원해 주는 프레임워크 입니다. in-memory 연산은 빠르지만, 불안정 합니다. 메모리 관리, CPU Core 수의 관리를 통해 Out of memory가 발생 하지 않는 선에서, Job…","frontmatter":{"date":"2023-04-07","tags":["Data-Engineering"],"path":"/data-engineering/spark-performance-tuning-1","title":"Spark 성능 튜닝 - 1. Partition, Shuffle","img":"/post_image/thumbnail/spark-performance-tuning-1.png","summary":"Spark에 성능 튜닝을 시도 해 보자."}}}]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"3c44d6b1-b341-5256-bb40-e6a58835b474","excerpt":"Intro 안녕하세요, 박민재입니다. 오늘은 Apache Iceberg의 Table에 수행 되는 쿼리가 최적의 성능으로 작동 될 수 있도록, File Compaction을 통해 이를 수행하는 방법에 대해 이야기 하는 시간을 가져 보도록 하겠습니다. File Compaction 우리가 쿼리를 수행 시, Hive Metastore의 정보를 이용하더라도, 혹은 Iceberg의 Metadata…","frontmatter":{"date":"2024-11-10","tags":["Data-Engineering"],"path":"/data-engineering/iceberg-table-optimization-1","title":"Iceberg Table의 성능 최적화 - 1. 압축","img":"/post_image/thumbnail/iceberg-table-optimization-1.webp","summary":"File Merge를 통한 성능 최적화에 대해 알아보자."}}},{"node":{"id":"6eaa7aeb-a4fe-5cd9-bbe5-309dde97514b","excerpt":"안녕하세요, 박민재입니다. 오늘은 Airflow DB를 관리하는 방법에 대해서 이야기 나눠 보도록 하겠습니다. Airflow Backend Database Airflow에서 Backend Database는 어떤 역할을 할까요? Airflow에서 DAG을 실행 하기 위해서, Airflow는 다음과 같은 정보들을 Backend Database에 저장하여 정합성을 유지 합니다. DagRun: 특정 Interval에 실행 된 DagRun…","frontmatter":{"date":"2024-10-27","tags":["Data-Engineering"],"path":"/data-engineering/airflow-db-management","title":"Airflow Backend Database Management (airflow db clean)","img":"/post_image/thumbnail/airflow-db-management.webp","summary":"Airflow의 Backend Database를 관리 하는 법"}}},{"node":{"id":"b595b168-8160-5abf-9641-39746d2f9e82","excerpt":"안녕하세요, 박민재입니다. 오늘은 Spark Application내의 각 Executor 내의 Task에 제한적으로 변수를 공유하는 두 가지 방법에 대해서 알아 보도록 하겠습니다. 시작하기에 앞서 단편적으로 생각 해 보면, Spark Application에서 연산 과정의 변수를 공유 한다는 것은 어려운 일인가? 라는 질문을 던져 볼 수 있습니다. 우리는 Task…","frontmatter":{"date":"2024-10-11","tags":["Data-Engineering"],"path":"/data-engineering/spark-sharing-variables","title":"Sharing Variables in Spark - Broadcast, Accumulator","img":"/post_image/thumbnail/spark-sharing-variables.png","summary":"Spark Application에서 변수를 공유 하는 방법"}}},{"node":{"id":"5effd6a1-bfd8-5a86-b718-5eb1e534601e","excerpt":"Intro 안녕하세요, 박민재입니다. 오늘은 Spark Memory에 관해 Deep Dive를 해 보도록 하겠습니다. Spark는 In-Memory를 이용하여, 빠른 연산을 할 수 있도록 보장합니다. 하지만, In-Memory 연산은 빠른 대신, 비싼 관계로 적은 리소스 만을 활용할 수 있습니다. 그렇기 때문에 우리는 효율적으로 Memory를 관리 하여, Spark Application이 빠르고, 안정적으로 Task…","frontmatter":{"date":"2024-04-12","tags":["Data-Engineering"],"path":"/data-engineering/spark-memory-deep-dive","title":"Deep Dive of Spark Memory","img":"/post_image/thumbnail/spark-memory-deep-dive.jpeg","summary":"Spark Memory의 깊은 이해를 위해 Deep Dive를 해 보자."}}}]}}}}},"staticQueryHashes":["3819017183","63159454"],"slicesMap":{}}