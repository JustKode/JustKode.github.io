{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-engineering/spark-on-k8s-1","result":{"data":{"markdownRemark":{"html":"<h3>Spark</h3>\n<p><strong>Apache Spark</strong>는 기존 <strong>Hadoop</strong>의 <strong>MapReduce</strong> 형태의 클러스터 컴퓨팅의 단점을 보완하기 위해 탄생한 프레임워크 입니다. 기존 하둡의 <strong>MapReduce</strong>에서는 Disk에서 데이터를 읽은 후, <strong>Mapping, Shuffling, Reducing</strong>의 과정을 거쳐서, 다시 Disk에 저장하는 형식으로 진행 되는데요, 이는 <strong>Disk I/O</strong>가 자주 발생 하기 때문에, 속도가 상대적으로 느리다는 단점이 있습니다.</p>\n<p>하지만 <strong>Apache Spark</strong>는, RDD, Data Frame, Data Set을 바탕으로, In-Memory 연산을 통해, <strong>Disk I/O</strong> 대신, <strong>Memory I/O</strong>로 <strong>100배가 빠른 연산 속도</strong>를 이뤄 낼 수 있었습니다. 그 대신, <strong>In-Memory</strong>에서 작동 하기 때문에, 많은 양의 데이터를 메모리에 올려서 연산 하기에는 무리가 있다는 단점이 있습니다. 그렇기 때문에, 용량이 많지는 않지만, 빠른 연산을 요구 하는 경우에 자주 쓰이죠. 자주 사용되는 Cluster Manager로는 <strong>YARN, Apache Mesos</strong>가 있습니다.</p>\n<p align=\"center\">\n    <img src=\"/post_image/spark-on-k8s/1-1.png\" min-width=\"400px\" />\n    <div align=\"center\" color=\"#aaaaaa\">MapReduce vs Spark (<a href=\"https://velog.io/@bona-park/Hadoop%EC%9D%98-mapreduce%EC%99%80-spark%EC%9D%98-RDD%EC%97%B0%EC%82%B0%EC%9D%80-%EC%96%B4%EB%96%A4-%EC%A0%90%EC%97%90%EC%84%9C-%EB%8B%A4%EB%A5%B8%EC%A7%80\">출처</a>)</div>\n</p>\n<h3>Kubernetes</h3>\n<p><strong>Kubernetes</strong>는 컨테이너를 쉽고 빠르게 배포/확장하고 관리를 자동화해주는 <strong>Container Orchestration Tool</strong> 입니다. <strong>Kubernetes</strong> 시스템을 통해, 다음을 제공 받을 수 있습니다.</p>\n<ul>\n<li>서비스 디스커버리와 로드 밸런싱: DNS 이름, 혹은 자체 IP 주소를 이용하여 <strong>컨테이너를 노출</strong> 해 주고, 트래픽이 많아지면 <strong>로드 밸런싱</strong>을 제공 하여 줍니다.</li>\n<li>스토리지 오케스트레이션: 로컬 저장소, 클라우드 공급자 등과 같은 <strong>저장소 시스템을 자동으로 탑재</strong> 하게 할 수 있습니다.</li>\n<li>자동화된 롤아웃과 롤백: 컨테이너의 원하는 상태를 지정 해 놓으면, 이에 맞춰 <strong>롤아웃, 롤백을 자동으로, 원하는 속도로</strong> 수행 해 줍니다.</li>\n<li>자동화된 빈 패킹 (bin packing): 컨테이너화된 작업을 실행하는 데 사용할 수 있는 쿠버네티스 클러스터 노드를 제공 하는데, <strong>컨테이너가 필요로 하는 CPU와 메모리를 적정 하게 제공</strong> 해 줍니다.</li>\n<li>자동화된 복구 (self-healing): 실패한 <strong>컨테이너를 다시 시작하고, 컨테이너를 교체</strong>하는 기술을 가지고 있습니다.</li>\n<li>시크릿과 구성 관리: 암호, OAuth 토큰 및 SSH 키와 같은 <strong>중요한 정보를 관리</strong> 할 수 있습니다.</li>\n</ul>\n<p align=\"center\">\n    <img src=\"/post_image/spark-on-k8s/1-2.png\" width=\"256px\" />\n    <div align=\"center\" color=\"#aaaaaa\">Kubernetes Logo</div>\n</p>\n<h3>Why Spark On Kubernetes?</h3>\n<p><strong>Spark Job</strong>를 왜 <strong>Kubernetes</strong> 환경에서 돌리는 것에 대한 의논이 왜 나왔을까요? 기존의 <strong>Hadoop Ecosystem</strong>에서 사용 하던 <strong>YARN</strong>도 있는데 말이죠.</p>\n<h4>YARN Cluster Manager</h4>\n<p><strong>YARN</strong>이라는 Cluster Manager를 이용하여 <strong>Spark</strong> 연산을 수행 할 수 있습니다. <strong>YARN</strong>은 다음과 같은 구조를 가지고 있는 데요, 수행 과정은 다음과 같습니다.</p>\n<ol>\n<li><strong>클라이언트</strong>는 <strong>Resource Manager</strong>에게 <strong>Application Master</strong> 실행을 요청 합니다.</li>\n<li><strong>Resource Manager</strong>는 컨테이너에서 <strong>Application Master</strong>을 실행 할 수 있는 <strong>Node Manager</strong>를 찾습니다.</li>\n<li><strong>Node Manager</strong>에서 컨테이너 생성 후 <strong>Application Master</strong>를 실행 합니다.</li>\n<li>분산 처리를 위해, <strong>Resource Manager</strong>에게 더 많은 컨테이너를 요청합니다.</li>\n<li>분산 처리를 수행할 수 있는 다른 <strong>Node Manager</strong>에게 컨테이너 생성을 요청 한 후, 분산 처리를 수행 합니다.</li>\n</ol>\n<p align=\"center\">\n    <img src=\"/post_image/spark-on-k8s/1-3.gif\" max-width=\"400px\" />\n    <div align=\"center\" color=\"#aaaaaa\">YARN Architecture</div>\n</p>\n<p>이렇게 보면 딱히 문제가 없는거 같지만, <strong>YARN</strong> 자체에는 내재 되어 있는 문제가 있습니다.</p>\n<p>첫 번째는, 운영적인 측면입니다. <strong>YARN</strong>에서 프로세스를 수행 하게 된다면, <strong>의존성 문제</strong>가 발생 하게 됩니다. 단일 Spark 버전만 사용 할 수 있기 때문에 발생 하는 <strong>멀티 테넌시 (단일 소프트웨어 인스턴스로, 여러 사용자 그룹에 서비스를 제공 하는 아키텍처) 운영 불가</strong> 문제, 성능을 위해서 <strong>Spark를 업그레이드 하려고 할 때 YARN 클러스터 전체를 업그레이드</strong> 해야 하는 문제 등, 여러 가지 문제가 내제 되어 있습니다.</p>\n<p>두 번째는, <strong>Resource</strong> 문제 입니다. 기존에 대기 하고 있는 <strong>Node Manager</strong>에서 Task를 수행 하면, <strong>Kubernetes</strong>에 비해, 네트워크를 새로 연결 하고, Pod을 굳이 띄울 필요가 없으니, <strong>Overhead</strong> 측면에서는 <strong>YARN</strong>이 이득일 수도 있습니다. 하지만, 어떤 연산은 메모리가 더 필요하고, 어떤 연산은 CPU가 더 필요 할 수도 있습니다. <strong>YARN</strong>은 모든 Job에 대해서 동일 한 <strong>Resource</strong>를 할당하는 <strong>Container</strong>를 제공 합니다. 그렇기 때문에, <strong>노는 CPU, 노는 메모리</strong>가 발생 할 수도 있는 것이죠.</p>\n<p>세 번째는, <strong>Performance</strong> 입니다. 최신 버전 (3.2)에서는 Kubernetes 상의 성능 및 안정성 문제를 개선하여, <a href=\"https://aws.amazon.com/ko/blogs/containers/optimizing-spark-performance-on-kubernetes/\">Amazon에서 테스트 해 본 결과</a>, YARN 보다 Kubernetes에서 Spark job을 돌리는 게 <strong>5%의 성능 향상</strong>을 불러 왔다고 하네요. <strong>Map-Reduce</strong> 과정의 <strong>Shuffling</strong> 과정은 <strong>많은 네트워크 I/O와, 많은 메모리를 사용</strong> 하는데, 이에 맞게 <strong>높은 I/O를 구동 할 수 있으면서, 대용량 메모리인 인스턴스</strong>를 이용 하여, 빠른 수행을 가능 하게 하는 거죠.</p>\n<p>이들을 <strong>Spark On K8S</strong>는, <strong>컨테이너화, 리소스 공유, 효과 적인 Auto Scaling</strong>을 통해서 이를 해결 합니다. 또한, <strong>Kubernetes</strong> 위에서 작동한다는 것은, <strong>Kubernetes</strong>의 다양한 생태계를 사용 할 수 있다는 걸 의미 합니다. 개발 상의 많은 이점이 존재 한다는 뜻이죠.</p>\n<h3>How To Work?</h3>\n<p>내부 동작은 다음과 같습니다.</p>\n<p align=\"center\">\n    <img src=\"/post_image/spark-on-k8s/1-4.png\" max-width=\"400px\" />\n    <div align=\"center\" color=\"#aaaaaa\">Spark on K8S</div>\n</p>\n<ul>\n<li>spark-submit을 통해서 Spark는 Kubernetes Pod 내에서 실행되는 <strong>Spark Driver를 생성</strong> 합니다.</li>\n<li><strong>Spark Driver</strong>는 Kubernetes Pod 내에서 <strong>Executor</strong>를 생성하고 연결하여, Application을 수행 합니다.</li>\n<li><strong>Application</strong>이 완료되면, <strong>Executor Pod</strong>가 종료되고 정리 되지만, <strong>Driver Pod</strong>은 완료 상태로 로그를 유지하고, 가비지 수집 혹은 수동으로 정리 될 때 까지 남아 있습니다.</li>\n</ul>\n<p>모니터링은 <strong>Prometheus</strong>를 통해 수행 할 수 있습니다. <code class=\"language-text\">$SPARK_CONF_DIR</code> 내에 <strong>Prometheus</strong> 관련 설정을 넣어 주신 후에, 다음과 같이, <strong>spark-submit</strong> 시에 <code class=\"language-text\">spark.kubernetes.driver.annotation.prometheus.io</code> 관련 설정을 만져 주면 가능합니다. 실행 중에 <code class=\"language-text\">http://&lt;spark-driver&gt;/metrics/executors/prometheus</code>에 접근 하면 확인 가능 합니다. 자세한 건 다음 시간에 알아 보도록 해요.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ spark-submit <span class=\"token punctuation\">\\</span>\n    --conf spark.ui.prometheus.enabled<span class=\"token operator\">=</span>true <span class=\"token punctuation\">\\</span>\n    --conf spark.kubernetes.driver.annotation.prometheus.io/scrape<span class=\"token operator\">=</span>true <span class=\"token punctuation\">\\</span>\n    --conf spark.kubernetes.driver.annotation.prometheus.io/path<span class=\"token operator\">=</span>/metrics/executors/prometheus <span class=\"token punctuation\">\\</span>\n    --conf spark.kubernetes.driver.annotation.prometheus.io/port<span class=\"token operator\">=</span><span class=\"token number\">4040</span> <span class=\"token punctuation\">\\</span>\n    <span class=\"token punctuation\">..</span>.</code></pre></div>\n<p>다음 시간에는 이를 <strong>실제로 구현</strong> 해 보면서, 어떤 문제점이 내재되어 있는지를 알아 보는 시간을 가져 보도록 하겠습니다.</p>","id":"6108ea9c-22bb-5693-995b-aebd5cfb3bcf","frontmatter":{"date":"2023-03-06","path":"/data-engineering/spark-on-k8s-1","title":"Spark on Kubernetes - Concept","tags":["Data-Engineering","Cloud-Computing"],"keyword":"Spark, Kubernetes","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자.","img":"/post_image/thumbnail/spark-on-k8s-1.jpeg","series":"Spark On Kubernetes"}}},"pageContext":{"series":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"7611f6af-dc48-595b-8866-23beee4d5cda","excerpt":"저번 시간에는 Spark On Kubernetes에 대한 이론을 배웠습니다. 오늘은 Spark On Kubernetes에 대한 실습을 진행 하도록 하겠습니다. 사전 준비 Docker Minikube (Kubernetes 1.20 버전 이상) kubectl Spark 3.0 버전 이상 최신 버전일 수록 좋습니다. 얼마 전에 구형 Docker가 깔려 있는 맥북에서 진행을 해 봤는데 Pod이 생성이 안되더군요.. Pyspark Image Build…","frontmatter":{"date":"2023-03-30","tags":["Data-Engineering","Cloud-Computing"],"path":"/data-engineering/spark-on-k8s-2","title":"Spark on Kubernetes - Practice","img":"/post_image/thumbnail/spark-on-k8s-2.png","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자."}}},{"node":{"id":"6108ea9c-22bb-5693-995b-aebd5cfb3bcf","excerpt":"Spark Apache Spark는 기존 Hadoop의 MapReduce 형태의 클러스터 컴퓨팅의 단점을 보완하기 위해 탄생한 프레임워크 입니다. 기존 하둡의 MapReduce에서는 Disk에서 데이터를 읽은 후, Mapping, Shuffling, Reducing의 과정을 거쳐서, 다시 Disk에 저장하는 형식으로 진행 되는데요, 이는 Disk I/O가 자주 발생 하기 때문에, 속도가 상대적으로 느리다는 단점이 있습니다. 하지만 Apache…","frontmatter":{"date":"2023-03-06","tags":["Data-Engineering","Cloud-Computing"],"path":"/data-engineering/spark-on-k8s-1","title":"Spark on Kubernetes - Concept","img":"/post_image/thumbnail/spark-on-k8s-1.jpeg","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자."}}}]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"fb3c924f-4a7c-50c2-8404-09a28f1e98ec","excerpt":"오늘은 Spark의 성능 튜닝에 대해서 이야기 해 보겠습니다. Spark는 요약해서 말하면, in-memory(RAM 위에서)에서 작동 하는 분산 컴퓨팅을 쉽게 지원해 주는 프레임워크 입니다. in-memory 연산은 빠르지만, 불안정 합니다. 메모리 관리, CPU Core 수의 관리를 통해 Out of memory가 발생 하지 않는 선에서, Job이 성공적으로 수행 될 수 있도록 하여야 하며, 적절한 캐싱 전략, 직렬화, Executor…","frontmatter":{"date":"2023-04-07","tags":["Data-Engineering"],"path":"/data-engineering/spark-performance-tuning-1","title":"Spark 성능 튜닝 - 1. Partition, Shuffle","img":"/post_image/thumbnail/spark-performance-tuning-1.png","summary":"Spark에 성능 튜닝을 시도 해 보자."}}},{"node":{"id":"7611f6af-dc48-595b-8866-23beee4d5cda","excerpt":"저번 시간에는 Spark On Kubernetes에 대한 이론을 배웠습니다. 오늘은 Spark On Kubernetes에 대한 실습을 진행 하도록 하겠습니다. 사전 준비 Docker Minikube (Kubernetes 1.20 버전 이상) kubectl Spark 3.0 버전 이상 최신 버전일 수록 좋습니다. 얼마 전에 구형 Docker가 깔려 있는 맥북에서 진행을 해 봤는데 Pod이 생성이 안되더군요.. Pyspark Image Build…","frontmatter":{"date":"2023-03-30","tags":["Data-Engineering","Cloud-Computing"],"path":"/data-engineering/spark-on-k8s-2","title":"Spark on Kubernetes - Practice","img":"/post_image/thumbnail/spark-on-k8s-2.png","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자."}}},{"node":{"id":"3a543178-c1c9-5cfb-9c9e-b89aed5e8ead","excerpt":"안녕하세요? 오늘은 Kubernetes 환경에 JupyterHub를 설치 하는 방법에 대해서 알아 보도록 하겠습니다. Kubernetes Kubernetes는 컨테이너를 쉽고 빠르게 배포/확장하고 관리를 자동화해주는 Container Orchestration Tool 입니다. Kubernetes 시스템을 통해, 다음을 제공 받을 수 있습니다. 서비스 디스커버리와 로드 밸런싱: DNS 이름, 혹은 자체 IP…","frontmatter":{"date":"2023-03-25","tags":["Data-Engineering","Cloud-Computing"],"path":"/data-engineering/jupyterhub-on-k8s","title":"Jupyterhub on Kubernetes","img":"/post_image/thumbnail/jupyterhub-on-k8s.jpg","summary":"Jupyterhub를 Kubernetes Cluster에서 실행 해 보자."}}},{"node":{"id":"6108ea9c-22bb-5693-995b-aebd5cfb3bcf","excerpt":"Spark Apache Spark는 기존 Hadoop의 MapReduce 형태의 클러스터 컴퓨팅의 단점을 보완하기 위해 탄생한 프레임워크 입니다. 기존 하둡의 MapReduce에서는 Disk에서 데이터를 읽은 후, Mapping, Shuffling, Reducing의 과정을 거쳐서, 다시 Disk에 저장하는 형식으로 진행 되는데요, 이는 Disk I/O가 자주 발생 하기 때문에, 속도가 상대적으로 느리다는 단점이 있습니다. 하지만 Apache…","frontmatter":{"date":"2023-03-06","tags":["Data-Engineering","Cloud-Computing"],"path":"/data-engineering/spark-on-k8s-1","title":"Spark on Kubernetes - Concept","img":"/post_image/thumbnail/spark-on-k8s-1.jpeg","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자."}}}]}}}}},"staticQueryHashes":["234633779","63159454"]}