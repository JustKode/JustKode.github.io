{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-engineering/spark-operator-2/","result":{"data":{"markdownRemark":{"html":"<p>안녕하세요, 박민재입니다. 저번 시간에는 <strong>Spark Operator</strong>가 무엇인지 간단하게 알아 보았는데요, 이번 시간에는 실제로 <strong>Spark Operator Helm Chart를 설치</strong>하여, Spark Operator 관련 구동 준비를 한 후, <strong>Spark Operator 관련 Resource를 작성</strong> 하여 <strong>실제 Job을 제출</strong> 해 보는 시간을 가져 보도록 하겠습니다.</p>\n<h3>Spark Operator Helm Chart</h3>\n<p><strong>Spark Operator</strong>를 사용 하기 위해서는 저번 시간에 언급 드렸던 것처럼, Spark Operator Resource를 해석 할 수 있는 <strong>Component들이 먼저 구동</strong> 되어야 하고, 이를 통해 Cluster가 <code class=\"language-text\">SparkApplication</code> Resorce가 제출 되었을 때 <strong>Resource를 해석</strong> 할 수 있어야 합니다. 이를 위해 <strong>Spark Operator Component</strong>들을 Helm Chart를 통해 Cluster에 우선적으로 설치하는 작업이라고 이해해 주시면 됩니다.</p>\n<p>저번에 언급 드렸던, <strong>Controller, Submission Runner, Spark Pod Monitor, Mutating Admission Webhook</strong>이 이에 해당합니다.</p>\n<p align=\"center\">\n    <img src=\"/post_image/spark-operator/03.png\" width=\"600px\" />\n    <div align=\"center\" color=\"#aaaaaa\">Kubeflow Kubernetes Operator Architecture</div>\n</p>\n<p>Helm Chart를 설치 하기 전, 해당 버전의 <strong>Helm</strong>과 <strong>Kubernetes</strong>가 준비 되어야 합니다.</p>\n<ul>\n<li>Helm >= 3</li>\n<li>Kubernetes >= 1.16</li>\n</ul>\n<p>이 둘이 설치 되었다면, Helm Repository를 추가 하여 주고, Update를 수행 한 후, Kubernetes Cluster에 Operator를 설치 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">helm repo <span class=\"token function\">add</span> spark-operator https://kubeflow.github.io/spark-operator\nhelm repo update\n\n<span class=\"token comment\"># helm install [RELEASE_NAME] spark-operator/spark-operator</span>\nhelm <span class=\"token function\">install</span> spark-operator spark-operator/spark-operator <span class=\"token punctuation\">\\</span> \n    <span class=\"token parameter variable\">--namespace</span> spark-operator  <span class=\"token comment\"># namespace 지정 \\ </span>\n    --create-namespace  <span class=\"token comment\"># 해당 namespace를 생성 하며 Install</span></code></pre></div>\n<p>추가적으로 Helm Chart를 설치 할 때, <code class=\"language-text\">--set</code> 을 통해 Flag를 지정 하여 옵션을 추가 하여 줄 수 있습니다. 추가 할 수 있는 <a href=\"https://github.com/kubeflow/spark-operator/tree/master/charts/spark-operator-chart#values\">Value 관련 정보</a>는 다음을 확인 해 주세요.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">helm <span class=\"token function\">install</span> my-release spark-operator/spark-operator <span class=\"token punctuation\">\\</span> \n    <span class=\"token parameter variable\">--namespace</span> spark-operator <span class=\"token punctuation\">\\</span> \n    --create-namespace <span class=\"token punctuation\">\\</span> \n    <span class=\"token parameter variable\">--set</span> <span class=\"token assign-left variable\">webhook.enable</span><span class=\"token operator\">=</span>true</code></pre></div>\n<p>대표적으로 자주 사용 되는 Value들은 다음과 같습니다.</p>\n<ul>\n<li><code class=\"language-text\">webhook.enable</code>: Mutating Webhook을 활성화합니다.</li>\n<li><code class=\"language-text\">spark.jobNamespaces</code>: 실제 Spark Job을 수행하는 Pod이 할당 될 Namespace를 설정 합니다. (ex: <code class=\"language-text\">--set \"spark.jobNamespaces={test-namespace}\"</code>)</li>\n<li><code class=\"language-text\">image.repository</code>: Controller, WebHook 등에서 사용하는 Docker Image의 Repository를 기입 합니다.</li>\n<li><code class=\"language-text\">image.tag</code>: Controller, WebHook 등에서 사용하는 Docker Image의 Tag를 선택 합니다.</li>\n</ul>\n<h3>Spark Operator Resource</h3>\n<p>Helm Chart 설치가 완료 되었다면, 그 다음은 <code class=\"language-text\">SparkApplication</code> Resource를 등록 할 차례 입니다. YAML 파일을 작성 한 후에 이를 <code class=\"language-text\">kubectl</code>로 제출 하는 방식으로 주로 사용하는데요, 기본적인 틀은 다음과 같습니다.</p>\n<p>아래와 같이 Spark Application 관련 정보를 입력 하여 주면, 이를 <code class=\"language-text\">spark-submit</code> 으로 변환하여 제출 해 줍니다. 그 이후, Spark Pod Monitor를 통해 Application 상태를 모니터링 하는 방식입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> sparkoperator.k8s.io/v1beta2\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> SparkApplication\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> spark<span class=\"token punctuation\">-</span>pi\n  <span class=\"token key atrule\">namespace</span><span class=\"token punctuation\">:</span> default\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> Scala\n  <span class=\"token key atrule\">mode</span><span class=\"token punctuation\">:</span> cluster\n  <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> spark<span class=\"token punctuation\">:</span>3.5.1\n  <span class=\"token key atrule\">mainClass</span><span class=\"token punctuation\">:</span> org.apache.spark.examples.SparkPi\n  <span class=\"token key atrule\">mainApplicationFile</span><span class=\"token punctuation\">:</span> local<span class=\"token punctuation\">:</span>///opt/spark/examples/jars/spark<span class=\"token punctuation\">-</span>examples_2.12<span class=\"token punctuation\">-</span>3.5.1.jar</code></pre></div>\n<ul>\n<li><code class=\"language-text\">spec.type</code>: <strong>Java, Python, R, Scala</strong> 등 <strong>Application의 종류</strong>를 입력 합니다.</li>\n<li><code class=\"language-text\">spec.mode</code>: client, cluster, in-cluster-client 등, <strong>Deploy 방식을 선택</strong> 할 수 있습니다. 현재 안정적으로 제공 하는 DeployMode는 cluster가 유일 하기 때문에 <strong>cluster</strong> 모드로 설정 하는 것을 권장합니다.</li>\n<li><code class=\"language-text\">spec.image</code>: Driver, Executor, inin-container의 <strong>Image를 지정</strong>합니다.</li>\n<li><code class=\"language-text\">spec.mainClass</code>: Java/Scala Application의 <strong>MainClass를 지정</strong> 합니다.</li>\n<li><code class=\"language-text\">spec.mainApplicationFile</code>: Application의 <strong>파일 경로를 지정</strong>합니다. Hadoop 관련 설정이 완료 되었다면, HDFS 내의 파일도 접근 가능합니다.</li>\n</ul>\n<h4>Application Dependencies</h4>\n<p>Application에 대한 <strong>의존성 추가</strong>를 위해서는 다음과 같은 옵션을 추가하여 주면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">deps</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">jars</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> local<span class=\"token punctuation\">:</span>///opt/spark<span class=\"token punctuation\">-</span>jars/gcs<span class=\"token punctuation\">-</span>connector.jar\n    <span class=\"token key atrule\">files</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> gs<span class=\"token punctuation\">:</span>//spark<span class=\"token punctuation\">-</span>data/data<span class=\"token punctuation\">-</span>file<span class=\"token punctuation\">-</span>1.txt\n      <span class=\"token punctuation\">-</span> gs<span class=\"token punctuation\">:</span>//spark<span class=\"token punctuation\">-</span>data/data<span class=\"token punctuation\">-</span>file<span class=\"token punctuation\">-</span>2.txt\n    <span class=\"token key atrule\">repositories</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> https<span class=\"token punctuation\">:</span>//repository.example.com/prod\n    <span class=\"token key atrule\">packages</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> com.example<span class=\"token punctuation\">:</span>some<span class=\"token punctuation\">-</span>package<span class=\"token punctuation\">:</span>1.0.0\n    <span class=\"token key atrule\">excludePackages</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> com.example<span class=\"token punctuation\">:</span>other<span class=\"token punctuation\">-</span>package\n    <span class=\"token punctuation\">...</span></code></pre></div>\n<ul>\n<li><code class=\"language-text\">spec.deps.jars</code>: Application에 <strong>Jar File로 Dependency를 추가</strong> 합니다. <code class=\"language-text\">spark-submit</code>의 <code class=\"language-text\">--jars</code> Option에 해당 합니다.</li>\n<li><code class=\"language-text\">spec.deps.files</code>: Application에 <strong>File을 추가</strong> 합니다. <code class=\"language-text\">spark-submit</code>의 <code class=\"language-text\">--files</code> Option에 해당 합니다.</li>\n<li><code class=\"language-text\">spec.deps.repostories</code>: <strong>설치할 Package가 있는 Repository</strong>를 지정 합니다.</li>\n<li><code class=\"language-text\">spec.deps.packages</code>: <strong>설치할 Package</strong>를 지정 합니다.</li>\n<li><code class=\"language-text\">spec.deps.excludePackages</code>: Package 설치 과정에서 함께 설치되는 Package 중 <strong>설치에서 제외할 Package</strong>를 지정 합니다.</li>\n</ul>\n<h4>Spark Configuration</h4>\n<p><strong>Spark Configuration</strong>은 <code class=\"language-text\">spec.sparkConf</code> 하위에 삽입 하여 설정 할 수 있습니다. 참고로 Type 관련 설정 때문에, <code class=\"language-text\">spec.sparkConf</code> 하위에 있는 모든 Key의 Value는 <code class=\"language-text\">string</code> 이어야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">sparkConf</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">spark.ui.port</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"4045\"</span>\n    <span class=\"token key atrule\">spark.eventLog.enabled</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"true\"</span>\n    <span class=\"token key atrule\">spark.eventLog.dir</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"hdfs://hdfs-namenode-1:8020/spark/spark-events\"</span>\n  <span class=\"token punctuation\">...</span></code></pre></div>\n<h4>Driver + Executor Spec</h4>\n<p>Driver와 Executor Spec은 다음과 같이 설정 해 줄 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">driver</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">cores</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n    <span class=\"token key atrule\">coreLimit</span><span class=\"token punctuation\">:</span> 200m\n    <span class=\"token key atrule\">memory</span><span class=\"token punctuation\">:</span> 512m\n    <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">version</span><span class=\"token punctuation\">:</span> 3.1.1\n    <span class=\"token key atrule\">serviceAccount</span><span class=\"token punctuation\">:</span> spark\n    <span class=\"token key atrule\">javaOptions</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap\"</span>\n  <span class=\"token key atrule\">executor</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">cores</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n    <span class=\"token key atrule\">instances</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n    <span class=\"token key atrule\">memory</span><span class=\"token punctuation\">:</span> 512m\n    <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">version</span><span class=\"token punctuation\">:</span> 3.1.1\n    <span class=\"token key atrule\">serviceAccount</span><span class=\"token punctuation\">:</span> spark\n    <span class=\"token key atrule\">javaOptions</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap\"</span>\n    <span class=\"token punctuation\">...</span></code></pre></div>\n<p>공통적인 옵션들은 다음과 같습니다.</p>\n<ul>\n<li><code class=\"language-text\">cores</code>: 하나의 Instance에 몇개의 Core를 할당 할지 설정 합니다. Instance는 Pod으로 할당 됩니다.</li>\n<li><code class=\"language-text\">memory</code>: 하나의 Instance에 얼마만큼의 Memory를 할당 할지 설정 합니다. Instance는 Pod으로 할당 됩니다.</li>\n<li><code class=\"language-text\">coreLimit</code>: Pod별 CPU core를 얼마만큼으로 제한할 지 설정 합니다.</li>\n<li><code class=\"language-text\">memoryOverhead</code>: off-heap Memory를 얼마만큼 할당할 지 설정 합니다.</li>\n<li><code class=\"language-text\">serviceAccount</code>: 어떤 Service Account로 Pod을 할당 할지 설정 합니다.</li>\n<li><code class=\"language-text\">javaOptions</code>: Java Options를 설정 합니다.</li>\n<li><code class=\"language-text\">image</code>: 어떤 이미지를 사용 할 지 설정 합니다.</li>\n</ul>\n<p>그 외에도 Env, ConfigMap, Secret, Volume, Pod Affinity 등 또한 설정 해 줄 수 있는데요, 해당 내용은 <a href=\"https://www.kubeflow.org/docs/components/spark-operator/user-guide/writing-sparkapplication/#specifying-environment-variables\">공식 Document 주소</a>로 갈음 하도록 하겠습니다.</p>\n<p>YAML 파일이 작성이 되었다면 다음과 같이 <code class=\"language-text\">kubectl</code> 로 제출 할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">kubectl apply <span class=\"token parameter variable\">-f</span> your-app.yaml</code></pre></div>\n<p><code class=\"language-text\">kubectl describe</code>를 통해 다음과 같이 Application의 상태를 확인 할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">kubectl describe sparkapplication [YOUR APPLICATION]\n\nEvents:\n  Type    Reason                      Age   From            Message\n  ----    ------                      ----  ----            -------\n  Normal  SparkApplicationAdded       5m    spark-operator  SparkApplication spark-pi was added, enqueued it for submission\n  Normal  SparkApplicationTerminated  4m    spark-operator  SparkApplication spark-pi terminated with state: COMPLETED</code></pre></div>\n<p>다음 시간에는 <strong>Spark Operator의 고가용성</strong>을 위한 설정, <strong>Scheduling 등의 방법</strong>에 대해서 알아 보도록 하겠습니다.</p>","id":"24718dd5-aa23-578b-aa81-0ca11fcc0f06","frontmatter":{"date":"2025-02-02","path":"/data-engineering/spark-operator-2","title":"Spark Operator - 2. Practice","tags":["Data-Engineering"],"keyword":"Spark, Spark on K8S, Kubernetes, Spark Operator","summary":"Spark Operator를 사용 해 보자.","img":"/post_image/thumbnail/spark-operator.jpg","series":"Spark On Kubernetes"}}},"pageContext":{"postPath":"/data-engineering/spark-operator-2","series":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"24718dd5-aa23-578b-aa81-0ca11fcc0f06","excerpt":"안녕하세요, 박민재입니다. 저번 시간에는 Spark Operator가 무엇인지 간단하게 알아 보았는데요, 이번 시간에는 실제로 Spark Operator Helm Chart를 설치하여, Spark Operator 관련 구동 준비를 한 후, Spark Operator 관련 Resource를 작성 하여 실제 Job을 제출 해 보는 시간을 가져 보도록 하겠습니다. Spark Operator Helm Chart Spark Operator…","frontmatter":{"date":"2025-02-02","tags":["Data-Engineering"],"path":"/data-engineering/spark-operator-2","title":"Spark Operator - 2. Practice","img":"/post_image/thumbnail/spark-operator.jpg","summary":"Spark Operator를 사용 해 보자."}}},{"node":{"id":"9ec3e659-5978-5311-b4d5-fc9d0902e008","excerpt":"안녕하세요, 박민재입니다. 아마 2년 전 즈음에 Spark on Kubernetes 관련 내용을 다뤘었는데요 (이 글 또한, 개정판을 작성 해 볼게요), 이번에는 Spark Job을 Kubernetes Cluster에 편리하게 제출할 수 있게 하는 Spark Operator에 대해 알아 보도록 하겠습니다. Spark on Kubernetes를 사용하는 이유? 그렇다고, 이 글에서 아예 설명 하지 않고 넘어가는 것은 아닌 것 같아, Spark…","frontmatter":{"date":"2025-01-19","tags":["Data-Engineering"],"path":"/data-engineering/spark-operator-1","title":"Spark Operator - 1. Spark Operator란?","img":"/post_image/thumbnail/spark-operator.jpg","summary":"Kubernetes Cluster로의 Spark Job 제출을 도와주는 Spark Operator가 무엇 인지 알아보자."}}},{"node":{"id":"28baf728-0bd2-5147-9ef0-b05da0826d77","excerpt":"저번 시간에는 Spark On Kubernetes에 대한 이론을 배웠습니다. 오늘은 Spark On Kubernetes에 대한 실습을 진행 하도록 하겠습니다. 사전 준비 Docker Minikube (Kubernetes 1.20 버전 이상) kubectl Spark 3.0 버전 이상 최신 버전일 수록 좋습니다. 얼마 전에 구형 Docker가 깔려 있는 맥북에서 진행을 해 봤는데 Pod이 생성이 안되더군요.. Pyspark Image Build…","frontmatter":{"date":"2023-03-30","tags":["Data-Engineering","Cloud-Computing"],"path":"/data-engineering/spark-on-k8s-2","title":"Spark on Kubernetes - Practice","img":"/post_image/thumbnail/spark-on-k8s-2.png","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자."}}},{"node":{"id":"159ef5da-bcc6-5cdb-bb70-0d8a76f3cb69","excerpt":"Spark Apache Spark는 기존 Hadoop의 MapReduce 형태의 클러스터 컴퓨팅의 단점을 보완하기 위해 탄생한 프레임워크 입니다. 기존 하둡의 MapReduce에서는 Disk에서 데이터를 읽은 후, Mapping, Shuffling, Reducing의 과정을 거쳐서, 다시 Disk에 저장하는 형식으로 진행 되는데요, 이는 Disk I/O가 자주 발생 하기 때문에, 속도가 상대적으로 느리다는 단점이 있습니다. 하지만 Apache…","frontmatter":{"date":"2023-03-06","tags":["Data-Engineering","Cloud-Computing"],"path":"/data-engineering/spark-on-k8s-1","title":"Spark on Kubernetes - Concept","img":"/post_image/thumbnail/spark-on-k8s-1.jpeg","summary":"Spark를 Kubernetes Cluster에서 동작 시켜 보자."}}}]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"24718dd5-aa23-578b-aa81-0ca11fcc0f06","excerpt":"안녕하세요, 박민재입니다. 저번 시간에는 Spark Operator가 무엇인지 간단하게 알아 보았는데요, 이번 시간에는 실제로 Spark Operator Helm Chart를 설치하여, Spark Operator 관련 구동 준비를 한 후, Spark Operator 관련 Resource를 작성 하여 실제 Job을 제출 해 보는 시간을 가져 보도록 하겠습니다. Spark Operator Helm Chart Spark Operator…","frontmatter":{"date":"2025-02-02","tags":["Data-Engineering"],"path":"/data-engineering/spark-operator-2","title":"Spark Operator - 2. Practice","img":"/post_image/thumbnail/spark-operator.jpg","summary":"Spark Operator를 사용 해 보자."}}},{"node":{"id":"9ec3e659-5978-5311-b4d5-fc9d0902e008","excerpt":"안녕하세요, 박민재입니다. 아마 2년 전 즈음에 Spark on Kubernetes 관련 내용을 다뤘었는데요 (이 글 또한, 개정판을 작성 해 볼게요), 이번에는 Spark Job을 Kubernetes Cluster에 편리하게 제출할 수 있게 하는 Spark Operator에 대해 알아 보도록 하겠습니다. Spark on Kubernetes를 사용하는 이유? 그렇다고, 이 글에서 아예 설명 하지 않고 넘어가는 것은 아닌 것 같아, Spark…","frontmatter":{"date":"2025-01-19","tags":["Data-Engineering"],"path":"/data-engineering/spark-operator-1","title":"Spark Operator - 1. Spark Operator란?","img":"/post_image/thumbnail/spark-operator.jpg","summary":"Kubernetes Cluster로의 Spark Job 제출을 도와주는 Spark Operator가 무엇 인지 알아보자."}}},{"node":{"id":"2001438a-fe37-5b3c-8954-bce7d5e18a7a","excerpt":"안녕하세요? 박민재입니다. 오늘은 Iceberg Table을 관리하는 방법 중 하나인, Branching & Tagging 그리고 Rollback Action에 대해서 알아 보도록 하겠습니다. Isolation of Changes with Branches Iceberg에서는 git과 같은 방식으로 Branch를 만들어, 데이터 변경 사항을 관리 할 수 있습니다. 우리의 사례로 빗대어 보면 H/W 이슈, 혹은 Application…","frontmatter":{"date":"2025-01-03","tags":["Data-Engineering"],"path":"/data-engineering/iceberg-table-management-2","title":"Iceberg Table Management - 2. Branching, Tagging & Rollback","img":"/post_image/thumbnail/iceberg-table-management.png","summary":"Branching, Tagging & Rollback을 통해 Iceberg Table을 관리 해 보자"}}},{"node":{"id":"dcd44de2-0eff-56f8-ac2d-2a99250ab9cf","excerpt":"안녕하세요? 박민재입니다. 오늘은 Iceberg Table을 관리하는 방법을 Metadata Table의 사용을 중심으로 깊게 알아 보도록 하겠습니다. Apache Iceberg의 경우에는 Metadata Table 기능을 매우 강력하게 지원합니다. 이를 통해 Iceberg Table을 운영을 쉽게 수행 할 수 있죠. 예를 들어, Table의 Evolution이 어떻게 진행 되었는지, 파일들이 어떻게 Partitioning…","frontmatter":{"date":"2024-12-05","tags":["Data-Engineering"],"path":"/data-engineering/iceberg-table-management-1","title":"Iceberg Table Management - 1. Metadata Table ","img":"/post_image/thumbnail/iceberg-table-management.png","summary":"Metadata Table을 통해 Iceberg Table을 관리 해 보자"}}}]}}}}},"staticQueryHashes":["3819017183","63159454"],"slicesMap":{}}