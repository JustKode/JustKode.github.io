{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-engineering/airflow-db-management/","result":{"data":{"markdownRemark":{"html":"<p>안녕하세요, 박민재입니다. 오늘은 <strong>Airflow DB를 관리</strong>하는 방법에 대해서 이야기 나눠 보도록 하겠습니다.</p>\n<h3>Airflow Backend Database</h3>\n<p><strong>Airflow</strong>에서 <strong>Backend Database</strong>는 어떤 역할을 할까요? Airflow에서 DAG을 실행 하기 위해서, Airflow는 다음과 같은 정보들을 Backend Database에 저장하여 <strong>정합성</strong>을 유지 합니다.</p>\n<ul>\n<li>DagRun: 특정 Interval에 실행 된 <strong>DagRun</strong>의 정보. <code class=\"language-text\">dag_id</code>, <code class=\"language-text\">logical_date</code>, <code class=\"language-text\">start_date</code>, <code class=\"language-text\">status</code> 등을 담고 있습니다.</li>\n<li>Task Instance: 특정 DagRun 내에서 실행 된 <strong>각 Task의 정보</strong>. <code class=\"language-text\">task_id</code>, <code class=\"language-text\">logical_date</code>, <code class=\"language-text\">status</code> 등을 담고 있습니다.</li>\n<li>XCom: Task간 <strong>데이터를 주고 받기 위해 사용하는 정보</strong>로, <code class=\"language-text\">task_id</code>, <code class=\"language-text\">logical_date</code>, <code class=\"language-text\">value</code> 로 이루어져 있습니다.</li>\n</ul>\n<p>이 외에도 Airflow를 운영하기 위한 <strong>Audit Log, DAG 정보, Role, Pool 등</strong>의 정보들을 담고 있습니다. 이 데이터들은 상호간의 정합성을 유지 하여야 하기 때문에, NoSQL이 아닌 <strong>Postgre, MySQL 등과 같은 RDBMS로 지원</strong> 하고 있죠.</p>\n<h3>시간은 흐르고, 데이터는 쌓인다.</h3>\n<p>하지만 시간이 지남에 따라서, RDBMS에 데이터가 계속 쌓이게 되면, 우리는 관리를 해줘야 하는 포인트에 도달하게 됩니다. 아까도 말씀 드렸다 싶이, <strong>Metadata의 정합성을 위해 RDBMS에 데이터를 쌓게</strong> 되는데요. <strong>DagRun, Task Instance</strong> 같은 정보들은 Airflow Scheduler에서 <strong>자주 사용 해야 하는 데이터</strong>인 이유로 <strong>Indexing</strong>을 수행 하는데요. 이는 DB에 더 많은 Disk 용량을 사용하게 됩니다.</p>\n<p>저의 경우에는 광고 조직 전체에서 사용하는, 수백개의 DAG이 운용 되고 있는 Airflow의 운영 관리를 맡고 있다 보니, Metadata 규모에 대한 압박이 가해져 이렇게 Metadata를 정리하는 업무를 수행하게 되었어요.</p>\n<h3>데이터를 지우기 전에</h3>\n<p>만약 MySQL, PostgreSQL 같은 RDBMS를 사용하고 있다면, <strong>MySQL에는 binlog, PostgreSQL 같은 경우는 wal log</strong>를 확인 해 보세요. MySQL의 binlog는 MySQL <strong>서버 인스턴스의 데이터 변경 사항 정보</strong>들을 담고 있는데요, Airflow는 DagRun, Task Instance, Log 등의 정보를 <strong>쉴 새 없이 변경</strong> 하기 때문에, 다른 사용 사례에 비해서 <strong>binlog가 매우 많이 쌓이게 됩니다.</strong> 그렇기 때문에, binlog / wal log 등이 현재 RDBMS Node에 많은 양이 쌓여 있는지 확인 할 필요가 있어요.</p>\n<h3>그럼에도 불구하고 데이터가 많다면...</h3>\n<p>그러면 이제 데이터를 정리 해야할 시간이 온 것 입니다. Airflow 에서는 2.3 버전부터 <code class=\"language-text\">airflow db clean</code> 라는 기능을 제공 합니다. 요약 하자면, 특정 timestamp 이전에 생성 된 데이터에 대해서, 기간을 지정한 후 삭제를 진행 하는 거에요. <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/cli-and-env-variables-ref.html#clean\">ref</a></p>\n<p>사용 예시는 다음과 같아요. <code class=\"language-text\">--clean-before-timestamp</code> 파라미터에는 삭제 하려고 하는 해당 시간을 삽입하고, <code class=\"language-text\">--t</code> 파라미터에는 Table을 삽입 하여 주는 거에요. <code class=\"language-text\">--dry-run</code> 옵션으로 실행 전 몇개의 레코드가 삭제 될 지 확인 할 수 있어요.  <code class=\"language-text\">--y</code>는 직접 데이터를 삽입 하는 거구요.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ airflow db clean --clean-before-timestamp <span class=\"token string\">'2023-06-28 00:00:00'</span> <span class=\"token parameter variable\">--t</span> <span class=\"token string\">'logs'</span> --dry-run  <span class=\"token comment\"># dry-run</span>\n$ airflow db clean --clean-before-timestamp <span class=\"token string\">'2023-06-28 00:00:00'</span> <span class=\"token parameter variable\">--t</span> <span class=\"token string\">'logs'</span> <span class=\"token parameter variable\">--y</span>  <span class=\"token comment\"># execute</span></code></pre></div>\n<p>Metadata를 정리 하기 위해서, 어떤 Table이 주로 사용되는 지, 어떤 Data를 삭제 하여도 무방한 지 알아야 겠죠? 대부분은 <code class=\"language-text\">logs</code>, <code class=\"language-text\">task_instance</code>, <code class=\"language-text\">dag_run</code>, <code class=\"language-text\">xcom</code> 순으로 많이 사용 됩니다.</p>\n<p>하지만 직접 확인 해보는 것이 좋겠죠? 각자의 Airflow 마다 사용 사례는 다르니까요.</p>\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">SELECT</span> table_name <span class=\"token keyword\">AS</span> <span class=\"token string\">'TableName'</span><span class=\"token punctuation\">,</span>\n                 <span class=\"token function\">ROUND</span><span class=\"token punctuation\">(</span><span class=\"token function\">SUM</span><span class=\"token punctuation\">(</span>data_length<span class=\"token operator\">+</span>index_length<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token punctuation\">(</span><span class=\"token number\">1024</span><span class=\"token operator\">*</span><span class=\"token number\">1024</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">AS</span> <span class=\"token string\">'All(MB)'</span><span class=\"token punctuation\">,</span>\n                 <span class=\"token function\">ROUND</span><span class=\"token punctuation\">(</span>data_length<span class=\"token operator\">/</span><span class=\"token punctuation\">(</span><span class=\"token number\">1024</span><span class=\"token operator\">*</span><span class=\"token number\">1024</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">AS</span> <span class=\"token string\">'Data(MB)'</span><span class=\"token punctuation\">,</span>\n                 <span class=\"token function\">ROUND</span><span class=\"token punctuation\">(</span>index_length<span class=\"token operator\">/</span><span class=\"token punctuation\">(</span><span class=\"token number\">1024</span><span class=\"token operator\">*</span><span class=\"token number\">1024</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">AS</span> <span class=\"token string\">'Index(MB)'</span>\n<span class=\"token keyword\">FROM</span> information_schema<span class=\"token punctuation\">.</span><span class=\"token keyword\">tables</span>\n<span class=\"token keyword\">GROUP</span> <span class=\"token keyword\">BY</span> table_name\n<span class=\"token keyword\">ORDER</span> <span class=\"token keyword\">BY</span> data_length <span class=\"token keyword\">DESC</span><span class=\"token punctuation\">;</span> </code></pre></div>\n<h4>logs</h4>\n<p>먼저 <code class=\"language-text\">logs</code> 테이블 입니다. 해당 Table은 <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/security/audit_logs.html\">Audit Log</a>에 해당 하는 데이터입니다. <strong>DAG, Task의 추가/수정/삭제</strong>의 기록, <strong>Task의 success, failed, clear 여부</strong> 등등을 가지고 있어, <strong>보안 위반 사항등을 감지 하거나, 문제가 발생 시 해당 문제를 파악</strong>하는 데도 도움이 돼요. 하지만, 이는 Airflow Scheduling에서 정합성을 맞추는데 사용하지 않기 때문에, 너무 오래 된 log들은 삭제 하여도 무방합니다.</p>\n<h4>xcom</h4>\n<p>그 다음은 <code class=\"language-text\">xcom</code> 테이블 입니다. 해당 Table은 XCom에 해당 합니다. <strong>동일 DAG내의 Task간 Variable을 공유</strong> 하는데 사용 하죠. 하지만, 사용자가 <strong>XCom에 큰 용량 (물론 64kb 제한이 기본으로 되어 있지만)의 변수 공유를 주기적</strong>으로 하게 된다면, 이 또한 문제가 될 것입니다. 그렇기 때문에 Task 단위 재처리가 필요하지 않은, <strong>오래된 DAG Run에 있는 XCom 데이터인 경우 삭제</strong> 해 줘도 무방합니다. 당연히, 실행 중인 DAG Run의 XCom을 삭제한다면 문제가 있겠죠? 만약 사용하는 XCom의 크기를 어쩔 수 없이 크게 운영 되어야 한다면, <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/xcoms.html#object-storage-xcom-backend\">Custom XCom Backend</a>를 사용 하는 것도 방법입니다.</p>\n<h4>task_instance, dag_run</h4>\n<p>마지막으로 <code class=\"language-text\">task_instance</code>, <code class=\"language-text\">dag_run</code> 테이블 입니다. 각각 <strong>Task Instance 정보, DAG Run 정보에 해당</strong>하며, Airflow <strong>Scheduling에 직접적인 영향</strong>을 주는 친구이기 때문에 삭제 하는데 조심 하여야 합니다.</p>\n<p>하지만 <code class=\"language-text\">task_instance</code> 가 DB에서 차지하는 Size가 많기 때문에, 삭제를 하는 것은 필연적인데요, 어떻게 하면 좋을까요? 이를 위해 몇 개의 Test를 진행 해 보았습니다. Task가 하나만 존재 하는 Test DAG을 생성 후, 30개의 DAG Run을 수행 해 보았습니다.</p>\n<p>우선, DagRun을 삭제하지 않은 채로, Task Instance를 <code class=\"language-text\">airflow db clean</code> 으로 삭제 해 보았습니다.</p>\n<p>결과는 다음과 같이, Task에 대한 정보는 삭제 되었지만, <strong>삭제 된 Task에 대해서 재수행을 하지 않았습니다.</strong> DAG Run은 Success 상태이기 때문에, Task가 다시 Trigger 되지 않은 모습입니다.</p>\n<p align=\"center\">\n    <img src=\"/post_image/airflow-db-management/01.png\" style=\"width:70%;max-width:768px;\"/>\n</p>\n<p>그 다음으로, DAG Run 또한 <code class=\"language-text\">airflow db clean</code> 으로 삭제를 진행 해 보았는데요. <strong>Airflow Scheduler는 DAG Run이 Clear가 되지 않는 이상, 가장 최신의 DAG Run을 바탕으로 다음에 수행할 DAG Run을 결정</strong>합니다. 그렇기 때문에, 과거의 DAG Run이 다시 Trigger 되지 않는 모습을 보입니다.</p>\n<p align=\"center\">\n    <img src=\"/post_image/airflow-db-management/02.png\" style=\"width:70%;max-width:768px;\"/>\n</p>\n<p>그렇다면, 전체 DAG Run을 지우려고 시도 하면 어떻게 될까요? <code class=\"language-text\">airflow db clean</code> 은 <strong>가장 최신의 DAG Run만 남기고 전체 삭제</strong>를 수행 합니다. 그렇기 때문에, 지금 ON 상태인 DAG의 Scheduling은 문제가 없이 작동 합니다.</p>\n<p align=\"center\">\n    <img src=\"/post_image/airflow-db-management/03.png\" style=\"width:70%;max-width:768px;\"/>\n</p>\n<h3>마지막으로</h3>\n<p>아 물론, <code class=\"language-text\">airflow db clean</code>은 Airflow Scheduler가 동작하는 DB에 직접 수행하는 것이니, <strong>DB Backup을 가능한 반드시 수행</strong> 해 주고 실행 하는것을 추천 드립니다. 또한, DB에 부하가 갈 수도 있으니, <strong>Airflow Task가 많이 Trigger 되지 않는 시간</strong>에 수행 하는 것을 추천 드립니다.</p>\n<h3>Reference</h3>\n<ul>\n<li><a href=\"https://airflow.apache.org/docs/apache-airflow/stable/howto/usage-cli.html#purge-history-from-metadata-database\">https://airflow.apache.org/docs/apache-airflow/stable/howto/usage-cli.html#purge-history-from-metadata-database</a></li>\n</ul>","id":"6eaa7aeb-a4fe-5cd9-bbe5-309dde97514b","frontmatter":{"date":"2024-10-27","path":"/data-engineering/airflow-db-management","title":"Airflow Backend Database Management (airflow db clean)","tags":["Data-Engineering"],"keyword":"Airflow, Airflow Database, Airflow Backend Database","summary":"Airflow의 Backend Database를 관리 하는 법","img":"/post_image/thumbnail/airflow-db-management.webp","series":null}}},"pageContext":{"postPath":"/data-engineering/airflow-db-management","series":{"data":{"allMarkdownRemark":{"edges":[]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"9ec3e659-5978-5311-b4d5-fc9d0902e008","excerpt":"안녕하세요, 박민재입니다. 아마 2년 전 즈음에 Spark on Kubernetes 관련 내용을 다뤘었는데요 (이 글 또한, 개정판을 작성 해 볼게요), 이번에는 Spark Job을 Kubernetes Cluster에 편리하게 제출할 수 있게 하는 Spark Operator에 대해 알아 보도록 하겠습니다. Spark on Kubernetes를 사용하는 이유? 그렇다고, 이 글에서 아예 설명 하지 않고 넘어가는 것은 아닌 것 같아, Spark…","frontmatter":{"date":"2025-01-19","tags":["Data-Engineering"],"path":"/data-engineering/spark-operator-1","title":"Spark Operator - 1. Spark Operator란?","img":"/post_image/thumbnail/spark-operator.jpg","summary":"Kubernetes Cluster로의 Spark Job 제출을 도와주는 Spark Operator가 무엇 인지 알아보자."}}},{"node":{"id":"2001438a-fe37-5b3c-8954-bce7d5e18a7a","excerpt":"안녕하세요? 박민재입니다. 오늘은 Iceberg Table을 관리하는 방법 중 하나인, Branching & Tagging 그리고 Rollback Action에 대해서 알아 보도록 하겠습니다. Isolation of Changes with Branches Iceberg에서는 git과 같은 방식으로 Branch를 만들어, 데이터 변경 사항을 관리 할 수 있습니다. 우리의 사례로 빗대어 보면 H/W 이슈, 혹은 Application…","frontmatter":{"date":"2025-01-03","tags":["Data-Engineering"],"path":"/data-engineering/iceberg-table-management-2","title":"Iceberg Table Management - 2. Branching, Tagging & Rollback","img":"/post_image/thumbnail/iceberg-table-management.png","summary":"Branching, Tagging & Rollback을 통해 Iceberg Table을 관리 해 보자"}}},{"node":{"id":"dcd44de2-0eff-56f8-ac2d-2a99250ab9cf","excerpt":"안녕하세요? 박민재입니다. 오늘은 Iceberg Table을 관리하는 방법을 Metadata Table의 사용을 중심으로 깊게 알아 보도록 하겠습니다. Apache Iceberg의 경우에는 Metadata Table 기능을 매우 강력하게 지원합니다. 이를 통해 Iceberg Table을 운영을 쉽게 수행 할 수 있죠. 예를 들어, Table의 Evolution이 어떻게 진행 되었는지, 파일들이 어떻게 Partitioning…","frontmatter":{"date":"2024-12-05","tags":["Data-Engineering"],"path":"/data-engineering/iceberg-table-management-1","title":"Iceberg Table Management - 1. Metadata Table ","img":"/post_image/thumbnail/iceberg-table-management.png","summary":"Metadata Table을 통해 Iceberg Table을 관리 해 보자"}}},{"node":{"id":"cbb6e851-d864-5552-86d7-08c81b4a54cc","excerpt":"Intro 안녕하세요, 박민재입니다. 저번 시간에는 Table Optimization을 위한 압축 기법에 대해 배웠습니다. 이번 시간에는 압축을 제외한 Table Optimization 기법을 알아 보도록 하겠습니다. Partitioning 역시, 기존의 방법을 꺼낼 때가 왔습니다. 바로 Partitioning입니다. 동일한 Column의 동일한 Value를 가진 친구들은 같은 File로 묶어 주는 방식이죠. 어? 왜 Directory…","frontmatter":{"date":"2024-11-24","tags":["Data-Engineering"],"path":"/data-engineering/iceberg-table-optimization-2","title":"Iceberg Table의 성능 최적화 - 2. Partitioning, MOR, Others","img":"/post_image/thumbnail/iceberg-table-optimization-1.webp","summary":"File Merge를 통한 성능 최적화에 대해 알아보자."}}}]}}}}},"staticQueryHashes":["3819017183","63159454"],"slicesMap":{}}