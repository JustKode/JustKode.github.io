{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-engineering/hdfs-architecture/","result":{"data":{"markdownRemark":{"html":"<p>안녕하세요? 오늘은 <strong>HDFS</strong>의 <strong>Architecture</strong>에 대해서 알아 보도록 하겠습니다. <strong>Hadoop Distributed File System(HDFS)</strong> 는 상용 하드웨어에서 동작하게 만든 오픈소스 SW입니다. 장애 발생에 강하며, 저비용 하드웨어 안에서도, 잘 작동 하게 설계 되었습니다. 또한, <strong>많은 데이터 셋을 지닌 어플리케이션에 적합</strong>하며, <strong>높은 throughput</strong>을 가지고 있습니다.</p>\n<p align=\"center\">\n\t<img src=\"/post_image/thumbnail/hdfs-architecture.png\" width=\"80%\"/>\n\t<p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\tHDFS 구성\n\t</p>\n</p>\n<h3>Assumptions and Goals</h3>\n<p>HDFS는 다음과 같은 것들을 <strong>가정</strong>하고, 그에 맞는 <strong>목표</strong>들을 가지고 있습니다.</p>\n<ul>\n<li><strong>Hardware Failure</strong>\n<ul>\n<li>많은 수의 component로 제작된 클러스터 라면, 일부 component는 작동하지 않을 것을 의미합니다.</li>\n<li>그렇기에, <strong>빠른 이상 감지</strong>와, <strong>빠르고 정확한 복구</strong>가 HDFS의 핵심입니다.</li>\n</ul>\n</li>\n<li><strong>Streaming Data Access</strong>\n<ul>\n<li>HDFS를 사용하는 어플리케이션은 <strong>streaming access</strong>의 방식을 주로 사용 합니다.</li>\n<li>HDFS는 <strong>batch processing을 위해 설계</strong> 되었습니다. low latency보단, <strong>high throughput</strong>에 중점을 둡니다.</li>\n</ul>\n</li>\n<li><strong>Large Data Sets</strong>\n<ul>\n<li>HDFS를 사용하는 어플리케이션은 <strong>많은 데이터를 다룹니다.</strong> 거의 테라 바이트 단위..</li>\n<li><strong>높은 집계 데이터 대역폭</strong>을 제공하고, 단일 클러스터에서 <strong>수백 개의 노드로 확장 가능</strong>하여, 단일 인스턴스는 <strong>수천만 개의 파일을 지원</strong>하도록 합니다.</li>\n</ul>\n</li>\n<li><strong>Simple Coherency Model (단순 일관성 모델)</strong>\n<ul>\n<li>HDFS 애플리케이션은, <strong>한 번 쓰고, 여러 번 읽는 액세스 모델</strong>이 권장 될니다.</li>\n<li>일단 생성되고 쓰여지고 닫힌 파일은 추가 및 자르기를 제외, <strong>변경 될 필요가 없습니다.</strong></li>\n<li>파일 끝 컨텐츠 추가는 가능하나, <strong>random access는 불가능</strong> 합니다.</li>\n<li>이는 데이터 일관성 문제를 단순화 시키며, 높은 처리량 데이터 액세스를 가능케 하여, <strong>MapReduce, Web Crawling</strong>에 최적화 시킵니다.</li>\n</ul>\n</li>\n<li><strong>“Moving Computation is Cheaper than Moving Data”</strong>\n<ul>\n<li>데이터 세트의 크기가 크면, <strong>데이터가 근처에 있을 때, 계산이 효과적</strong>입니다. (데이터의 지역성)</li>\n<li>이는 네트워크 정체를 최소화하며, <strong>시스템의 전체 처리량을 증가</strong> 시킨다.</li>\n<li>데이터를 응용 프로그램의 위치로 옮기는게 아닌, <strong>데이터가 있는 위치에 더 가깝게</strong> 계산을 마이그레이션 하는 것이 더 나은 경우가 많다고 가정합니다.</li>\n</ul>\n</li>\n<li><strong>Portability Across Heterogeneous Hardware and Software Platforms (H, S/W 플랫폼간 이식성)</strong>\n<ul>\n<li>한 플랫폼에서 다른 플랫폼으로 이동하기 쉽게 설계합니다.</li>\n</ul>\n</li>\n</ul>\n<h3>NameNode &#x26; DataNode</h3>\n<p>HDFS는 <strong>master/slave architecture</strong>를 가지고 있습니다. 요약하면 <strong>Namenode</strong>는 master 역할로, <strong>데이터를 관리하는 역할</strong>을, <strong>Datanode</strong>는 <strong>자신에게 할당된 데이터 블록을 처리</strong>하는 역할을 합니다.</p>\n<h4>NameNode</h4>\n<ul>\n<li><strong>마스터 서버</strong>의 역할을 합니다.</li>\n<li><strong>File system namespace</strong>와, <strong>클라이언트의 파일 액세스를 규제</strong>하는 역할을 담당 합니다.\n<ul>\n<li><strong>file system namespace</strong>의 변동 내역은 <strong>NameNode</strong>에 저장 됩니다.</li>\n<li><strong>replication factor</strong>에 대한 정보들 또한 <strong>보관</strong>하고 있습니다.</li>\n<li>블록 복제에 관한 모든 결정을 내리며, 클러스터의 <strong>각 DataNode에서 정기적으로 Heartbeat 및 Blockreport를 수신</strong> 합니다.</li>\n</ul>\n</li>\n<li>클러스터 내, <strong>단 한 개</strong>만 존재하며, <strong>고가용성</strong>을 위해, <strong>예비 NameNode</strong>도 만들어 놓는 것이 좋습니다.</li>\n<li>파일 열기, 닫기, 파일/폴더 이름 수정과 같은 <strong>operation</strong>을 수행 합니다.</li>\n<li>DataNode에 대한 <strong>블록의 Mapping</strong>도 결정 합니다.</li>\n</ul>\n<h4>DataNode</h4>\n<ul>\n<li>HDFS에서 파일이 저장 될 때, <strong>한 개 이상의 block</strong>으로 나누어 지고, 이들은 <strong>DataNode 들에 적재</strong> 됩니다.\n<ul>\n<li>그렇기 때문에, <strong>파일을 저장</strong> 할 때, <strong>적절한 Block 크기를 고려</strong> 하여야 합니다. 사용 하는 입장에서는 <strong>Block을 그대로 가져와 병렬 처리</strong>를 수행 할테니까요!</li>\n</ul>\n</li>\n<li>DataNode는 system’s clients의 <strong>파일을 읽고, 쓰는 역할</strong>을 합니다.\n<ul>\n<li>NameNode로 부터 온, <strong>block 생성, 삭제, 복제를 수행</strong> 합니다.</li>\n</ul>\n</li>\n<li>실제 배포에서는 DataNode를 한 곳에 때려 박지 않습니다. (여러 서버 렉에 저장)</li>\n</ul>\n<h3>The File System Namespace</h3>\n<ul>\n<li>HDFS는 <strong>전통적인 계층형 파일 구성을 지원</strong> 합니다.\n<ul>\n<li>즉, 폴더를 생성하고, 그 안에 파일을 집어 넣는 것이 가능 하다.</li>\n</ul>\n</li>\n<li>HDFS는 hard link와, soft link를 지원 하지 않지만, 배제 하지는 않습니다.</li>\n<li>naming도 대부분 비슷하게 지원 합니다만, <strong>몇 개의 경로와 이름은 예약</strong> 되어 있습니다. 이는 <strong>암호화, 스냅샷</strong>과 관련이 있습니다. (e.g. /.reserved and .snapshot)</li>\n</ul>\n<p align=\"center\">\n\t<img src=\"/post_image/hadoop/hdfs-architecture-01.png\" width=\"80%\"/>\n\t<p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n        Data Replication\n\t</p>\n</p>\n<h3>데이터 고가용성</h3>\n<p>HDFS는 데이터 <strong>고가용성</strong>을 위해 <strong>Data Replica</strong>를 <strong>여러 개의 노드에 삽입</strong>하는 방식을 사용 합니다.</p>\n<h4>Data Replication</h4>\n<ul>\n<li>HDFS는 <strong>매우 큰 파일들</strong>을 클러스터 내에 <strong>안전하게 저장</strong> 되도록 설계 되었습니다.\n<ul>\n<li>fault tolerance를 지원함. <strong>block size</strong>와 <strong>replication factor</strong>는 파일 마다 설정 가능합니다.</li>\n</ul>\n</li>\n<li>마지막 블록을 제외한 파일의 모든 블록은 <strong>동일한 크기로 저장</strong> 됩니다.\n<ul>\n<li>가변 길이 블록에 대한 지원이 추가 된 후, 블록 크기를 끝까지 안채워도 새 블록을 시작 할 수 있습니다.</li>\n</ul>\n</li>\n<li>Application에서 파일 생성 시, <strong>파일의 복제본 수를 지정</strong> 할 수 있습니다. <strong>블록 크기</strong>도요!\n<ul>\n<li>쓰기는 1회이며, 항상 하나의 작성자만 존재 한다.</li>\n</ul>\n</li>\n</ul>\n<h4>Replica Placement: The First Baby Steps</h4>\n<ul>\n<li>복제본 배치는 <strong>HDFS 안정성과 성능에 매우 중요한 요소</strong> 입니다. 이를 최적화 하여 성능을 올리는 것이, HDFS의 특징입니다.\n<ul>\n<li>이는 많은 튜닝과 경험을 필요로 합니다. <strong>rack-aware replica placement의 목적</strong>은, 데<strong>이터의 안정성, 가용성 및 네트워크 대역폭 활용도를 개선</strong>하는 것입니다.</li>\n<li>현재의 <strong>replica placement policy</strong>는 <strong>이를 목적</strong>으로 하고 있으며, 이 정책을 구현하는 단기 목표는 프로덕션 시스템에서 이를 검증하고, 동작에 대해 자세히 알아보고, 보다 정교한 정책을 테스트하고 연구하기 위한 기반을 구축 하는 것입니다.</li>\n<li><strong>NameNode</strong>는 <strong>Hadoop rack awareness</strong>를 통해, <strong>DataNode</strong>가 속하는 <strong>랙 ID를 결정</strong>합니다. 대부분 <strong>replica</strong>를 <strong>고유한 rack</strong>에 배치 하는 것이 대부분입니다.\n<ul>\n<li>이래야 데이터 손실 방지 및 여러 rack의 대역폭을 사용할 수 있습니다. Component 장애 시 부하를 쉽게 분산 가능 하고요.</li>\n<li>하지만, <strong>블록을 여러 랙으로 전송</strong> 하는 것이, <strong>write 비용을 증가</strong> 시킨다는 단점이 있습니다.</li>\n</ul>\n</li>\n<li>그래서 3개의 replica를 놓는다고 하면 (복제본의 1/3은 한 노드에 있고, 복제본의 2/3은 한 랙에 있으며, 나머지 1/3은 나머지 랙에 고르게 분산 됨.)\n<ul>\n<li>a rack의 A datanode 안에</li>\n<li>a rack의 B datanode 안에</li>\n<li>b rack의 C datanode 안에</li>\n<li>이렇게 해야, 일반적으로 <strong>write 성능을 향상</strong>시킬 수 있으며, <strong>랙 사이에서 발생하는 write 트래픽</strong>을 줄일 수 있습니다.</li>\n<li>replication factor가 3 이상인 경우, <strong>랙당 복제본 수</strong>를 상한선 (기본적으로 (복제본 - 1) / 랙 + 2) 이하로 유지하는 방향으로, <strong>4번째 이후 복제본의 배치가 무작위</strong>로 결정 됩니다.</li>\n<li><strong>최대 복제본의 수는 DataNode의 총 갯수</strong>입니다. (하나의 DataNode 내 동일 Replica를 허용 하지 않음)</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>","id":"9dbd0b47-b274-5813-960b-805e0f92e2d0","frontmatter":{"date":"2023-05-16","path":"/data-engineering/hdfs-architecture","title":"HDFS Architectrue","tags":["Data-Engineering"],"keyword":"hdfs, hadoop, hdfs architecture","summary":"HDFS의 구조에 대해서 알아보자.","img":"/post_image/thumbnail/hdfs-architecture.png","series":null}}},"pageContext":{"postPath":"/data-engineering/hdfs-architecture","series":{"data":{"allMarkdownRemark":{"edges":[]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"2f3abeaf-1ba1-5817-8329-0ef461b07b9c","excerpt":"오늘은 Spark 성능 튜닝에 필요한, 와  에 대해서 알아 보도록 하겠습니다. RDD는 Transformation (ex: , ,  등)을 이용 하여 새로운 RDD를 만들 수 있습니다. 하지만, Action (ex: , ,  등)이 호출 되기 전까지는, 실제 연산을 수행 하지 않죠. 다음 예제를 함께 봅시다! 하지만, 우리가 다음과 같은 상황을 가정해 보죠. 만약, 동일하게 Transformation 된 RDD에 대해, 여러 개의 Action…","frontmatter":{"date":"2023-05-24","tags":["Data-Engineering"],"path":"/data-engineering/spark-performance-tuning-2","title":"Spark 성능 튜닝 - 2. cache(), persist(), unpersist()","img":"/post_image/thumbnail/spark-performance-tuning-2.jpeg","summary":"Spark의 Performance 튜닝을 수행 해 보자."}}},{"node":{"id":"9dbd0b47-b274-5813-960b-805e0f92e2d0","excerpt":"안녕하세요? 오늘은 HDFS의 Architecture에 대해서 알아 보도록 하겠습니다. Hadoop Distributed File System(HDFS) 는 상용 하드웨어에서 동작하게 만든 오픈소스 SW입니다. 장애 발생에 강하며, 저비용 하드웨어 안에서도, 잘 작동 하게 설계 되었습니다. 또한, 많은 데이터 셋을 지닌 어플리케이션에 적합하며, 높은 throughput을 가지고 있습니다. Assumptions and Goals HDFS…","frontmatter":{"date":"2023-05-16","tags":["Data-Engineering"],"path":"/data-engineering/hdfs-architecture","title":"HDFS Architectrue","img":"/post_image/thumbnail/hdfs-architecture.png","summary":"HDFS의 구조에 대해서 알아보자."}}},{"node":{"id":"c7182a1e-4786-5112-9048-54cca7467f6d","excerpt":"안녕하세요? 오늘은 Spark Structured Streaming에 대해서 알아 보도록 하겠습니다. Spark Structured Streaming이란? Spark Structured Streaming은, Spark SQL (Dataset/DataFrame) 엔진 기반의, 확장 가능하고, 내결함성이 있는 Stream Processing Engine 입니다. 이는 Batch 작업에서 구조화된 데이터를 처리 하는 것 처럼, Streaming…","frontmatter":{"date":"2023-05-13","tags":["Data-Engineering"],"path":"/data-engineering/spark-structured-streaming","title":"Spark Structured Streaming이란?","img":"/post_image/thumbnail/spark-structured-streaming.png","summary":"Spark로 Streaming Job을 수행 해 보자."}}},{"node":{"id":"fb3c924f-4a7c-50c2-8404-09a28f1e98ec","excerpt":"오늘은 Spark의 성능 튜닝에 대해서 이야기 해 보겠습니다. Spark는 요약해서 말하면, **in-memory(RAM 위에서)**에서 작동 하는 분산 컴퓨팅을 쉽게 지원해 주는 프레임워크 입니다. in-memory 연산은 빠르지만, 불안정 합니다. 메모리 관리, CPU Core 수의 관리를 통해 Out of memory가 발생 하지 않는 선에서, Job…","frontmatter":{"date":"2023-04-07","tags":["Data-Engineering"],"path":"/data-engineering/spark-performance-tuning-1","title":"Spark 성능 튜닝 - 1. Partition, Shuffle","img":"/post_image/thumbnail/spark-performance-tuning-1.png","summary":"Spark에 성능 튜닝을 시도 해 보자."}}}]}}}}},"staticQueryHashes":["2876327880","63159454"],"slicesMap":{}}