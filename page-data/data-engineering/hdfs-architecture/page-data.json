{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-engineering/hdfs-architecture/","result":{"data":{"markdownRemark":{"html":"<p>안녕하세요? 오늘은 <strong>HDFS</strong>의 <strong>Architecture</strong>에 대해서 알아 보도록 하겠습니다. <strong>Hadoop Distributed File System(HDFS)</strong> 는 상용 하드웨어에서 동작하게 만든 오픈소스 SW입니다. 장애 발생에 강하며, 저비용 하드웨어 안에서도, 잘 작동 하게 설계 되었습니다. 또한, <strong>많은 데이터 셋을 지닌 어플리케이션에 적합</strong>하며, <strong>높은 throughput</strong>을 가지고 있습니다.</p>\n<p align=\"center\">\n\t<img src=\"/post_image/thumbnail/hdfs-architecture.png\" width=\"80%\"/>\n\t<p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\tHDFS 구성\n\t</p>\n</p>\n<h3>Assumptions and Goals</h3>\n<p>HDFS는 다음과 같은 것들을 <strong>가정</strong>하고, 그에 맞는 <strong>목표</strong>들을 가지고 있습니다.</p>\n<ul>\n<li><strong>Hardware Failure</strong>\n<ul>\n<li>많은 수의 component로 제작된 클러스터 라면, 일부 component는 작동하지 않을 것을 의미합니다.</li>\n<li>그렇기에, <strong>빠른 이상 감지</strong>와, <strong>빠르고 정확한 복구</strong>가 HDFS의 핵심입니다.</li>\n</ul>\n</li>\n<li><strong>Streaming Data Access</strong>\n<ul>\n<li>HDFS를 사용하는 어플리케이션은 <strong>streaming access</strong>의 방식을 주로 사용 합니다.</li>\n<li>HDFS는 <strong>batch processing을 위해 설계</strong> 되었습니다. low latency보단, <strong>high throughput</strong>에 중점을 둡니다.</li>\n</ul>\n</li>\n<li><strong>Large Data Sets</strong>\n<ul>\n<li>HDFS를 사용하는 어플리케이션은 <strong>많은 데이터를 다룹니다.</strong> 거의 테라 바이트 단위..</li>\n<li><strong>높은 집계 데이터 대역폭</strong>을 제공하고, 단일 클러스터에서 <strong>수백 개의 노드로 확장 가능</strong>하여, 단일 인스턴스는 <strong>수천만 개의 파일을 지원</strong>하도록 합니다.</li>\n</ul>\n</li>\n<li><strong>Simple Coherency Model (단순 일관성 모델)</strong>\n<ul>\n<li>HDFS 애플리케이션은, <strong>한 번 쓰고, 여러 번 읽는 액세스 모델</strong>이 권장 될니다.</li>\n<li>일단 생성되고 쓰여지고 닫힌 파일은 추가 및 자르기를 제외, <strong>변경 될 필요가 없습니다.</strong></li>\n<li>파일 끝 컨텐츠 추가는 가능하나, <strong>random access는 불가능</strong> 합니다.</li>\n<li>이는 데이터 일관성 문제를 단순화 시키며, 높은 처리량 데이터 액세스를 가능케 하여, <strong>MapReduce, Web Crawling</strong>에 최적화 시킵니다.</li>\n</ul>\n</li>\n<li><strong>“Moving Computation is Cheaper than Moving Data”</strong>\n<ul>\n<li>데이터 세트의 크기가 크면, <strong>데이터가 근처에 있을 때, 계산이 효과적</strong>입니다. (데이터의 지역성)</li>\n<li>이는 네트워크 정체를 최소화하며, <strong>시스템의 전체 처리량을 증가</strong> 시킨다.</li>\n<li>데이터를 응용 프로그램의 위치로 옮기는게 아닌, <strong>데이터가 있는 위치에 더 가깝게</strong> 계산을 마이그레이션 하는 것이 더 나은 경우가 많다고 가정합니다.</li>\n</ul>\n</li>\n<li><strong>Portability Across Heterogeneous Hardware and Software Platforms (H, S/W 플랫폼간 이식성)</strong>\n<ul>\n<li>한 플랫폼에서 다른 플랫폼으로 이동하기 쉽게 설계합니다.</li>\n</ul>\n</li>\n</ul>\n<h3>NameNode &#x26; DataNode</h3>\n<p>HDFS는 <strong>master/slave architecture</strong>를 가지고 있습니다. 요약하면 <strong>Namenode</strong>는 master 역할로, <strong>데이터를 관리하는 역할</strong>을, <strong>Datanode</strong>는 <strong>자신에게 할당된 데이터 블록을 처리</strong>하는 역할을 합니다.</p>\n<h4>NameNode</h4>\n<ul>\n<li><strong>마스터 서버</strong>의 역할을 합니다.</li>\n<li><strong>File system namespace</strong>와, <strong>클라이언트의 파일 액세스를 규제</strong>하는 역할을 담당 합니다.\n<ul>\n<li><strong>file system namespace</strong>의 변동 내역은 <strong>NameNode</strong>에 저장 됩니다.</li>\n<li><strong>replication factor</strong>에 대한 정보들 또한 <strong>보관</strong>하고 있습니다.</li>\n<li>블록 복제에 관한 모든 결정을 내리며, 클러스터의 <strong>각 DataNode에서 정기적으로 Heartbeat 및 Blockreport를 수신</strong> 합니다.</li>\n</ul>\n</li>\n<li>클러스터 내, <strong>단 한 개</strong>만 존재하며, <strong>고가용성</strong>을 위해, <strong>예비 NameNode</strong>도 만들어 놓는 것이 좋습니다.</li>\n<li>파일 열기, 닫기, 파일/폴더 이름 수정과 같은 <strong>operation</strong>을 수행 합니다.</li>\n<li>DataNode에 대한 <strong>블록의 Mapping</strong>도 결정 합니다.</li>\n</ul>\n<h4>DataNode</h4>\n<ul>\n<li>HDFS에서 파일이 저장 될 때, <strong>한 개 이상의 block</strong>으로 나누어 지고, 이들은 <strong>DataNode 들에 적재</strong> 됩니다.\n<ul>\n<li>그렇기 때문에, <strong>파일을 저장</strong> 할 때, <strong>적절한 Block 크기를 고려</strong> 하여야 합니다. 사용 하는 입장에서는 <strong>Block을 그대로 가져와 병렬 처리</strong>를 수행 할테니까요!</li>\n</ul>\n</li>\n<li>DataNode는 system’s clients의 <strong>파일을 읽고, 쓰는 역할</strong>을 합니다.\n<ul>\n<li>NameNode로 부터 온, <strong>block 생성, 삭제, 복제를 수행</strong> 합니다.</li>\n</ul>\n</li>\n<li>실제 배포에서는 DataNode를 한 곳에 때려 박지 않습니다. (여러 서버 렉에 저장)</li>\n</ul>\n<h3>The File System Namespace</h3>\n<ul>\n<li>HDFS는 <strong>전통적인 계층형 파일 구성을 지원</strong> 합니다.\n<ul>\n<li>즉, 폴더를 생성하고, 그 안에 파일을 집어 넣는 것이 가능 하다.</li>\n</ul>\n</li>\n<li>HDFS는 hard link와, soft link를 지원 하지 않지만, 배제 하지는 않습니다.</li>\n<li>naming도 대부분 비슷하게 지원 합니다만, <strong>몇 개의 경로와 이름은 예약</strong> 되어 있습니다. 이는 <strong>암호화, 스냅샷</strong>과 관련이 있습니다. (e.g. /.reserved and .snapshot)</li>\n</ul>\n<p align=\"center\">\n\t<img src=\"/post_image/hadoop/hdfs-architecture-01.png\" width=\"80%\"/>\n\t<p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n        Data Replication\n\t</p>\n</p>\n<h3>데이터 고가용성</h3>\n<p>HDFS는 데이터 <strong>고가용성</strong>을 위해 <strong>Data Replica</strong>를 <strong>여러 개의 노드에 삽입</strong>하는 방식을 사용 합니다.</p>\n<h4>Data Replication</h4>\n<ul>\n<li>HDFS는 <strong>매우 큰 파일들</strong>을 클러스터 내에 <strong>안전하게 저장</strong> 되도록 설계 되었습니다.\n<ul>\n<li>fault tolerance를 지원함. <strong>block size</strong>와 <strong>replication factor</strong>는 파일 마다 설정 가능합니다.</li>\n</ul>\n</li>\n<li>마지막 블록을 제외한 파일의 모든 블록은 <strong>동일한 크기로 저장</strong> 됩니다.\n<ul>\n<li>가변 길이 블록에 대한 지원이 추가 된 후, 블록 크기를 끝까지 안채워도 새 블록을 시작 할 수 있습니다.</li>\n</ul>\n</li>\n<li>Application에서 파일 생성 시, <strong>파일의 복제본 수를 지정</strong> 할 수 있습니다. <strong>블록 크기</strong>도요!\n<ul>\n<li>쓰기는 1회이며, 항상 하나의 작성자만 존재 한다.</li>\n</ul>\n</li>\n</ul>\n<h4>Replica Placement: The First Baby Steps</h4>\n<ul>\n<li>복제본 배치는 <strong>HDFS 안정성과 성능에 매우 중요한 요소</strong> 입니다. 이를 최적화 하여 성능을 올리는 것이, HDFS의 특징입니다.\n<ul>\n<li>이는 많은 튜닝과 경험을 필요로 합니다. <strong>rack-aware replica placement의 목적</strong>은, 데<strong>이터의 안정성, 가용성 및 네트워크 대역폭 활용도를 개선</strong>하는 것입니다.</li>\n<li>현재의 <strong>replica placement policy</strong>는 <strong>이를 목적</strong>으로 하고 있으며, 이 정책을 구현하는 단기 목표는 프로덕션 시스템에서 이를 검증하고, 동작에 대해 자세히 알아보고, 보다 정교한 정책을 테스트하고 연구하기 위한 기반을 구축 하는 것입니다.</li>\n<li><strong>NameNode</strong>는 <strong>Hadoop rack awareness</strong>를 통해, <strong>DataNode</strong>가 속하는 <strong>랙 ID를 결정</strong>합니다. 대부분 <strong>replica</strong>를 <strong>고유한 rack</strong>에 배치 하는 것이 대부분입니다.\n<ul>\n<li>이래야 데이터 손실 방지 및 여러 rack의 대역폭을 사용할 수 있습니다. Component 장애 시 부하를 쉽게 분산 가능 하고요.</li>\n<li>하지만, <strong>블록을 여러 랙으로 전송</strong> 하는 것이, <strong>write 비용을 증가</strong> 시킨다는 단점이 있습니다.</li>\n</ul>\n</li>\n<li>그래서 3개의 replica를 놓는다고 하면 (복제본의 1/3은 한 노드에 있고, 복제본의 2/3은 한 랙에 있으며, 나머지 1/3은 나머지 랙에 고르게 분산 됨.)\n<ul>\n<li>a rack의 A datanode 안에</li>\n<li>a rack의 B datanode 안에</li>\n<li>b rack의 C datanode 안에</li>\n<li>이렇게 해야, 일반적으로 <strong>write 성능을 향상</strong>시킬 수 있으며, <strong>랙 사이에서 발생하는 write 트래픽</strong>을 줄일 수 있습니다.</li>\n<li>replication factor가 3 이상인 경우, <strong>랙당 복제본 수</strong>를 상한선 (기본적으로 (복제본 - 1) / 랙 + 2) 이하로 유지하는 방향으로, <strong>4번째 이후 복제본의 배치가 무작위</strong>로 결정 됩니다.</li>\n<li><strong>최대 복제본의 수는 DataNode의 총 갯수</strong>입니다. (하나의 DataNode 내 동일 Replica를 허용 하지 않음)</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>","id":"57fa8df1-f97c-53f9-9052-9fa247efb2da","frontmatter":{"date":"2023-05-16","path":"/data-engineering/hdfs-architecture","title":"HDFS Architectrue","tags":["Data-Engineering"],"keyword":"hdfs, hadoop, hdfs architecture","summary":"HDFS의 구조에 대해서 알아보자.","img":"/post_image/thumbnail/hdfs-architecture.png","series":null}}},"pageContext":{"postPath":"/data-engineering/hdfs-architecture","series":{"data":{"allMarkdownRemark":{"edges":[]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"3c44d6b1-b341-5256-bb40-e6a58835b474","excerpt":"Intro 안녕하세요, 박민재입니다. 오늘은 Apache Iceberg의 Table에 수행 되는 쿼리가 최적의 성능으로 작동 될 수 있도록, File Compaction을 통해 이를 수행하는 방법에 대해 이야기 하는 시간을 가져 보도록 하겠습니다. File Compaction 우리가 쿼리를 수행 시, Hive Metastore의 정보를 이용하더라도, 혹은 Iceberg의 Metadata…","frontmatter":{"date":"2024-11-10","tags":["Data-Engineering"],"path":"/data-engineering/iceberg-table-optimization-1","title":"Iceberg Table의 성능 최적화 - 1. 압축","img":"/post_image/thumbnail/iceberg-table-optimization-1.webp","summary":"File Merge를 통한 성능 최적화에 대해 알아보자."}}},{"node":{"id":"6eaa7aeb-a4fe-5cd9-bbe5-309dde97514b","excerpt":"안녕하세요, 박민재입니다. 오늘은 Airflow DB를 관리하는 방법에 대해서 이야기 나눠 보도록 하겠습니다. Airflow Backend Database Airflow에서 Backend Database는 어떤 역할을 할까요? Airflow에서 DAG을 실행 하기 위해서, Airflow는 다음과 같은 정보들을 Backend Database에 저장하여 정합성을 유지 합니다. DagRun: 특정 Interval에 실행 된 DagRun…","frontmatter":{"date":"2024-10-27","tags":["Data-Engineering"],"path":"/data-engineering/airflow-db-management","title":"Airflow Backend Database Management (airflow db clean)","img":"/post_image/thumbnail/airflow-db-management.webp","summary":"Airflow의 Backend Database를 관리 하는 법"}}},{"node":{"id":"b595b168-8160-5abf-9641-39746d2f9e82","excerpt":"안녕하세요, 박민재입니다. 오늘은 Spark Application내의 각 Executor 내의 Task에 제한적으로 변수를 공유하는 두 가지 방법에 대해서 알아 보도록 하겠습니다. 시작하기에 앞서 단편적으로 생각 해 보면, Spark Application에서 연산 과정의 변수를 공유 한다는 것은 어려운 일인가? 라는 질문을 던져 볼 수 있습니다. 우리는 Task…","frontmatter":{"date":"2024-10-11","tags":["Data-Engineering"],"path":"/data-engineering/spark-sharing-variables","title":"Sharing Variables in Spark - Broadcast, Accumulator","img":"/post_image/thumbnail/spark-sharing-variables.png","summary":"Spark Application에서 변수를 공유 하는 방법"}}},{"node":{"id":"5effd6a1-bfd8-5a86-b718-5eb1e534601e","excerpt":"Intro 안녕하세요, 박민재입니다. 오늘은 Spark Memory에 관해 Deep Dive를 해 보도록 하겠습니다. Spark는 In-Memory를 이용하여, 빠른 연산을 할 수 있도록 보장합니다. 하지만, In-Memory 연산은 빠른 대신, 비싼 관계로 적은 리소스 만을 활용할 수 있습니다. 그렇기 때문에 우리는 효율적으로 Memory를 관리 하여, Spark Application이 빠르고, 안정적으로 Task…","frontmatter":{"date":"2024-04-12","tags":["Data-Engineering"],"path":"/data-engineering/spark-memory-deep-dive","title":"Deep Dive of Spark Memory","img":"/post_image/thumbnail/spark-memory-deep-dive.jpeg","summary":"Spark Memory의 깊은 이해를 위해 Deep Dive를 해 보자."}}}]}}}}},"staticQueryHashes":["3819017183","63159454"],"slicesMap":{}}