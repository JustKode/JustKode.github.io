{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-engineering/spark-structured-streaming-unit-test/","result":{"data":{"markdownRemark":{"html":"<h3>머릿말</h3>\n<p>안녕하세요? 새해부터 찾아온 <strong>JustKode, 박민재</strong>입니다. 오늘은 <strong>Spark Structured Streaming</strong>에 대한 <strong>Unit Test</strong>를 수행 하는 법에 대해서 공유 드려 보려고 합니다.</p>\n<h3>What is Spark Structured Streaming?</h3>\n<p><strong>Spark Structured Streaming</strong>은 <strong>Spark SQL API</strong> (Dataframe, Dataset)를 이용하여, Streaming 처리를 수행 할 수 있게 하는 <strong>Stream Processing Engine</strong> 입니다. <strong>Spark 2.x 버전 이상</strong>부터 지원하고 있으며, <strong>차세대 Spark 기반 Streaming Engine</strong>입니다.</p>\n<h3>In real case</h3>\n<p>우리는 실제 Streaming 데이터를 처리 하면서 <strong>다양한 경우</strong>를 경험 하게 됩니다.</p>\n<ul>\n<li><strong>JSON 데이터가 깨져서</strong> 들어 오는 경우</li>\n<li>한창 전에 유입 되었어야 할 <strong>데이터가 뒤늦게</strong> 들어 오는 경우</li>\n<li><strong>중복 데이터가 유입</strong> 되는 경우</li>\n</ul>\n<p>이런 상황에서도 우리는 Streaming 데이터를 처리하는 Application이 종료 되지 않도록, <strong>예외 처리</strong>를 수행해야 합니다. 하지만, <strong>Spark Structured Streaming 환경에서 Unit Test</strong>는 어떻게 수행 하여야 할까요? <strong>Spark SQL</strong> 쿼리를 함수로 빼서 Test를 수행 할 수 있겠지만, 실제 Streaming 데이터가 들어온다는 가정 하에는 테스트를 자동으로 수행 하게 하기가 어렵습니다.</p>\n<p>네... 아래와 같은 함수들은 <strong>JUnit</strong>이나, <strong>ScalaTest</strong>로 충분히 가능 하거든요.</p>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre class=\"language-scala\"><code class=\"language-scala\"><span class=\"token keyword\">def</span> aggProductPerformanceReport<span class=\"token punctuation\">(</span>df<span class=\"token operator\">:</span> DataFrame<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> DataFrame <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n  df<span class=\"token punctuation\">.</span>groupBy<span class=\"token punctuation\">(</span>col<span class=\"token punctuation\">(</span><span class=\"token string\">\"productId\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">.</span>agg<span class=\"token punctuation\">(</span>\n      sum<span class=\"token punctuation\">(</span><span class=\"token string\">\"price\"</span><span class=\"token punctuation\">)</span> as <span class=\"token string\">\"price\"</span><span class=\"token punctuation\">,</span>\n      count<span class=\"token punctuation\">(</span><span class=\"token string\">\"*\"</span><span class=\"token punctuation\">)</span> as <span class=\"token string\">\"sales\"</span>\n    <span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<p>굳이 한다면, <strong>Socket</strong>을 <strong>readStream</strong>으로 적용한 <strong>Test용 Application</strong>을 만들어서 진행 할 수 있을 것 같지만, 5분 단위 Streaming Window에 대해서 이를 테스트 하려고 5분을 기다리는 건 너무 <strong>비효율적</strong>이며, 수동으로 데이터를 삽입 하여야 한다는 문제가 발생 합니다. 이를 <strong>CI/CD</strong> 과정에 태우는 것도 어려움이 있을 거에요. <strong>Sink Result</strong> 같은 경우에도, 콘솔로 출력 하는 것이 최선일 것이기 때문이에요.</p>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre class=\"language-scala\"><code class=\"language-scala\"><span class=\"token keyword\">val</span> query <span class=\"token operator\">=</span> wordCounts<span class=\"token punctuation\">.</span>writeStream\n  <span class=\"token punctuation\">.</span>outputMode<span class=\"token punctuation\">(</span><span class=\"token string\">\"complete\"</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span><span class=\"token string\">\"console\"</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nquery<span class=\"token punctuation\">.</span>awaitTermination<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>우리가 정밀한 Test를 위해서 직면한 문제를 정의 하면 다음과 같습니다.</p>\n<ul>\n<li><strong>실제 Streaming 데이터</strong>가 들어오는 것처럼, 깨진 파일 등의 <strong>Test Case</strong>를 만들 수 있는가?</li>\n<li><strong>지연된 데이터가 유입되는 시나리오</strong>를 구현 하기 위해, <strong>원하는 시간대에서 Trigger</strong> 되도록 구현 할 수 있는가?</li>\n<li><strong>Sink Result</strong>를 뽑아서, 조건에 일치 하는 지 확인 할 수 있는가?</li>\n</ul>\n<p>이제 하나하나씩 문제를 해결 해 보도록 하겠습니다.</p>\n<blockquote>\n<p>해당 실습에서 사용하는 Spark Version은 3.5.0을 사용합니다.</p>\n</blockquote>\n<h3>MemoryStream</h3>\n<p><strong>실제 Streaming 데이터가 들어 오는 것</strong>을 구현하기 위해서는 어떻게 해야 할까요? 우리는 이를 위해, <code class=\"language-text\">MemoryStream</code>을 사용할 수 있습니다. <code class=\"language-text\">MemoryStream</code>을 통해서, <strong>Kafka</strong>로 데이터가 유입되는 케이스를 구현 할 수 있습니다. 다음과 같이 말이에요.</p>\n<p>해당 <strong>Code Snippet</strong>은 <code class=\"language-text\">MemoryStream</code> 객체에 데이터를 삽입하는 예제입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre class=\"language-scala\"><code class=\"language-scala\"><span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>execution<span class=\"token punctuation\">.</span>streaming<span class=\"token punctuation\">.</span></span>MemoryStream\n\n<span class=\"token keyword\">val</span> logs <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> MemoryStream<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span>\nlogs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span><span class=\"token triple-quoted-string string\">\"\"\"{\"id\": 1, \"content\": \"hello\"}\"\"\"</span><span class=\"token punctuation\">)</span>\nlogs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span><span class=\"token triple-quoted-string string\">\"\"\"{\"id\": 2, \"content\": \"hello!\"}\"\"\"</span><span class=\"token punctuation\">)</span>\nlogs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span><span class=\"token triple-quoted-string string\">\"\"\"{\"id\": 3, \"content\": \"hello!!\"}\"\"\"</span><span class=\"token punctuation\">)</span>\nlogs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span><span class=\"token triple-quoted-string string\">\"\"\"{\"id\": 3, \"co\"\"\"</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\">// 이상 데이터</span></code></pre></div>\n<p>이를 <code class=\"language-text\">DataFrame</code>으로 변환하기 위해서는 <code class=\"language-text\">MemoryStream</code>의 메소드인 <code class=\"language-text\">toDF()</code>를 호출 하면 되고, JSON을 추출하기 위해서는 <code class=\"language-text\">from_json()</code>과 <code class=\"language-text\">StructType</code>을 이용하면 됩니다.</p>\n<p>방금 우리가 <code class=\"language-text\">MemoryStream</code>으로 만들어 낸 <code class=\"language-text\">DataFrame</code>을 가상의 <strong>In-Memory Table</strong>에 <strong>Sink</strong>하기 위해서는 <code class=\"language-text\">writeStream</code>을 이용하여 다음과 같이 <code class=\"language-text\">.format(\"memory\")</code>와 <code class=\"language-text\">.queryName(\"원하는 테이블 명\")</code> 을 입력 하면 됩니다. 추가적으로, 인위적인 Trigger 없이, 즉시 데이터를 Processing 하고 싶다면, <code class=\"language-text\">DataFrame</code>으로 만들어 낸 <code class=\"language-text\">StreamingQuery</code>의 <code class=\"language-text\">processAllAvailable()</code> 메서드를 호출하여 주면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre class=\"language-scala\"><code class=\"language-scala\"><span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>types<span class=\"token punctuation\">.</span></span>_\n\n<span class=\"token keyword\">val</span> schema <span class=\"token operator\">=</span> StructType<span class=\"token punctuation\">(</span>\n  Seq<span class=\"token punctuation\">(</span>\n    StructField<span class=\"token punctuation\">(</span><span class=\"token string\">\"id\"</span><span class=\"token punctuation\">,</span> DataTypes<span class=\"token punctuation\">.</span>LongType<span class=\"token punctuation\">,</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    StructField<span class=\"token punctuation\">(</span><span class=\"token string\">\"content\"</span><span class=\"token punctuation\">,</span> DataTypes<span class=\"token punctuation\">.</span>StringType<span class=\"token punctuation\">,</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">val</span> df <span class=\"token operator\">=</span> logs<span class=\"token punctuation\">.</span>toDF<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>select<span class=\"token punctuation\">(</span>from_json<span class=\"token punctuation\">(</span>col<span class=\"token punctuation\">(</span><span class=\"token string\">\"value\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> schema<span class=\"token punctuation\">)</span> as <span class=\"token string\">\"data\"</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>select<span class=\"token punctuation\">(</span><span class=\"token string\">\"data.*\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">val</span> streamingQuery <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>writeStream\n  <span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span><span class=\"token string\">\"memory\"</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>queryName<span class=\"token punctuation\">(</span><span class=\"token string\">\"agg\"</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>outputMode<span class=\"token punctuation\">(</span><span class=\"token string\">\"append\"</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nstreamingQuery<span class=\"token punctuation\">.</span>processAllAvailable<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">val</span> result <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">(</span><span class=\"token string\">\"select * from agg\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>collectAsList<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nresult<span class=\"token punctuation\">.</span>forEach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span></code></pre></div>\n<p>출력 결과는 다음과 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token punctuation\">[</span><span class=\"token number\">1</span>,hello<span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token number\">2</span>,hello<span class=\"token operator\">!</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span><span class=\"token number\">3</span>,hello<span class=\"token operator\">!</span><span class=\"token operator\">!</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span>null,null<span class=\"token punctuation\">]</span></code></pre></div>\n<p>하지만, 다음과 같은 구성은 <strong>Watermark</strong> 같이, 과거의 데이터를 드랍 하는 로직이 정상적으로 작동 하는지를 확인 하기 어렵습니다. <strong>Trigger</strong>가 호출 되는 <strong>논리적 시간을 조정</strong>하는 로직은 <code class=\"language-text\">StreamingQuery</code> Class에 존재 하지 않기 때문이에요. 그렇다면 우리는 다른 방법을 찾아 볼 필요가 있습니다.</p>\n<h3>StreamingQueryManager.startQuery()</h3>\n<p><code class=\"language-text\">StreamingQueryManager.startQuery()</code>는 <code class=\"language-text\">StreamingQuery</code>를 호출하는 저레벨의 Private 함수 입니다. 파라미터로 Option, 연산을 수행 할 DataFrame, Clock, Sink, OutputMode 등을 입력 하면, 이에 맞는 <code class=\"language-text\">StreamingQuery</code> 를 반환 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre class=\"language-scala\"><code class=\"language-scala\"><span class=\"token keyword\">private</span><span class=\"token punctuation\">[</span>sql<span class=\"token punctuation\">]</span> <span class=\"token keyword\">def</span> startQuery<span class=\"token punctuation\">(</span>\n    userSpecifiedName<span class=\"token operator\">:</span> Option<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    userSpecifiedCheckpointLocation<span class=\"token operator\">:</span> Option<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    df<span class=\"token operator\">:</span> DataFrame<span class=\"token punctuation\">,</span>\n    extraOptions<span class=\"token operator\">:</span> Map<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    sink<span class=\"token operator\">:</span> Table<span class=\"token punctuation\">,</span>\n    outputMode<span class=\"token operator\">:</span> OutputMode<span class=\"token punctuation\">,</span>\n    useTempCheckpointLocation<span class=\"token operator\">:</span> <span class=\"token builtin\">Boolean</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>\n    recoverFromCheckpointLocation<span class=\"token operator\">:</span> <span class=\"token builtin\">Boolean</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">true</span><span class=\"token punctuation\">,</span>\n    trigger<span class=\"token operator\">:</span> Trigger <span class=\"token operator\">=</span> Trigger<span class=\"token punctuation\">.</span>ProcessingTime<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    triggerClock<span class=\"token operator\">:</span> Clock <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SystemClock<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    catalogAndIdent<span class=\"token operator\">:</span> Option<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>TableCatalog<span class=\"token punctuation\">,</span> Identifier<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> None<span class=\"token punctuation\">,</span>\n    catalogTable<span class=\"token operator\">:</span> Option<span class=\"token punctuation\">[</span>CatalogTable<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> None<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> StreamingQuery</code></pre></div>\n<p><code class=\"language-text\">StreamingQueryManager.startQuery()</code>와, <code class=\"language-text\">MemorySink</code>, <code class=\"language-text\">ManualClock</code>을 이용하여, <strong>원하는 논리적 시간대</strong>에 <strong>Trigger를 호출</strong> 할 수 있습니다.</p>\n<h4>중요!!!</h4>\n<p>그 전에 우리가 해야 할 일이 있습니다. <code class=\"language-text\">StreamingQueryManager.startQuery()</code>과 <code class=\"language-text\">ManualClock</code>은 Private Method라서 일반적인 방법으로는 사용이 불가능 하기 때문에, 인위적으로 Package에 접근 하여 꺼내오는 방법은 다음과 같습니다. 약간의 트릭을 사용 하여, Test 폴더 내 <code class=\"language-text\">org.apache.spark.sql</code> 경로에서 파일을 생성 합니다.</p>\n<blockquote>\n<p>org.apache.spark.sql.StreamingTestUtil</p>\n</blockquote>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre class=\"language-scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>execution<span class=\"token punctuation\">.</span>streaming<span class=\"token punctuation\">.</span>sources<span class=\"token punctuation\">.</span></span>MemorySink\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>streaming<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">{</span>OutputMode<span class=\"token punctuation\">,</span> StreamingQuery<span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span></span>ManualClock\n\n<span class=\"token keyword\">object</span> StreamingTestUtil <span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">def</span> getStreamingQuery<span class=\"token punctuation\">(</span>df<span class=\"token operator\">:</span> DataFrame<span class=\"token punctuation\">,</span>\n                        clock<span class=\"token operator\">:</span> ManualClock<span class=\"token punctuation\">,</span>\n                        sink<span class=\"token operator\">:</span> MemorySink<span class=\"token punctuation\">,</span>\n                        checkpoint<span class=\"token operator\">:</span> <span class=\"token builtin\">String</span><span class=\"token punctuation\">,</span>\n                        outputMode<span class=\"token operator\">:</span> OutputMode<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> StreamingQuery <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    df<span class=\"token punctuation\">.</span>sparkSession\n      <span class=\"token punctuation\">.</span>streams\n      <span class=\"token punctuation\">.</span>startQuery<span class=\"token punctuation\">(</span>\n        userSpecifiedName <span class=\"token operator\">=</span> Some<span class=\"token punctuation\">(</span><span class=\"token string\">\"spark-structured-streaming-unit-test\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        userSpecifiedCheckpointLocation <span class=\"token operator\">=</span> Some<span class=\"token punctuation\">(</span>checkpoint<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        df <span class=\"token operator\">=</span> df<span class=\"token punctuation\">,</span>\n        extraOptions <span class=\"token operator\">=</span> Map<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        sink <span class=\"token operator\">=</span> sink<span class=\"token punctuation\">,</span>\n        outputMode <span class=\"token operator\">=</span> outputMode<span class=\"token punctuation\">,</span>\n        recoverFromCheckpointLocation <span class=\"token operator\">=</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span>\n        triggerClock <span class=\"token operator\">=</span> clock\n      <span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">}</span>\n\n  <span class=\"token keyword\">def</span> getClock<span class=\"token punctuation\">(</span>time<span class=\"token operator\">:</span> <span class=\"token builtin\">Long</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> ManualClock <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">new</span> ManualClock<span class=\"token punctuation\">(</span>time<span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h3>SparkStreamingTestRunner</h3>\n<p>원활한 테스트 코드를 작성 하기 위해서, <code class=\"language-text\">SparkStreamingTestRunner</code> 라는 <code class=\"language-text\">trait</code> 또한 만들어 보겠습니다. 구현된 내용은 다음과 같습니다.</p>\n<ul>\n<li><strong>Scalatest</strong>의 API를 사용합니다. (<code class=\"language-text\">AnyFlatSpec</code>, <code class=\"language-text\">BeforeAndAfter</code>, <code class=\"language-text\">BeforeAndAfterAll</code>)</li>\n<li><code class=\"language-text\">val spark</code>: 로컬에서 구동 되는 <code class=\"language-text\">SparkContext</code> 를 가지고 있습니다.</li>\n<li><code class=\"language-text\">checkpointLocation, logs, memorySink</code>: 각각 체크포인트 경로, <code class=\"language-text\">MemoryStream</code>, <code class=\"language-text\">MemorySink</code>를 가지고 있습니다. <code class=\"language-text\">startQuery</code>로는 특정 in-memory table에 데이터를 저장 하도록 설정할 수 없으므로, MemorySink에 데이터를 저장하여, <code class=\"language-text\">MemorySink.allData</code>로 <code class=\"language-text\">Seq[Row]</code> 정보를 추출 합니다.</li>\n<li><code class=\"language-text\">getDataFrameFromJsonRecordsBySchema(schema: StructType): DataFrame</code>: <code class=\"language-text\">StructType</code>을 입력 받아, <code class=\"language-text\">MemoryStream</code>내에 존재하는 JSON을 <code class=\"language-text\">DataFrame</code>으로 변환 합니다.</li>\n<li><code class=\"language-text\">caseClassObjectToJson[T](obj: T): String</code>: case class 객체를 JSON String으로 변환 합니다.</li>\n<li><code class=\"language-text\">caseClassToStructType[T: scala.reflect.runtime.universe.TypeTag]: StructType</code>: case class Type을 삽입하면, 이를 Struct로 변환 합니다.</li>\n<li><code class=\"language-text\">calenderToTimestamp(calender: Calendar): Timestamp</code>: <code class=\"language-text\">java.util.Calendar</code> 객체를 <code class=\"language-text\">java.sql.Timestamp</code> 객체로 변환 합니다.</li>\n<li><code class=\"language-text\">rowListToString(rows: Seq[Row]): String</code>: <code class=\"language-text\">Row</code>가 담긴 리스트를 <code class=\"language-text\">String</code>으로 변환 합니다.</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre class=\"language-scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">kr<span class=\"token punctuation\">.</span>justkode<span class=\"token punctuation\">.</span>util</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>fasterxml<span class=\"token punctuation\">.</span>jackson<span class=\"token punctuation\">.</span>databind<span class=\"token punctuation\">.</span></span>ObjectMapper\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>fasterxml<span class=\"token punctuation\">.</span>jackson<span class=\"token punctuation\">.</span>module<span class=\"token punctuation\">.</span>scala<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">{</span>DefaultScalaModule<span class=\"token punctuation\">,</span> ScalaObjectMapper<span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>commons<span class=\"token punctuation\">.</span>io<span class=\"token punctuation\">.</span></span>FileUtils\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">{</span>DataFrame<span class=\"token punctuation\">,</span> Row<span class=\"token punctuation\">,</span> SparkSession<span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>execution<span class=\"token punctuation\">.</span>streaming<span class=\"token punctuation\">.</span></span>MemoryStream\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>execution<span class=\"token punctuation\">.</span>streaming<span class=\"token punctuation\">.</span>sources<span class=\"token punctuation\">.</span></span>MemorySink\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>functions<span class=\"token punctuation\">.</span></span>_\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>types<span class=\"token punctuation\">.</span></span>StructType\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>scalatest<span class=\"token punctuation\">.</span>flatspec<span class=\"token punctuation\">.</span></span>AnyFlatSpec\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>scalatest<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">{</span>BeforeAndAfter<span class=\"token punctuation\">,</span> BeforeAndAfterAll<span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>catalyst<span class=\"token punctuation\">.</span></span>ScalaReflection\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">java<span class=\"token punctuation\">.</span>io<span class=\"token punctuation\">.</span></span>File\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">java<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span></span>Timestamp\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">java<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span></span>Calendar\n\n<span class=\"token keyword\">trait</span> SparkStreamingTestRunner <span class=\"token keyword\">extends</span> AnyFlatSpec\n  <span class=\"token keyword\">with</span> BeforeAndAfter\n  <span class=\"token keyword\">with</span> BeforeAndAfterAll <span class=\"token punctuation\">{</span>\n\n  <span class=\"token keyword\">private</span> <span class=\"token keyword\">val</span> mapper <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> ObjectMapper<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">with</span> ScalaObjectMapper\n  mapper<span class=\"token punctuation\">.</span>registerModule<span class=\"token punctuation\">(</span>DefaultScalaModule<span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">val</span> spark <span class=\"token operator\">=</span> SparkSession\n      <span class=\"token punctuation\">.</span>builder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">(</span><span class=\"token string\">\"spark.sql.shuffle.partitions\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">.</span>master<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[2]\"</span><span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">.</span>getOrCreate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">import</span> <span class=\"token namespace\">spark<span class=\"token punctuation\">.</span>implicits<span class=\"token punctuation\">.</span></span>_\n\n  <span class=\"token keyword\">implicit</span> <span class=\"token keyword\">val</span> ctx <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>sqlContext\n\n  spark<span class=\"token punctuation\">.</span>sparkContext<span class=\"token punctuation\">.</span>setLogLevel<span class=\"token punctuation\">(</span><span class=\"token string\">\"WARN\"</span><span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">val</span> checkpointLocation <span class=\"token operator\">=</span> <span class=\"token string\">\"/tmp/spark-structured-streaming-unit-test\"</span>\n  <span class=\"token keyword\">val</span> logs<span class=\"token operator\">:</span> MemoryStream<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> MemoryStream<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span>\n  <span class=\"token keyword\">val</span> memorySink <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> MemorySink\n\n  <span class=\"token keyword\">override</span> <span class=\"token keyword\">def</span> beforeAll<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    FileUtils<span class=\"token punctuation\">.</span>deleteDirectory<span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> File<span class=\"token punctuation\">(</span>checkpointLocation<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">}</span>\n\n  <span class=\"token keyword\">override</span> <span class=\"token keyword\">def</span> afterAll<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    FileUtils<span class=\"token punctuation\">.</span>deleteDirectory<span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> File<span class=\"token punctuation\">(</span>checkpointLocation<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">}</span>\n\n  <span class=\"token keyword\">protected</span> <span class=\"token keyword\">def</span> getDataFrameFromJsonRecordsBySchema<span class=\"token punctuation\">(</span>schema<span class=\"token operator\">:</span> StructType<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> DataFrame <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    logs<span class=\"token punctuation\">.</span>toDF<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">.</span>select<span class=\"token punctuation\">(</span>from_json<span class=\"token punctuation\">(</span>col<span class=\"token punctuation\">(</span><span class=\"token string\">\"value\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> schema<span class=\"token punctuation\">)</span> as <span class=\"token string\">\"data\"</span><span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">.</span>select<span class=\"token punctuation\">(</span><span class=\"token string\">\"data.*\"</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">}</span>\n\n  <span class=\"token keyword\">protected</span> <span class=\"token keyword\">def</span> caseClassObjectToJson<span class=\"token punctuation\">[</span>T<span class=\"token punctuation\">]</span><span class=\"token punctuation\">(</span>obj<span class=\"token operator\">:</span> T<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">String</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    mapper<span class=\"token punctuation\">.</span>writeValueAsString<span class=\"token punctuation\">(</span>obj<span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">}</span>\n\n  <span class=\"token keyword\">protected</span> <span class=\"token keyword\">def</span> caseClassObjectToJson<span class=\"token punctuation\">[</span>T<span class=\"token punctuation\">]</span><span class=\"token punctuation\">(</span>objList<span class=\"token operator\">:</span> Seq<span class=\"token punctuation\">[</span>T<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">String</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    objList<span class=\"token punctuation\">.</span>foldLeft<span class=\"token punctuation\">(</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">=></span> x <span class=\"token operator\">+</span> mapper<span class=\"token punctuation\">.</span>writeValueAsString<span class=\"token punctuation\">(</span>y<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token char\">'\\n'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>trim\n  <span class=\"token punctuation\">}</span>\n\n  <span class=\"token keyword\">protected</span> <span class=\"token keyword\">def</span> caseClassToStructType<span class=\"token punctuation\">[</span>T<span class=\"token operator\">:</span> scala<span class=\"token punctuation\">.</span>reflect<span class=\"token punctuation\">.</span>runtime<span class=\"token punctuation\">.</span>universe<span class=\"token punctuation\">.</span>TypeTag<span class=\"token punctuation\">]</span><span class=\"token operator\">:</span> StructType <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    ScalaReflection<span class=\"token punctuation\">.</span>schemaFor<span class=\"token punctuation\">[</span>T<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dataType<span class=\"token punctuation\">.</span>asInstanceOf<span class=\"token punctuation\">[</span>StructType<span class=\"token punctuation\">]</span>\n  <span class=\"token punctuation\">}</span>\n\n  <span class=\"token keyword\">protected</span> <span class=\"token keyword\">def</span> calenderToTimestamp<span class=\"token punctuation\">(</span>calender<span class=\"token operator\">:</span> Calendar<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> Timestamp <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">new</span> Timestamp<span class=\"token punctuation\">(</span>calender<span class=\"token punctuation\">.</span>getTimeInMillis <span class=\"token operator\">/</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">}</span>\n\n  <span class=\"token keyword\">protected</span> <span class=\"token keyword\">def</span> rowListToString<span class=\"token punctuation\">(</span>rows<span class=\"token operator\">:</span> Seq<span class=\"token punctuation\">[</span>Row<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">String</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    rows<span class=\"token punctuation\">.</span>foldLeft<span class=\"token punctuation\">(</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> row<span class=\"token punctuation\">)</span> <span class=\"token keyword\">=></span> x <span class=\"token operator\">+</span> row<span class=\"token punctuation\">.</span>toString<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token char\">'\\n'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>trim\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre></div>\n<p>그 다음, 이 함수들을 이용해서 한 번 Test 환경을 구축 해 보겠습니다. 자세한 설명은 주석으로 남기겠습니다.</p>\n<blockquote>\n<p>kr.justkode.aggregator.WatermarkAggregator</p>\n</blockquote>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre class=\"language-scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">kr<span class=\"token punctuation\">.</span>justkode<span class=\"token punctuation\">.</span>aggregator</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span></span>DataFrame\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>functions<span class=\"token punctuation\">.</span></span>_\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">java<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span></span>Timestamp\n\n<span class=\"token keyword\">object</span> WatermarkAggregator <span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">case</span> <span class=\"token keyword\">class</span> Event<span class=\"token punctuation\">(</span>adId<span class=\"token operator\">:</span> <span class=\"token builtin\">Long</span><span class=\"token punctuation\">,</span> eventId<span class=\"token operator\">:</span> <span class=\"token builtin\">Long</span><span class=\"token punctuation\">,</span> timestamp<span class=\"token operator\">:</span> Timestamp<span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">def</span> aggClick<span class=\"token punctuation\">(</span>df<span class=\"token operator\">:</span> DataFrame<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> DataFrame <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    df<span class=\"token punctuation\">.</span>filter<span class=\"token punctuation\">(</span>col<span class=\"token punctuation\">(</span><span class=\"token string\">\"eventId\"</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span><span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">.</span>withWatermark<span class=\"token punctuation\">(</span><span class=\"token string\">\"timestamp\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"10 minutes\"</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\">// 특정 기준에서 10분 이상 벗어난 데이터는 Drop</span>\n      <span class=\"token punctuation\">.</span>groupBy<span class=\"token punctuation\">(</span>\n        window<span class=\"token punctuation\">(</span>col<span class=\"token punctuation\">(</span><span class=\"token string\">\"timestamp\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"10 minutes\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"5 minutes\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> \n        col<span class=\"token punctuation\">(</span><span class=\"token string\">\"adId\"</span><span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">)</span>  <span class=\"token comment\">// 5분 간격, 10분 길이 Window에 대해 Group By 연산</span>\n      <span class=\"token punctuation\">.</span>count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<blockquote>\n<p>kr.justkode.streaming.WatermarkStreamingTest</p>\n</blockquote>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre class=\"language-scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">kr<span class=\"token punctuation\">.</span>justkode<span class=\"token punctuation\">.</span>streaming</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">kr<span class=\"token punctuation\">.</span>justkode<span class=\"token punctuation\">.</span>aggregator<span class=\"token punctuation\">.</span></span>WatermarkAggregator<span class=\"token punctuation\">.</span><span class=\"token punctuation\">{</span>Event<span class=\"token punctuation\">,</span> aggClick<span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">kr<span class=\"token punctuation\">.</span>justkode<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span></span>SparkStreamingTestRunner\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>commons<span class=\"token punctuation\">.</span>io<span class=\"token punctuation\">.</span></span>FileUtils\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span></span>StreamingTestUtil<span class=\"token punctuation\">.</span><span class=\"token punctuation\">{</span>getClock<span class=\"token punctuation\">,</span> getStreamingQuery<span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>execution<span class=\"token punctuation\">.</span>streaming<span class=\"token punctuation\">.</span>sources<span class=\"token punctuation\">.</span></span>MemorySink\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">.</span>streaming<span class=\"token punctuation\">.</span></span>OutputMode\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">java<span class=\"token punctuation\">.</span>io<span class=\"token punctuation\">.</span></span>File\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">java<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span></span>Calendar\n\n<span class=\"token keyword\">class</span> WatermarkStreamingTest <span class=\"token keyword\">extends</span> SparkStreamingTestRunner <span class=\"token punctuation\">{</span>\n  <span class=\"token comment\">// case class로부터, StructType 추출 </span>\n  <span class=\"token keyword\">val</span> schema <span class=\"token operator\">=</span> caseClassToStructType<span class=\"token punctuation\">[</span>Event<span class=\"token punctuation\">]</span>\n\n  <span class=\"token comment\">// Test 종료 시, Checkpoint 제거 및 MemoryStream 초기화</span>\n  after <span class=\"token punctuation\">{</span>\n    logs<span class=\"token punctuation\">.</span>reset<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    FileUtils<span class=\"token punctuation\">.</span>deleteDirectory<span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> File<span class=\"token punctuation\">(</span>checkpointLocation<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">}</span>\n\n  <span class=\"token string\">\"row count / sum of imp\"</span> should <span class=\"token string\">\"2, 10 / 2, 14\"</span> in <span class=\"token punctuation\">{</span>\n    <span class=\"token comment\">// Calendar 객체, 2024-01-01 00:00으로 초기화</span>\n    <span class=\"token keyword\">val</span> currentTime <span class=\"token operator\">=</span> Calendar<span class=\"token punctuation\">.</span>getInstance<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    currentTime<span class=\"token punctuation\">.</span>set<span class=\"token punctuation\">(</span><span class=\"token number\">2024</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\n    logs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span>caseClassObjectToJson<span class=\"token punctuation\">(</span>Event<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> calenderToTimestamp<span class=\"token punctuation\">(</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    logs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span>caseClassObjectToJson<span class=\"token punctuation\">(</span>Event<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> calenderToTimestamp<span class=\"token punctuation\">(</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    logs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span>caseClassObjectToJson<span class=\"token punctuation\">(</span>Event<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> calenderToTimestamp<span class=\"token punctuation\">(</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    logs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span>caseClassObjectToJson<span class=\"token punctuation\">(</span>Event<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> calenderToTimestamp<span class=\"token punctuation\">(</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    logs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span>caseClassObjectToJson<span class=\"token punctuation\">(</span>Event<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> calenderToTimestamp<span class=\"token punctuation\">(</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    logs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span><span class=\"token string\">\"{asdfd}\"</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\">// 깨진 데이터</span>\n\n    <span class=\"token keyword\">val</span> df <span class=\"token operator\">=</span> getDataFrameFromJsonRecordsBySchema<span class=\"token punctuation\">(</span>schema<span class=\"token punctuation\">)</span>  <span class=\"token comment\">// JSON으로 부터 데이터 추출</span>\n    <span class=\"token keyword\">val</span> sink <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> MemorySink\n    <span class=\"token keyword\">val</span> clock <span class=\"token operator\">=</span> getClock<span class=\"token punctuation\">(</span>currentTime<span class=\"token punctuation\">.</span>getTimeInMillis<span class=\"token punctuation\">)</span>  <span class=\"token comment\">// ManualClock을 2024-01-01 00:00으로 초기화</span>\n\n    <span class=\"token comment\">// StreamingQuery 초기화 후, Mini-Batch 1회 수행</span>\n    <span class=\"token keyword\">val</span> streamingQuery <span class=\"token operator\">=</span> getStreamingQuery<span class=\"token punctuation\">(</span>aggClick<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> clock<span class=\"token punctuation\">,</span> sink<span class=\"token punctuation\">,</span> checkpointLocation<span class=\"token punctuation\">,</span> OutputMode<span class=\"token punctuation\">.</span>Update<span class=\"token punctuation\">)</span>\n    streamingQuery<span class=\"token punctuation\">.</span>processAllAvailable<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">// 1회차 Mini-Batch Test. sink.allData는 Seq[Row]를 반환 합니다.</span>\n    info<span class=\"token punctuation\">(</span><span class=\"token string\">\"=== 1 ===\"</span><span class=\"token punctuation\">)</span>\n    info<span class=\"token punctuation\">(</span>rowListToString<span class=\"token punctuation\">(</span>sink<span class=\"token punctuation\">.</span>allData<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    assert<span class=\"token punctuation\">(</span>sink<span class=\"token punctuation\">.</span>allData<span class=\"token punctuation\">.</span>size <span class=\"token operator\">==</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n    assert<span class=\"token punctuation\">(</span>sink<span class=\"token punctuation\">.</span>allData<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">.</span>getAs<span class=\"token punctuation\">[</span><span class=\"token builtin\">Long</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"count\"</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">2L</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">// Clock, CurrentTime 5분 증가</span>\n    clock<span class=\"token punctuation\">.</span>advance<span class=\"token punctuation\">(</span><span class=\"token number\">1000</span> <span class=\"token operator\">*</span> <span class=\"token number\">60</span> <span class=\"token operator\">*</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n    currentTime<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Calendar<span class=\"token punctuation\">.</span>MINUTE<span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\n    logs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span>caseClassObjectToJson<span class=\"token punctuation\">(</span>Event<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> calenderToTimestamp<span class=\"token punctuation\">(</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    logs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span>caseClassObjectToJson<span class=\"token punctuation\">(</span>Event<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> calenderToTimestamp<span class=\"token punctuation\">(</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    logs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span>caseClassObjectToJson<span class=\"token punctuation\">(</span>Event<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> calenderToTimestamp<span class=\"token punctuation\">(</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    logs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span>caseClassObjectToJson<span class=\"token punctuation\">(</span>Event<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> calenderToTimestamp<span class=\"token punctuation\">(</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">// Clock 에서 부터 22분 전의 데이터 삽입</span>\n    currentTime<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>Calendar<span class=\"token punctuation\">.</span>MINUTE<span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">22</span><span class=\"token punctuation\">)</span>\n    logs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span>caseClassObjectToJson<span class=\"token punctuation\">(</span>Event<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> calenderToTimestamp<span class=\"token punctuation\">(</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    logs<span class=\"token punctuation\">.</span>addData<span class=\"token punctuation\">(</span>caseClassObjectToJson<span class=\"token punctuation\">(</span>Event<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> calenderToTimestamp<span class=\"token punctuation\">(</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    streamingQuery<span class=\"token punctuation\">.</span>processAllAvailable<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">// 2회차 Mini-Batch Test</span>\n    info<span class=\"token punctuation\">(</span><span class=\"token string\">\"=== 2 ===\"</span><span class=\"token punctuation\">)</span>\n    info<span class=\"token punctuation\">(</span>rowListToString<span class=\"token punctuation\">(</span>sink<span class=\"token punctuation\">.</span>allData<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    assert<span class=\"token punctuation\">(</span>sink<span class=\"token punctuation\">.</span>allData<span class=\"token punctuation\">.</span>size <span class=\"token operator\">==</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\n    assert<span class=\"token punctuation\">(</span>sink<span class=\"token punctuation\">.</span>allData<span class=\"token punctuation\">.</span>foldLeft<span class=\"token punctuation\">(</span><span class=\"token number\">0L</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">=></span> x <span class=\"token operator\">+</span> y<span class=\"token punctuation\">.</span>getAs<span class=\"token punctuation\">[</span><span class=\"token builtin\">Long</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"count\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">14L</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n</code></pre></div>\n<p>Output은 다음은 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">=== 1 ===\n\n[[2024-01-01 00:00:00.0,2024-01-01 00:10:00.0],1,2]\n[[2023-12-31 23:55:00.0,2024-01-01 00:05:00.0],1,2]\n\n=== 2 ===\n\n[[2024-01-01 00:00:00.0,2024-01-01 00:10:00.0],1,2]\n[[2023-12-31 23:55:00.0,2024-01-01 00:05:00.0],1,2]\n[[2024-01-01 00:05:00.0,2024-01-01 00:15:00.0],1,1]\n[[2024-01-01 00:00:00.0,2024-01-01 00:10:00.0],1,3]\n[[2024-01-01 00:05:00.0,2024-01-01 00:15:00.0],2,1]\n[[2024-01-01 00:00:00.0,2024-01-01 00:10:00.0],2,1]\n[[2024-01-01 00:05:00.0,2024-01-01 00:15:00.0],3,1]\n[[2024-01-01 00:00:00.0,2024-01-01 00:10:00.0],3,1]\n[[2024-01-01 00:05:00.0,2024-01-01 00:15:00.0],4,1]\n[[2024-01-01 00:00:00.0,2024-01-01 00:10:00.0],4,1]</code></pre></div>\n<h3>마치며</h3>\n<p>코드의 길이가 길어서 따라오기가 힘들었을 것으로 예상 됩니다. 해당 <a href=\"https://github.com/JustKode/spark-streaming-playground/blob/feature/sss-unit-test/src/test/scala/kr/justkode/streaming/WatermarkStreamingTest.scala\">Github Repository</a>에 예제 코드를 기록 해 놨으니, 더 자세한 예제가 필요 하다면 Repository를 참조 해 주세요.</p>\n<p>긴 글 읽어 주셔서 감사합니다. 좋은 하루 보내세요! :D</p>","id":"3e003c7c-3b0a-5b57-adcc-4466a148d4fc","frontmatter":{"date":"2024-01-07","path":"/data-engineering/spark-structured-streaming-unit-test","title":"Unit Test of Spark Structured Streaming","tags":["Data-Engineering"],"keyword":"Spark, Spark Structured Streaming, Unit Test","summary":"더 정밀한 Streaming Unit Test를 위해","img":"/post_image/thumbnail/spark-structured-streaming-unit-test.jpeg","series":"Spark Structured Streaming"}}},"pageContext":{"postPath":"/data-engineering/spark-structured-streaming-unit-test","series":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"3e003c7c-3b0a-5b57-adcc-4466a148d4fc","excerpt":"머릿말 안녕하세요? 새해부터 찾아온 JustKode, 박민재입니다. 오늘은 Spark Structured Streaming에 대한 Unit Test를 수행 하는 법에 대해서 공유 드려 보려고 합니다. What is Spark Structured Streaming? Spark Structured Streaming은 Spark SQL API (Dataframe, Dataset)를 이용하여, Streaming…","frontmatter":{"date":"2024-01-07","tags":["Data-Engineering"],"path":"/data-engineering/spark-structured-streaming-unit-test","title":"Unit Test of Spark Structured Streaming","img":"/post_image/thumbnail/spark-structured-streaming-unit-test.jpeg","summary":"더 정밀한 Streaming Unit Test를 위해"}}},{"node":{"id":"900d112f-9ad2-52a1-99f9-d2106ddec93b","excerpt":"안녕하세요? 오늘은 Spark Structured Streaming에 대해서 알아 보도록 하겠습니다. Spark Structured Streaming이란? Spark Structured Streaming은, Spark SQL (Dataset/DataFrame) 엔진 기반의, 확장 가능하고, 내결함성이 있는 Stream Processing Engine 입니다. 이는 Batch 작업에서 구조화된 데이터를 처리 하는 것 처럼, Streaming…","frontmatter":{"date":"2023-05-13","tags":["Data-Engineering"],"path":"/data-engineering/spark-structured-streaming","title":"Spark Structured Streaming이란?","img":"/post_image/thumbnail/spark-structured-streaming.png","summary":"Spark로 Streaming Job을 수행 해 보자."}}}]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"ac2612fc-bbdf-504f-94d9-d2bab40e68e6","excerpt":"안녕하세요? 박민재입니다. 오늘날의 Data Engineer…","frontmatter":{"date":"2025-03-26","tags":["Data-Engineering"],"path":"/data-engineering/dbt-intro","title":"dbt란 무엇인가?","img":"/post_image/thumbnail/dbt-intro.webp","summary":"SQL을 바탕으로 Data Transformation Pipeline을 구성해 주는 dbt를 알아보자."}}},{"node":{"id":"dec9e599-9444-556f-99ba-7a1dc27a4dbb","excerpt":"안녕하세요, 박민재입니다. 혹시 Data Discovery에 중요성을 느껴, DataHub를 사용하려고 하시는 분이 있나요? 아마 그렇다면 DataHub를 도입한 사례를 몇 개 읽어 보셨을꺼라 생각합니다. 대표적으로 국내 기업에서는 뱅크샐러드, 소카, 베이글코드 등에서 성공적으로 도입한 사례들을 회사 사이트에 올리는 경우를 확인 할 수 있었어요. SOCAR BankSalad BagelCode DataHub…","frontmatter":{"date":"2025-03-02","tags":["Data-Engineering"],"path":"/data-engineering/to-datahub-user","title":"DataHub 도입을 고려 하시는 분들에게","img":"/post_image/thumbnail/to-datahub-user.webp","summary":"DataHub를 도입 하려고 할 때 알아야 할 점"}}},{"node":{"id":"24718dd5-aa23-578b-aa81-0ca11fcc0f06","excerpt":"안녕하세요, 박민재입니다. 저번 시간에는 Spark Operator가 무엇인지 간단하게 알아 보았는데요, 이번 시간에는 실제로 Spark Operator Helm Chart를 설치하여, Spark Operator 관련 구동 준비를 한 후, Spark Operator 관련 Resource를 작성 하여 실제 Job을 제출 해 보는 시간을 가져 보도록 하겠습니다. Spark Operator Helm Chart Spark Operator…","frontmatter":{"date":"2025-02-02","tags":["Data-Engineering"],"path":"/data-engineering/spark-operator-2","title":"Spark Operator - 2. Practice","img":"/post_image/thumbnail/spark-operator.jpg","summary":"Spark Operator를 사용 해 보자."}}},{"node":{"id":"9ec3e659-5978-5311-b4d5-fc9d0902e008","excerpt":"안녕하세요, 박민재입니다. 아마 2년 전 즈음에 Spark on Kubernetes 관련 내용을 다뤘었는데요 (이 글 또한, 개정판을 작성 해 볼게요), 이번에는 Spark Job을 Kubernetes Cluster에 편리하게 제출할 수 있게 하는 Spark Operator에 대해 알아 보도록 하겠습니다. Spark on Kubernetes를 사용하는 이유? 그렇다고, 이 글에서 아예 설명 하지 않고 넘어가는 것은 아닌 것 같아, Spark…","frontmatter":{"date":"2025-01-19","tags":["Data-Engineering"],"path":"/data-engineering/spark-operator-1","title":"Spark Operator - 1. Spark Operator란?","img":"/post_image/thumbnail/spark-operator.jpg","summary":"Kubernetes Cluster로의 Spark Job 제출을 도와주는 Spark Operator가 무엇 인지 알아보자."}}}]}}}}},"staticQueryHashes":["3819017183","63159454"],"slicesMap":{}}