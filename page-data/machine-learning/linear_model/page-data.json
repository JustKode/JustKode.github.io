{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/machine-learning/linear_model","result":{"data":{"markdownRemark":{"html":"<p><strong>머신 러닝</strong>을 통해 해결 할 수 있는 문제는 매우 다양합니다. <strong>지도 학습</strong>을 통한 <strong>분류</strong> 문제의 해결, <strong>회귀 분석</strong> 을 통한 값의 예측, <strong>비지도 학습</strong>을 통한 <strong>군집화</strong> 등등 많은 문제가 있습니다.</p>\n<p>만약 당신이 집을 팔려고 한다고 가정 하겠습니다. 당신의 집은 화장실 갯수에 따라, 사는 지역에 따라, 역과의 거리에 따라 종속적으로 집의 가격이 바뀔 것 입니다. 이 아이디어에서 착안한 것이 <strong>선형 회귀</strong> 입니다.</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>D</mi></mrow><annotation encoding=\"application/x-tex\">D</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span></span></span></span>차원의 벡터 독립 변수 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span></span></span></span>가 존재한다고 가정 하면, 그에 따른 종속 변수 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span></span> 가 있다고 가정하여, 선형 상관 관계를 모델링 하는 것이 <strong>선형 회귀</strong> 입니다. 선형 회귀의 가장 기본 형태인 <strong>직선 함수</strong>를 식으로 도식화해보면 다음과 같습니다.</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi><mo>=</mo><msub><mi>w</mi><mn>0</mn></msub><mo>+</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo>+</mo><msub><mi>w</mi><mi>D</mi></msub><msub><mi>x</mi><mi>D</mi></msub></mrow><annotation encoding=\"application/x-tex\">y = w_0 + w_1x_1 + ... + w_Dx_D</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">D</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">D</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>\n<p>선형 회귀에 더 자세히 알고 싶다면...<br>\n<a href=\"https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80\">https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80</a></p>\n<h2>코드로 구현하기</h2>\n<p>일단 이를 구현하는 방법은 매우 간단합니다! 우선 <code class=\"language-text\">scikit-learn</code>을 우선 설치 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">$ pip install -U scikit-learn</code></pre></div>\n<p>그 다음 <code class=\"language-text\">sklearn</code> 모듈 안에 있는 <code class=\"language-text\">linear_model</code>을 import 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn <span class=\"token keyword\">import</span> linear_model</code></pre></div>\n<p>그 다음 <code class=\"language-text\">linear_model</code>에 있는 <code class=\"language-text\">LinearRegression</code> 객체를 호출 후, <code class=\"language-text\">fit()</code> 메소드를 이용하여 데이터를 학습합니다. 첫 번째 인자로는 입력 값 <code class=\"language-text\">list</code> 객체를, 두 번째 인자로는 출력 값 <code class=\"language-text\">list</code> 객체를 넣습니다. 단, <strong>입력 값 리스트</strong>에 있는 <strong>원소들의 차원</strong>은 전부 다 <strong>일치</strong> 하여야 합니다.</p>\n<p>여기서 <code class=\"language-text\">fit()</code> 메소드는 <a href=\"https://ko.wikipedia.org/wiki/%EA%B2%BD%EC%82%AC_%ED%95%98%EA%B0%95%EB%B2%95\">경사 하강법</a>을 이용, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo>∑</mo><mrow><mo fence=\"true\">∣</mo><mi>w</mi><mi>x</mi><mo>−</mo><mi>y</mi><mo fence=\"true\">∣</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\sum \\left|wx-y\\right|</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.00001em;vertical-align:-0.25001em;\"></span><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">∣</span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose delimcenter\" style=\"top:0em;\">∣</span></span></span></span></span>의 값을 최대한 줄이는 방향으로 학습 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">reg <span class=\"token operator\">=</span> linear_model<span class=\"token punctuation\">.</span>LinearRegression<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nreg<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><code class=\"language-text\">coef_</code> 어트리뷰트로 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">w_1, w_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 값을 확인 할 수 있습니다. 입력 값 리스트에 있는 <strong>원소들의 차원 수</strong>에 따라 가변 적으로 늘어 나는 것을 확인 할 수 있습니다. 또한, <code class=\"language-text\">intercept_</code> 어트리뷰트로 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>w</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">w_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 값을 확인 할 수 있습니다.\n<br></p>\n<ul>\n<li><strong>In</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">reg_2d <span class=\"token operator\">=</span> linear_model<span class=\"token punctuation\">.</span>LinearRegression<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nreg_2d<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>reg_2d<span class=\"token punctuation\">.</span>coef_<span class=\"token punctuation\">,</span> reg_2d<span class=\"token punctuation\">.</span>intercept_<span class=\"token punctuation\">)</span>\n\nreg_3d <span class=\"token operator\">=</span> linear_model<span class=\"token punctuation\">.</span>LinearRegression<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nreg_3d<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2.5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>reg_3d<span class=\"token punctuation\">.</span>coef_<span class=\"token punctuation\">,</span> reg_3d<span class=\"token punctuation\">.</span>intercept_<span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n<ul>\n<li><strong>Out</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">[0.5 0.5] 1.0\n[0.5 0.5 0.5] 1.0000000000000002</code></pre></div>\n<h2>다항 회귀</h2>\n<p>가지고 있는 데이터가 직선보다 복잡한 형태일 경우, 각 특성의 거듭제곱을 새로운 특성으로 추가하고, 이렇게 새롭게 만들어진 특성에 대해 선형 모델을 훈련시키는 <strong>다항 회귀</strong> 방법을 사용 할 수 있습니다. <code class=\"language-text\">sklearn.preprocessing</code> 모듈 내의 <code class=\"language-text\">PolynomialFeatures</code> 클래스를 이용 하여 거듭제곱의 특성을 새로 추가 할 수 있습니다.</p>\n<ul>\n<li><strong>In</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> LinearRegression\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>preprocessing <span class=\"token keyword\">import</span> PolynomialFeatures\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n\nX <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ny <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">**</span> <span class=\"token number\">2</span> <span class=\"token operator\">+</span> X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># y = x_1^2 + x_2 + 1</span>\n\npoly_features <span class=\"token operator\">=</span> PolynomialFeatures<span class=\"token punctuation\">(</span>degree<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> include_bias<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\nX_poly <span class=\"token operator\">=</span> poly_features<span class=\"token punctuation\">.</span>fit_transform<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># [x_1, x_2]</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>X_poly<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># [x_1, x_2, x_1^2, x_1*x_2, x_2^2]</span>\n\nlin <span class=\"token operator\">=</span> LinearRegression<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nlin<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_poly<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>lin<span class=\"token punctuation\">.</span>intercept_<span class=\"token punctuation\">,</span> lin<span class=\"token punctuation\">.</span>coef_<span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n<ul>\n<li><strong>Out</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">[0.0800759  0.82814432]\n[0.0800759  0.82814432 0.00641215 0.0663144  0.68582302]\n0.9999999999999999 [ 7.06703197e-16  1.00000000e+00  1.00000000e+00  6.66133815e-16\n -5.68989300e-16]</code></pre></div>\n<h2>마치며</h2>\n<p>선형 회귀를 할 때, 훈련 하는 모델은 다양한 형태가 존재 하기 때문에, 더 알고 싶은 사람은 다음 링크를 참조 해 주세요. <br>\n<a href=\"https://scikit-learn.org/stable/modules/linear_model.html\">https://scikit-learn.org/stable/modules/linear_model.html</a></p>","id":"c4e88f21-45c2-5afa-aa92-8e953640c859","frontmatter":{"date":"2020-06-13","path":"/machine-learning/linear_model","title":"Python으로 알아보는 선형 회귀","tags":["Machine-Learning","Python"],"keyword":"scikit-learn, 싸이킷런, 선형 회귀, Linear Regression","summary":"scikit-learn으로 알아보는 Linear Regression","img":"https://miro.medium.com/max/683/1*h6PuI6-PdPE8d4dTnhcg3w.png","series":"ML Basic"}}},"pageContext":{"series":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"d8ce5f6a-8189-5355-8550-00649acaaa99","excerpt":"저번 시간에는 선형 회귀에 대해서 배워 보았습니다. 선형 회귀는 차원의 벡터 독립 변수 가 존재한다고 가정 하면, 그에 따른 종속 변수  가 있다고 가정하여, 선형 상관 관계를 모델링 하는 것이라고 배웠습니다. 예시 코드를 보겠습니다. 하지만, 범주형 변수에 대해서 생각을 해 보겠습니다. 예를 들어, 50점 이상이면 합격, 이하면 불합격이고, 이를 합격일 시 1로, 불합격일 시…","frontmatter":{"date":"2020-07-16","tags":["Machine-Learning","Python"],"path":"/machine-learning/logistic-regression","title":"수식과 코드로 알아보는 로지스틱 회귀","img":"https://memegenerator.net/img/instances/73789366.jpg","summary":"수식과 코드로 통해 보는 Logistic Regression"}}},{"node":{"id":"c4e88f21-45c2-5afa-aa92-8e953640c859","excerpt":"…","frontmatter":{"date":"2020-06-13","tags":["Machine-Learning","Python"],"path":"/machine-learning/linear_model","title":"Python으로 알아보는 선형 회귀","img":"https://miro.medium.com/max/683/1*h6PuI6-PdPE8d4dTnhcg3w.png","summary":"scikit-learn으로 알아보는 Linear Regression"}}}]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"a272e5eb-daef-505b-91e4-ddb97a4caf45","excerpt":"Normalization, PCA 안녕하세요? Justkode 입니다. 이번 시간에는 Normalization (정규화)와, 차원 축소를 위한 PCA에 대해 공부 해 보는 시간을 가져 보도록 하겠습니다. 정규화와 차원 축소는 기계 학습에서 중요 한 요소 입니다. 학습에서 직접적인 영향을 주기 때문이죠. Normalization 저번에 Linear Regression의 Cost Function에 대한 미분을 하게 되면, Input Vector…","frontmatter":{"date":"2021-07-25","tags":["Data-Science","Machine-Learning"],"path":"/data-science/just-data-science-8","title":"[찍먹 Data Science] 8. Normalization, PCA","img":"/post_image/thumbnail/just-data-science-8.jpg","summary":"값의 범위를 줄이고, 차원을 효율 적으로 줄여보자."}}},{"node":{"id":"8276c1fb-09d2-5fea-a583-b11d7ca961a3","excerpt":"SVM, K-NN, Random Forest 안녕하세요? Justkode 입니다. 저번 시간에는 선형 회귀와 분류에 대해 공부 해 보았습니다. 그런데 Logistic Regression…","frontmatter":{"date":"2021-07-21","tags":["Data-Science","Machine-Learning"],"path":"/data-science/just-data-science-7","title":"[찍먹 Data Science] 7. SVM, K-NN, Random forest","img":"/post_image/thumbnail/just-data-science-7.jpg","summary":"자주 사용 되는 ML 모델을 사용 해 보자."}}},{"node":{"id":"a15e6d2e-d923-5e8e-9bb9-ae1c7116c1bc","excerpt":"Linear Regression, Classification 안녕하세요? Justkode 입니다. 오늘은 선형 회귀와 분류에 대해 이론을 공부 해 보고, 실습을 진행 해 보는 시간을 가져 보도록 하겠습니다. Before we start 먼저 이번 실습에는  모듈이 필요합니다. 다음을 통해 설치 해 주세요. (단, numpy, pandas, matplotlib이 설치 되어 있다면 scikit-learn만 설치 하셔도 됩니다.) Linear…","frontmatter":{"date":"2021-07-21","tags":["Data-Science","Machine-Learning"],"path":"/data-science/just-data-science-6","title":"[찍먹 Data Science] 6. Linear Regression, Logistic Regression","img":"/post_image/thumbnail/just-data-science-6.jpg","summary":"선형 회귀와 로지스틱 회귀에 대해서 알아 보자."}}},{"node":{"id":"5a9d9d37-ba85-593d-9e17-cd7082bc18c6","excerpt":"Maching Learning Basic. 안녕하세요? Justkode 입니다. 오늘은 머신 러닝의 기본 개념에 대해 공부 해 보는 시간을 가져 보도록 하겠습니다. 학습의 종류 머신 러닝 학습의 종류는 두 종류가 있습니다.  지도 학습 (Supervised Learning) 첫 번째는 지도 학습입니다. 지도 학습은 훈련 데이터로 Feature(특징)와 Target…","frontmatter":{"date":"2021-07-19","tags":["Data-Science","Machine-Learning"],"path":"/data-science/just-data-science-5","title":"[찍먹 Data Science] 5. Machine Learning Basic","img":"/post_image/thumbnail/just-data-science-5.jpg","summary":"머신 러닝의 기본 개념에 대해 알아보자."}}}]}}}}},"staticQueryHashes":["234633779","63159454"]}