{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-science/just-data-science-9","result":{"data":{"markdownRemark":{"html":"<h2>Deep Neural Network</h2>\n<p>안녕하세요? 오늘은 <strong>DNN</strong>, <strong>Deep Neural Network</strong>에 대해서 알아 보도록 하겠습니다.</p>\n<p>여태까지 우리는 <strong>간단한 선형 모델</strong>에 대해서만 학습을 진행 하였습니다. <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi><mo>=</mo><mi>w</mi><mi>X</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">y = wX + b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">b</span></span></span></span> (혹은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi><mo>=</mo><msub><mi>w</mi><mn>0</mn></msub><msub><mi>x</mi><mn>0</mn></msub><mo>+</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo>+</mo><msub><mi>w</mi><mi>n</mi></msub><msub><mi>x</mi><mi>n</mi></msub><mo>+</mo><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">y = w_0x_0 + w_1x_1 + ... + w_nx_n + b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">b</span></span></span></span>) 와 같이, 선형 연산을 통해서, 데이터에 대해서 예측하고, 분류 해 보는 실습을 진행 하였습니다. 하지만, 이러한 <strong>선형적인 모델</strong>이 <strong>비선형적인 문제</strong>를 해결 하려면 어떻게 해야 할까요?</p>\n<p>일단 간단한 예제를 생각 해 보겠습니다. <strong>XOR</strong> 문제를 예시로 들겠습니다. 우리가 과연 <strong>XOR</strong> 문제를 <strong>머신 러닝 파트</strong>에서 배웠던 것 처럼, <strong>선형 분리</strong>가 가능 할 까요?</p>\n<p>답은 '가능하지 않다' 입니다. 우리가 데이터를 이렇게 묶으면, 하나의 x값에 대해, 두 가지 y값이 나오게 되므로 선형 함수로는 데이터를 분류 하는 것은 불가능 해 보입니다. 이는 <strong>퍼셉트론(선형 분류기)의 한계</strong>를 설명 할 때 등장하는 XOR(exclusive OR) 문제 입니다.</p>\n<p align=\"center\">\n       <img src=\"/post_image/just-data-science/09-01.png\" width=\"50%\"/>\n       <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n              XOR Gate\n       </p>\n</p>\n<p>우리는 이 문제를 해결하기 위해서 어떻게 하면 좋을까요? 방법은, <strong>층을 쌓는 것</strong> 입니다. 보이시는 그래프처럼 두 가지 분류 기준을 만듭니다. 그림으로 직관적으로 보면, <strong>파란색 선 아래, 청록색 선 위</strong>에 존재하는 데이터를 추출 하는 방식으로 말이죠.</p>\n<p align=\"center\">\n       <img src=\"/post_image/just-data-science/09-02.png\" width=\"50%\"/>\n       <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n              XOR Gate\n       </p>\n</p>\n<p>파란색 선 위, 아래를 각각 0, 1 이라고 가정하고, 이를 x축에 대입 하겠습니다.</p>\n<p>그 다음, 청록색 선 위, 아래를 각각 1, 0 이라고 가정하고, 이를 y축에 대입 하겠습니다.</p>\n<p>그러면 다음과 같은 그래프가 만들어 지겠네요. 이제 <strong>선형 분류</strong>가 가능 하게 되었습니다.</p>\n<p align=\"center\">\n       <img src=\"/post_image/just-data-science/09-03.png\" width=\"50%\"/>\n       <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n              XOR to new dimension\n       </p>\n</p>\n<p>위 과정을 그래프가 아닌 그림으로 나타 내 보겠습니다. 그러면 인공 지능에 관심이 있으셨다면 한번쯤 봤을 그림을 볼 수 있을 것 입니다.</p>\n<p>파란색 선은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>=</mo><msub><mi>w</mi><mn>11</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>21</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">n_1 = w_{11}x_1 + w_{21}x_2 + b_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 에 대한 결과, 청록색 선은, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>n</mi><mn>2</mn></msub><mo>=</mo><msub><mi>w</mi><mn>12</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>22</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">n_2 = w_{12}x_1 + w_{22}x_2 + b_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>에 대한 결과로 나타 낼 수 있을 것입니다. 그리고 파란색 선, 청록색 선에 대한 각각의 분류 결과를 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>y</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">y_{out}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\">u</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>으로 보내는 것이지요. 그렇게 우리는 비선형적인 정보들도 분류 할 수 있는 것 입니다.</p>\n<p align=\"center\">\n       <img src=\"/post_image/just-data-science/09-04.png\" width=\"50%\"/>\n       <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n              Multi-Layer Perceptron\n       </p>\n</p>\n<p>이렇게 <strong>Multi-Layer Perceptron</strong>에 대해서 연구가 이루어 진 결과, 우리는 적절한 층과, 적절한 노드 갯수를 이용하여 우리는 <strong>선형 모델</strong>이 분류 하지 못했던 것들을 분류 할 수 있게 되었습니다. 또한, <strong>역전파 알고리즘</strong>에 대한 연구가 이루어져서, 층을 3개 이상 쌓는 <strong>Deep Nerual Network</strong>의 부흥기가 시작 되었습니다. 자, 이제 우리는 이를 통해, 새로운 것들을 만들어 보고자 합니다.</p>\n<p>우리가 오늘 해 볼 것은, <strong>DNN을 이용한 Fashion MNIST Dataset</strong> 분류 입니다. 여기서 말하는 <strong>Fashion MNIST</strong>는 입력이 28x28 크기의 행렬로 이루어져 있고 출력은 10개의 분류로 나타 냅니다. 열 개의 분류는 다음과 같습니다. (T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot)</p>\n<p>데이터의 크기는, 6만 개의 학습용 이미지, 만개의 테스트용 이미지로 구성 되어 있습니다.</p>\n<p>일단 <strong>DNN</strong>을 구현 해 보기 전에, Pytorch에 대한 기본 사용법에 대해 다루는 내용들을 보고 오는 것을 추천 드립니다.</p>\n<ul>\n<li><a href=\"https://justkode.kr/deep-learning/pytorch-basic\">Pytorch Basic</a></li>\n<li><a href=\"https://justkode.kr/deep-learning/pytorch-autograd\">Pytorch Autograd</a></li>\n</ul>\n<h2>Fashion MNIST</h2>\n<p>일단, Module 부터 먼저 <strong>Import</strong> 해 보겠습니다. <code class=\"language-text\">pytorch</code>와 <code class=\"language-text\">torchvision</code>에 대한 데이터를 가져 옵니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 여러분의 정신 건강을 위해, 그냥 프로젝트 옮길 때마다 복붙 해서 쓰는 것을 추천 드립니다.</span>\n<span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>functional <span class=\"token keyword\">as</span> F\n<span class=\"token keyword\">from</span> torch<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>data <span class=\"token keyword\">import</span> Dataset\n<span class=\"token keyword\">from</span> torchvision<span class=\"token punctuation\">.</span>datasets <span class=\"token keyword\">import</span> FashionMNIST\n<span class=\"token keyword\">from</span> torchvision <span class=\"token keyword\">import</span> transforms\n<span class=\"token keyword\">from</span> torch<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>data <span class=\"token keyword\">import</span> DataLoader\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt</code></pre></div>\n<p>첫 번째로, 데이터를 불러 오기 전, 데이터를 전처리 하기 위한 <strong>파이프 라인</strong>을 구성 해 보겠습니다. 아래 코드는 <strong>Input Data</strong>를 <strong>Tensor</strong>로 만들고, 이를 <strong>Z-Score Normalization</strong>을 하는 모습입니다. <code class=\"language-text\">transforms.Compose</code>를 이용하여 파이프라인을 구성하고, <code class=\"language-text\">transforms.ToTensor()</code>를 통해 <code class=\"language-text\">Tensor</code>로의 변환, <code class=\"language-text\">transforms.Normalize</code>를 통해 Z-Score Normalization을 실시 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">RANDOM_SEED <span class=\"token operator\">=</span> <span class=\"token number\">123</span>\nDEVICE <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>device<span class=\"token punctuation\">(</span><span class=\"token string\">'cuda:0'</span> <span class=\"token keyword\">if</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>is_available<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">else</span> <span class=\"token string\">'cpu'</span><span class=\"token punctuation\">)</span>\n\ncustom_train_transform <span class=\"token operator\">=</span> transforms<span class=\"token punctuation\">.</span>Compose<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>  \n                                             transforms<span class=\"token punctuation\">.</span>ToTensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                             transforms<span class=\"token punctuation\">.</span>Normalize<span class=\"token punctuation\">(</span>mean<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> std<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\ncustom_test_transform <span class=\"token operator\">=</span> transforms<span class=\"token punctuation\">.</span>Compose<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n                                             transforms<span class=\"token punctuation\">.</span>ToTensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                                             transforms<span class=\"token punctuation\">.</span>Normalize<span class=\"token punctuation\">(</span>mean<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> std<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>두 번째로는 만들어진 <strong>파이프라인</strong>에, <strong>Fashion MNIST</strong> 데이터를 넣어 전처리를 해 보겠습니다. 이는 <code class=\"language-text\">Dataset</code>을 불러 올 때 <code class=\"language-text\">transform</code> 파라미터에 값을 넣어 줌으로써 가능 합니다.</p>\n<p><code class=\"language-text\">DataLoader</code>를 통해 <strong>데이터 셋</strong>을 <strong>미니 배치</strong>로 분류하고, <strong>데이터를 섞어 줄 수</strong> 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">BATCH_SIZE <span class=\"token operator\">=</span> <span class=\"token number\">64</span>\n\ntrain_dataset <span class=\"token operator\">=</span> FashionMNIST<span class=\"token punctuation\">(</span><span class=\"token string\">\".\"</span><span class=\"token punctuation\">,</span> train<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> download<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> transform<span class=\"token operator\">=</span>custom_train_transform<span class=\"token punctuation\">)</span>\n\ntrain_loader <span class=\"token operator\">=</span> DataLoader<span class=\"token punctuation\">(</span>dataset<span class=\"token operator\">=</span>train_dataset<span class=\"token punctuation\">,</span>\n                          batch_size<span class=\"token operator\">=</span>BATCH_SIZE<span class=\"token punctuation\">,</span>\n                          shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                          drop_last<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n                          num_workers<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n\n\ntest_dataset <span class=\"token operator\">=</span> FashionMNIST<span class=\"token punctuation\">(</span><span class=\"token string\">\".\"</span><span class=\"token punctuation\">,</span> train<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> download<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span> transform<span class=\"token operator\">=</span>custom_test_transform<span class=\"token punctuation\">)</span>\n\ntest_loader <span class=\"token operator\">=</span> DataLoader<span class=\"token punctuation\">(</span>dataset<span class=\"token operator\">=</span>test_dataset<span class=\"token punctuation\">,</span>\n                         batch_size<span class=\"token operator\">=</span>BATCH_SIZE<span class=\"token punctuation\">,</span>\n                         shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                         num_workers<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>아래 창은 데이터가 잘 다운로드 되었는지 확인 하는 코드입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> batch_idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>train_loader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">' | Batch size:'</span><span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    x <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>DEVICE<span class=\"token punctuation\">)</span>\n    y <span class=\"token operator\">=</span> y<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>DEVICE<span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"X shape: \"</span><span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Y shape: \"</span><span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'break minibatch for-loop'</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">break</span></code></pre></div>\n<h2>Deep Neural Network</h2>\n<p>이제 <strong>DNN 모델</strong>을 구현 해 볼 시간입니다. 한 번 구현을 해 볼까요?</p>\n<p>일단 코드 설명을 드리자면, 가장 먼저 해야할 일은 <code class=\"language-text\">torch.nn.Module</code>을 상속 받은 class를 만드는 것입니다. 그 다음, 생성자와 <code class=\"language-text\">forward</code> 함수를 구현 해 주면 됩니다.</p>\n<p>먼저 생성자 함수는 <code class=\"language-text\">super(클래스명, self).__init__()</code>을 통해, 모델 초기화를 해 주어야 하며, 그 다음으로는 <code class=\"language-text\">torch.nn.Linear</code>로 층을 쌓아 줍니다. <code class=\"language-text\">torch.nn.Linear</code>는 파라미터로 (input<em>features, output</em>features)를 입력 해 줍니다. 입력 차원과 출력 차원을 입력 해 주어야 한다는 것입니다. 층을 입력 해 줄때마다 <strong>Input Vector</strong>에 대해 (input<em>features X output</em>features) 에 대한 행렬 곱을 하는 것과 같습니다.</p>\n<p><code class=\"language-text\">forward</code>에서는 순전파 연산을 진행 합니다. 파라미터로 데이터를 넣어 가면서 통과 시키면 되지만, 여기서 중간에 <strong>ReLU</strong> 함수를 넣는 것을 볼 수가 있습니다. 그 이유는, <strong>y = ax + b</strong> 꼴의 층을 쌓는다고 한들, 층을 하나 더 쌓으면 <strong>y = c(ax + b) + d = acx + bc + d</strong> 꼴이 되기 때문에, 학습이 되지 않습니다. 그렇기 때문에, <strong>활성화 함수</strong>를 사용 합니다. 우리는 현재 가장 대중적으로 사용 되고 있는 <strong>ReLU</strong> 함수를 사용 해 보았습니다.</p>\n<p><strong>ReLU</strong> 함수는 0보다 작거나 같으면 0을, 0보다 크면 그대로 값을 반환 합니다.</p>\n<p>여기서 적절한 층의 갯수나, 층별 노드 갯수는 어떻게 정해 질까요? 답은 <strong>해결 하고자 하는 문제에 따라 다르다</strong> 입니다. 검색해 보면 해결하고자 하는 문제에 따라 어떻게 노드와 층을 설계했을지 성능이 잘 나오는지, 벤치마킹 테스트 결과를 나타낸 결과 혹은 논문이 있습니다. 이를 참고하여 모델을 설계 해 주면 됩니다.</p>\n<p><a href=\"https://paperswithcode.com/\">https://paperswithcode.com/</a> 다음 사이트를 참조 하시면, 많은 논문들을 코드로 구현한 것을 볼 수가 있습니다.</p>\n<p>일단, 층이 너무 깊으면 학습이 안되고, Overfitting에 빠진 가능성이 높습니다. 노드가 너무 많으면 시간이 너무 오래 걸리고, 이에 따른 성능 향상도 크지 않아요. 고로, 적절한 노드 갯수과, 적절한 층의 갯수를 선택 하는 것이 좋습니다!</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">DNN</span><span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> num_features<span class=\"token punctuation\">,</span> num_hidden_1<span class=\"token punctuation\">,</span> num_hidden_2<span class=\"token punctuation\">,</span> num_hidden_3<span class=\"token punctuation\">,</span> num_classes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>DNN<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        \n        self<span class=\"token punctuation\">.</span>num_classes <span class=\"token operator\">=</span> num_classes\n        \n        self<span class=\"token punctuation\">.</span>linear_1 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>num_features<span class=\"token punctuation\">,</span> num_hidden_1<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>linear_2 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>num_hidden_1<span class=\"token punctuation\">,</span> num_hidden_2<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>linear_3 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>num_hidden_2<span class=\"token punctuation\">,</span> num_hidden_3<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>linear_out <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>num_hidden_3<span class=\"token punctuation\">,</span> num_classes<span class=\"token punctuation\">)</span>\n        \n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">### activation 함수 변경 가능</span>\n        <span class=\"token comment\">### (optional)레이어간의 연결 추가, 변경 가능</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>linear_1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>linear_2<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>linear_3<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        logits <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>linear_out<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        probas <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>sigmoid<span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> logits<span class=\"token punctuation\">,</span> probas\n    \nrandom<span class=\"token punctuation\">.</span>seed<span class=\"token punctuation\">(</span>RANDOM_SEED<span class=\"token punctuation\">)</span>\ntorch<span class=\"token punctuation\">.</span>manual_seed<span class=\"token punctuation\">(</span>RANDOM_SEED<span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> DNN<span class=\"token punctuation\">(</span>num_features<span class=\"token operator\">=</span><span class=\"token number\">28</span><span class=\"token operator\">*</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span>\n            num_hidden_1<span class=\"token operator\">=</span><span class=\"token number\">1024</span><span class=\"token punctuation\">,</span>\n            num_hidden_2<span class=\"token operator\">=</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span>\n            num_hidden_3<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span>\n            num_classes<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>DEVICE<span class=\"token punctuation\">)</span></code></pre></div>\n<h2>Training</h2>\n<p>Training 과정에 대한 코드는 주석으로 설명 하겠습니다. 다음 코드를 실행하면 학습이 진행 됩니다. 하지만, 여기 내부에 있는 함수들을 Pytorch Documentation에서 하나하나 공부하여 내부 원리를 파악 하는 것을 추천드립니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">optimizer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>SGD<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 파라미터 학습을 위한 optimizer, 경사 하강법에 도움을 줌</span>\nNUM_EPOCHS <span class=\"token operator\">=</span> <span class=\"token number\">20</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">compute_accuracy_and_loss</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> data_loader<span class=\"token punctuation\">,</span> device<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># 손실 계산</span>\n    correct_pred<span class=\"token punctuation\">,</span> num_examples <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span>\n    cross_entropy <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">.</span>\n    <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">,</span> targets<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>data_loader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># 미니 배치 iteration</span>\n            \n        features <span class=\"token operator\">=</span> features<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token operator\">*</span><span class=\"token number\">28</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># view를 통해 [batch_size * 784] 크기로 변경</span>\n        targets <span class=\"token operator\">=</span> targets<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 타겟</span>\n\n        logits<span class=\"token punctuation\">,</span> probas <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 모델 결과 반환 (결과, sigmoid 적용한 결과)</span>\n        cross_entropy <span class=\"token operator\">+=</span> F<span class=\"token punctuation\">.</span>cross_entropy<span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">,</span> targets<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 타겟과 연산 결과의 cost 결과</span>\n        _<span class=\"token punctuation\">,</span> predicted_labels <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span>probas<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 예측 결과 반환</span>\n        num_examples <span class=\"token operator\">+=</span> targets<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># input 개수 반환</span>\n        correct_pred <span class=\"token operator\">+=</span> <span class=\"token punctuation\">(</span>predicted_labels <span class=\"token operator\">==</span> targets<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 맞은 갯수 반환</span>\n    <span class=\"token keyword\">return</span> correct_pred<span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">/</span>num_examples <span class=\"token operator\">*</span> <span class=\"token number\">100</span><span class=\"token punctuation\">,</span> cross_entropy<span class=\"token operator\">/</span>num_examples  <span class=\"token comment\"># 정확도, cost 평균</span>\n    \n\nstart_time <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 시작 시간 계산</span>\ntrain_acc_lst<span class=\"token punctuation\">,</span> test_acc_lst <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># 훈련 데이터 정확도, 테스트 데이터 정확도</span>\ntrain_loss_lst<span class=\"token punctuation\">,</span> test_loss_lst <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># 훈련 데이터 손실함수, 테스트 데이터 손실함수</span>\n\n<span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>NUM_EPOCHS<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># EPOCH 만큼 반복</span>\n    \n    model<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 학습 모드</span>\n    \n    <span class=\"token keyword\">for</span> batch_idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">,</span> targets<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>train_loader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  <span class=\"token comment\"># 미니 배치 iteration</span>\n    \n        <span class=\"token comment\">### PREPARE MINIBATCH</span>\n        features <span class=\"token operator\">=</span> features<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token operator\">*</span><span class=\"token number\">28</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>DEVICE<span class=\"token punctuation\">)</span>\n        targets <span class=\"token operator\">=</span> targets<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>DEVICE<span class=\"token punctuation\">)</span>\n            \n        <span class=\"token comment\">### FORWARD AND BACK PROP</span>\n        logits<span class=\"token punctuation\">,</span> probas <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>features<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 순전파</span>\n        cost <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>cross_entropy<span class=\"token punctuation\">(</span>logits<span class=\"token punctuation\">,</span> targets<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 예측 결과에 대한 cost 계산</span>\n        optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 기울기 0 초기화</span>\n        \n        cost<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 역전파</span>\n        \n        <span class=\"token comment\">### UPDATE MODEL PARAMETERS</span>\n        optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 모델 파라미터 업데이트</span>\n        \n        <span class=\"token comment\">### LOGGING</span>\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> batch_idx <span class=\"token operator\">%</span> <span class=\"token number\">40</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span> <span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'Epoch: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>epoch<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">03d</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">/</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>NUM_EPOCHS<span class=\"token punctuation\">:</span><span class=\"token format-spec\">03d</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> | '</span></span>\n                   <span class=\"token string-interpolation\"><span class=\"token string\">f'Batch </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>batch_idx<span class=\"token punctuation\">:</span><span class=\"token format-spec\">03d</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">/</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_loader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">03d</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> |'</span></span> \n                   <span class=\"token string-interpolation\"><span class=\"token string\">f' Cost: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>cost<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.4f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># 매 Epoch마다 evaluation을 진행합니다. </span>\n    <span class=\"token comment\"># Epoch마다 Loss를 기록하여 학습과정을 살펴보고 Underfitting, Overfitting 여부를 확인합니다.</span>\n    model<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">with</span> torch<span class=\"token punctuation\">.</span>set_grad_enabled<span class=\"token punctuation\">(</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\"># Gradient 계산이 안되도록</span>\n        train_acc<span class=\"token punctuation\">,</span> train_loss <span class=\"token operator\">=</span> compute_accuracy_and_loss<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> train_loader<span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>DEVICE<span class=\"token punctuation\">)</span> <span class=\"token comment\"># train acc, loss 계산</span>\n        test_acc<span class=\"token punctuation\">,</span> test_loss <span class=\"token operator\">=</span> compute_accuracy_and_loss<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> test_loader<span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span>DEVICE<span class=\"token punctuation\">)</span>    <span class=\"token comment\"># test acc, loss 계산</span>\n        \n        <span class=\"token comment\"># list에 train, test의  acc, loss 추가</span>\n        train_acc_lst<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>train_acc<span class=\"token punctuation\">)</span>\n        test_acc_lst<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>test_acc<span class=\"token punctuation\">)</span>\n        train_loss_lst<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>train_loss<span class=\"token punctuation\">)</span>\n        test_loss_lst<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>test_loss<span class=\"token punctuation\">)</span>\n        \n        <span class=\"token comment\"># 로깅</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'Epoch: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>epoch<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token format-spec\">03d</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">/</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>NUM_EPOCHS<span class=\"token punctuation\">:</span><span class=\"token format-spec\">03d</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> Train Acc.: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>train_acc<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">%'</span></span>\n              <span class=\"token string-interpolation\"><span class=\"token string\">f' | Test Acc.: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>test_acc<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">%'</span></span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># 1 epoch 학습 소요시간</span>\n    elapsed <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> start_time<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">60</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'Time elapsed: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>elapsed<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> min'</span></span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 총 학습 소요시간</span>\nelapsed <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> start_time<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">60</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'Total Training Time: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>elapsed<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\"> min'</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">Epoch: 001/020 | Batch 000/937 | Cost: 2.3114\nEpoch: 001/020 | Batch 040/937 | Cost: 2.2735\nEpoch: 001/020 | Batch 080/937 | Cost: 2.2252\n...\nEpoch: 020/020 | Batch 800/937 | Cost: 0.3877\nEpoch: 020/020 | Batch 840/937 | Cost: 0.1904\nEpoch: 020/020 | Batch 880/937 | Cost: 0.1722\nEpoch: 020/020 | Batch 920/937 | Cost: 0.3173\nEpoch: 020/020 Train Acc.: 90.89% | Test Acc.: 87.81%\nTime elapsed: 4.73 min\nTotal Training Time: 4.73 min</code></pre></div>\n<h2>Evaluation</h2>\n<p>테스트 데이터와 학습 데이터의 Loss변화를 확인합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> NUM_EPOCHS<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> train_loss_lst<span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Training loss'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> NUM_EPOCHS<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> test_loss_lst<span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Test loss'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'upper right'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'Cross entropy'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'Epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p align=\"center\">\n       <img src=\"/post_image/just-data-science/09-05.png\" width=\"50%\"/>\n       <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n              Loss Graph\n       </p>\n</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> NUM_EPOCHS<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> train_acc_lst<span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Training accuracy'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> NUM_EPOCHS<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> test_acc_lst<span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'Test accuracy'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">'upper left'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'Accuracy'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'Epoch'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p align=\"center\">\n       <img src=\"/post_image/just-data-science/09-06.png\" width=\"50%\"/>\n       <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n              Accuracy Graph\n       </p>\n</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">model<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">with</span> torch<span class=\"token punctuation\">.</span>set_grad_enabled<span class=\"token punctuation\">(</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token comment\"># save memory during inference</span>\n    test_acc<span class=\"token punctuation\">,</span> test_loss <span class=\"token operator\">=</span> compute_accuracy_and_loss<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> test_loader<span class=\"token punctuation\">,</span> DEVICE<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'Test accuracy: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>test_acc<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.2f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">%'</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">Test accuracy: 87.81%</code></pre></div>\n<h3>마치며</h3>\n<p>이렇게 간단하게(?) <strong>DNN</strong> 모델을 개발하여, 학습 해 보았습니다. 생각보다 사진 정보에 대한 학습 성능이 좋지 않았습니다. 왜 일까요? 답은, 우리가 이미지 부분부분에 대한 정보가 아닌 이미지를 쫙 펴서, 픽셀 정보로만 학습을 했기 때문입니다. 그렇기 때문에, 우리는 이미지의 국소적인 정보를 추출 하는 것이 중요합니다. 세로, 가로 정보 같은 것들 말이죠. 다음 시간에는 이에 대한 단점을 해결한 <strong>CNN</strong>에 대해서 배워 보겠습니다.</p>","id":"e708c84f-fcff-5de6-9204-de9a7569750c","frontmatter":{"date":"2021-07-29","path":"/data-science/just-data-science-9","title":"[찍먹 Data Science] 9. Deep Neural Network","tags":["Data-Science","Deep-Learning"],"keyword":"Data Science, 데이터 사이언스, Deep Learning, 딥러닝","summary":"딥러닝의 기초, DNN에 대해서 알아 보자.","img":"/post_image/thumbnail/just-data-science-9.jpg","series":"찍먹 Data Science"}}},"pageContext":{"series":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"49a9d801-a31f-50ec-8e5b-d29b96e4a2de","excerpt":"Generative Adversarial Network 안녕하세요? 오늘은 GAN, Generative Adversarial Network에 대해서 알아 보도록 하겠습니다. Generative Adversarial Network…","frontmatter":{"date":"2021-08-07","tags":["Data-Science","Deep-Learning"],"path":"/data-science/just-data-science-12","title":"[찍먹 Data Science] 12. Generative Adversarial Network","img":"/post_image/thumbnail/just-data-science-12.jpg","summary":"서로가 적대적으로 학습하는 GAN에 대해서 알아 보자."}}},{"node":{"id":"8b853027-d41f-5306-8cb9-8242edaf29c1","excerpt":"Recurrent Neural Network 안녕하세요? 오늘은 RNN, Recurrent Neural Network에 대해서 알아 보도록 하겠습니다. RNN…","frontmatter":{"date":"2021-08-05","tags":["Data-Science","Deep-Learning"],"path":"/data-science/just-data-science-11","title":"[찍먹 Data Science] 11. Recurrent Neural Network","img":"/post_image/thumbnail/just-data-science-11.jpg","summary":"시계열 데이터를 처리하는 RNN을 알아보자."}}},{"node":{"id":"78aa3994-0aa2-55e7-b6cb-0ebc85c57591","excerpt":"Convolutional Neural Network 안녕하세요? 오늘은 CNN, Convolutional Neural Network에 대해서 알아 보도록 하겠습니다. 저번 시간에는 DNN…","frontmatter":{"date":"2021-07-31","tags":["Data-Science","Deep-Learning"],"path":"/data-science/just-data-science-10","title":"[찍먹 Data Science] 10. Convolutional Neural Network","img":"/post_image/thumbnail/just-data-science-10.jpg","summary":"국소적인 정보를 추출하는 CNN에 대해 알아 보자."}}},{"node":{"id":"e708c84f-fcff-5de6-9204-de9a7569750c","excerpt":"Deep Neural Network 안녕하세요? 오늘은 DNN, Deep Neural Network에 대해서 알아 보도록 하겠습니다. 여태까지 우리는 간단한 선형 모델에 대해서만 학습을 진행 하였습니다.  (혹은 ) 와 같이, 선형 연산을 통해서, 데이터에 대해서 예측하고, 분류 해 보는 실습을 진행 하였습니다. 하지만, 이러한 선형적인 모델이 비선형적인 문제를 해결 하려면 어떻게 해야 할까요? 일단 간단한 예제를 생각 해 보겠습니다. XOR…","frontmatter":{"date":"2021-07-29","tags":["Data-Science","Deep-Learning"],"path":"/data-science/just-data-science-9","title":"[찍먹 Data Science] 9. Deep Neural Network","img":"/post_image/thumbnail/just-data-science-9.jpg","summary":"딥러닝의 기초, DNN에 대해서 알아 보자."}}},{"node":{"id":"a272e5eb-daef-505b-91e4-ddb97a4caf45","excerpt":"Normalization, PCA 안녕하세요? Justkode 입니다. 이번 시간에는 Normalization (정규화)와, 차원 축소를 위한 PCA에 대해 공부 해 보는 시간을 가져 보도록 하겠습니다. 정규화와 차원 축소는 기계 학습에서 중요 한 요소 입니다. 학습에서 직접적인 영향을 주기 때문이죠. Normalization 저번에 Linear Regression의 Cost Function에 대한 미분을 하게 되면, Input Vector…","frontmatter":{"date":"2021-07-25","tags":["Data-Science","Machine-Learning"],"path":"/data-science/just-data-science-8","title":"[찍먹 Data Science] 8. Normalization, PCA","img":"/post_image/thumbnail/just-data-science-8.jpg","summary":"값의 범위를 줄이고, 차원을 효율 적으로 줄여보자."}}},{"node":{"id":"a15e6d2e-d923-5e8e-9bb9-ae1c7116c1bc","excerpt":"Linear Regression, Classification 안녕하세요? Justkode 입니다. 오늘은 선형 회귀와 분류에 대해 이론을 공부 해 보고, 실습을 진행 해 보는 시간을 가져 보도록 하겠습니다. Before we start 먼저 이번 실습에는  모듈이 필요합니다. 다음을 통해 설치 해 주세요. (단, numpy, pandas, matplotlib이 설치 되어 있다면 scikit-learn만 설치 하셔도 됩니다.) Linear…","frontmatter":{"date":"2021-07-21","tags":["Data-Science","Machine-Learning"],"path":"/data-science/just-data-science-6","title":"[찍먹 Data Science] 6. Linear Regression, Logistic Regression","img":"/post_image/thumbnail/just-data-science-6.jpg","summary":"선형 회귀와 로지스틱 회귀에 대해서 알아 보자."}}},{"node":{"id":"8276c1fb-09d2-5fea-a583-b11d7ca961a3","excerpt":"SVM, K-NN, Random Forest 안녕하세요? Justkode 입니다. 저번 시간에는 선형 회귀와 분류에 대해 공부 해 보았습니다. 그런데 Logistic Regression…","frontmatter":{"date":"2021-07-21","tags":["Data-Science","Machine-Learning"],"path":"/data-science/just-data-science-7","title":"[찍먹 Data Science] 7. SVM, K-NN, Random forest","img":"/post_image/thumbnail/just-data-science-7.jpg","summary":"자주 사용 되는 ML 모델을 사용 해 보자."}}},{"node":{"id":"5a9d9d37-ba85-593d-9e17-cd7082bc18c6","excerpt":"Maching Learning Basic. 안녕하세요? Justkode 입니다. 오늘은 머신 러닝의 기본 개념에 대해 공부 해 보는 시간을 가져 보도록 하겠습니다. 학습의 종류 머신 러닝 학습의 종류는 두 종류가 있습니다.  지도 학습 (Supervised Learning) 첫 번째는 지도 학습입니다. 지도 학습은 훈련 데이터로 Feature(특징)와 Target…","frontmatter":{"date":"2021-07-19","tags":["Data-Science","Machine-Learning"],"path":"/data-science/just-data-science-5","title":"[찍먹 Data Science] 5. Machine Learning Basic","img":"/post_image/thumbnail/just-data-science-5.jpg","summary":"머신 러닝의 기본 개념에 대해 알아보자."}}},{"node":{"id":"67ae44e3-5a48-57d9-87ea-fd77d9876c34","excerpt":"SQL 안녕하세요? Justkode 입니다. 오늘은 SQL에 대해서 간단하게 알아보는 시간을 가져보도록 하겠습니다. SQL은 Structured Query Language의 약자로, RDBMS의 데이터베이스를 주로 조회 하는데에 사용이 되는, 데이터베이스 관리 시스템(RDBMS)의 데이터를 관리하기 위해 설계된 특수 목적의 프로그래밍 언어입니다. 여기서 설명 하는 문법들은 많은 내용을 담지 않고, SQL…","frontmatter":{"date":"2021-07-11","tags":["Data-Science","Python"],"path":"/data-science/just-data-science-4","title":"[찍먹 Data Science] 4. SQL","img":"/post_image/thumbnail/just-data-science-4.jpg","summary":"SQL의 기본 문법에 대해 알아보자."}}},{"node":{"id":"72999af7-d2c7-5f95-8d6c-eb8d5219cd76","excerpt":"Matplotlib 안녕하세요? Justkode 입니다. 오늘은 Matplotlib에 대해서 알아보는 시간을 가져보도록 하겠습니다. Matplotlib는 데이터 분석을 위해 만들어진 라이브러리로 Numpy, Pandas…","frontmatter":{"date":"2021-07-08","tags":["Data-Science","Python"],"path":"/data-science/just-data-science-3","title":"[찍먹 Data Science] 3. Matplotlib","img":"/post_image/thumbnail/just-data-science-3.jpeg","summary":"데이터 시각화 모듈, Matplotlib을 알아보자."}}},{"node":{"id":"05ccbb5b-48d4-57d0-9f3b-ca1dae54ed34","excerpt":"Pandas 안녕하세요? Justkode 입니다. 오늘은 Pandas에 대해서 심층있게 알아보는 시간을 가져보도록 하겠습니다. Pandas는 데이터 분석을 위해 만들어진 라이브러리로 Numpy와 함께 많이 사용 됩니다. 주로 사용하는 데이터 구조는 Dataframe과 Series로, Table 정보와 같은 데이터를 처리 하는데 이점이 있습니다. Series and DataFrame 첫 번째로 Series입니다. Series는…","frontmatter":{"date":"2021-07-04","tags":["Data-Science","Python"],"path":"/data-science/just-data-science-2","title":"[찍먹 Data Science] 2. Pandas","img":"/post_image/thumbnail/just-data-science-2.jpg","summary":"데이터 분석에 쓰이는 Pandas를 알아보자."}}},{"node":{"id":"c29d290f-1001-5de9-8997-cb6fe729221b","excerpt":"Data Science And Math 안녕하세요? Justkode 입니다. 많은 Machine Learning과 Deep Learning…","frontmatter":{"date":"2021-06-30","tags":["Data-Science","Python"],"path":"/data-science/just-data-science-1","title":"[찍먹 Data Science] 1. Math, Numpy","img":"/post_image/thumbnail/just-data-science-1.jpg","summary":"간단한 수학 식을 Numpy로 구현해 보자"}}},{"node":{"id":"d0d8165b-3ac6-5f7f-b1e6-e8fb46731ec5","excerpt":"Data Science, 어디부터 해야 할까? 안녕하세요? Justkode 입니다. 일단, 제가 대학교 1,…","frontmatter":{"date":"2021-06-23","tags":["Data-Science"],"path":"/data-science/just-data-science-0","title":"[찍먹 Data Science] 0. Orientation","img":"/post_image/thumbnail/just-data-science-0.jpg","summary":"Data Science를 찍먹해 보자."}}}]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"0d127ed8-2483-5c3f-9041-36f402ee5ef0","excerpt":"Regularization 안녕하세요? 이번 시간에는 Regularization에 대해서 알아 보도록 하겠습니다. 우리가 모델을 만들 때, 많은 분들이 Overfitting을 경험 해 보셨을 것 입니다. 여러분들은 Overfitting을 경험할 때, 다음과 같은 것들을 시도 해 볼 것입니다. 모델의 크기를 줄인다. (네트워크의 깊이, 노드 갯수 등등) 데이터의 크기를 늘린다. 하지만, 이 외에도 다른 방법들이 있습니다. DropOut…","frontmatter":{"date":"2021-08-31","tags":["Data-Science","Deep-Learning"],"path":"/data-science/regularization","title":"Regularization: 모델의 과적합을 막는 방법","img":"/post_image/thumbnail/regularization.jpg","summary":"모델의 과적합을 막는 Regularization에 대해서 알아 보자."}}},{"node":{"id":"49a9d801-a31f-50ec-8e5b-d29b96e4a2de","excerpt":"Generative Adversarial Network 안녕하세요? 오늘은 GAN, Generative Adversarial Network에 대해서 알아 보도록 하겠습니다. Generative Adversarial Network…","frontmatter":{"date":"2021-08-07","tags":["Data-Science","Deep-Learning"],"path":"/data-science/just-data-science-12","title":"[찍먹 Data Science] 12. Generative Adversarial Network","img":"/post_image/thumbnail/just-data-science-12.jpg","summary":"서로가 적대적으로 학습하는 GAN에 대해서 알아 보자."}}},{"node":{"id":"8b853027-d41f-5306-8cb9-8242edaf29c1","excerpt":"Recurrent Neural Network 안녕하세요? 오늘은 RNN, Recurrent Neural Network에 대해서 알아 보도록 하겠습니다. RNN…","frontmatter":{"date":"2021-08-05","tags":["Data-Science","Deep-Learning"],"path":"/data-science/just-data-science-11","title":"[찍먹 Data Science] 11. Recurrent Neural Network","img":"/post_image/thumbnail/just-data-science-11.jpg","summary":"시계열 데이터를 처리하는 RNN을 알아보자."}}},{"node":{"id":"78aa3994-0aa2-55e7-b6cb-0ebc85c57591","excerpt":"Convolutional Neural Network 안녕하세요? 오늘은 CNN, Convolutional Neural Network에 대해서 알아 보도록 하겠습니다. 저번 시간에는 DNN…","frontmatter":{"date":"2021-07-31","tags":["Data-Science","Deep-Learning"],"path":"/data-science/just-data-science-10","title":"[찍먹 Data Science] 10. Convolutional Neural Network","img":"/post_image/thumbnail/just-data-science-10.jpg","summary":"국소적인 정보를 추출하는 CNN에 대해 알아 보자."}}}]}}}}},"staticQueryHashes":["234633779","63159454"]}