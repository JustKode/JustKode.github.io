{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-science/just-data-science-5/","result":{"data":{"markdownRemark":{"html":"<h2>Maching Learning Basic.</h2>\n<p>안녕하세요? <strong>Justkode</strong> 입니다. 오늘은 <strong>머신 러닝의 기본 개념</strong>에 대해 공부 해 보는 시간을 가져 보도록 하겠습니다.</p>\n<h2>학습의 종류</h2>\n<p>머신 러닝 학습의 종류는 두 종류가 있습니다.</p>\n<h3>지도 학습 (Supervised Learning)</h3>\n<p>첫 번째는 <strong>지도 학습</strong>입니다. <strong>지도 학습</strong>은 <strong>훈련 데이터</strong>로 **Feature(특징)**와 <strong>Target(결과)</strong> 쌍이 주어지며, <strong>훈련 데이터</strong>로부터 <strong>하나의 함수</strong>(모델)를 유추해내기 위한 <strong>기계 학습</strong>의 하나의 방법입니다. 가장 기본적인 형태이며, <strong>Feature</strong>를 <strong>모델에 삽입하여 나오는 결과 값</strong>과 <strong>실제 결과</strong>를 비교 하는 방식으로 학습 합니다. 다시 한번 직관적으로 설명 드리자면, <strong>주어진 데이터를 통해 결과 값을 예측하는 함수를 만든다</strong>라고 할 수 있을 것 같습니다.</p>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/05-01.jpg\" width=\"30%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\tx1, x2는 Feature, y는 Target\n\t</p>\n</p>\n<p>다음은 <strong>지도 학습</strong>의 종류 대해서 알아 보겠습니다.</p>\n<ul>\n<li><strong>회귀(Regression)</strong>: 회귀 문제는 한 개 이상의 <strong>독립 변수</strong> (Feature)와 <strong>종속 변수</strong> y (Target)와의 관계를 모델링 하여, <strong>연속적인 결과</strong> 값을 예측하는 데에 사용 됩니다. 예시로는 부동산 가격 예측, 키를 통한 몸무게의 예측 등등이 있겠습니다.</li>\n</ul>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/05-02.jpg\" width=\"30%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\t회귀의 예시\n\t</p>\n</p>\n<ul>\n<li><strong>분류(Regression)</strong>: 분류 문제는 한 개 이상의 <strong>독립 변수</strong> (Feature)와 <strong>종류</strong> y (Target)와의 관계를 모델링 하여 <strong>비연속적인 결과</strong>, 즉 분류를 목표로 합니다. 예시로는, 키와 몸무게를 통한 남/여 예측, 줄기의 길이와 너비를 통한 붓꽃 품종 예측 등이 있겠습니다.</li>\n</ul>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/05-03.jpg\" width=\"30%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\t분류의 예시\n\t</p>\n</p>\n<h3>비지도 학습 (Unsupervised Learning)</h3>\n<p>두 번째는 <strong>비지도 학습</strong>입니다. <strong>비지도 학습</strong>은 <strong>훈련 데이터</strong>로 <strong>Feature(특징)</strong> 만이 주어 집니다. \"아니, 이게 무슨 의미가 있나?\" 하실 수도 있지만, <strong>비지도 학습</strong>은 데이터간 <strong>숨겨진 구조</strong>를 찾는 데 사용 됩니다.</p>\n<p>예시를 들자면 다음과 같습니다.</p>\n<ul>\n<li><strong>군집(Cluster)</strong>: 입력된 데이터를 비슷한 것들끼지 묶는 것을 **군집화(Clustering)**이라고 하고, 이렇게 묶인 집합을 **군집(Cluster)**이라고 합니다. 이를 통해, 잡음 추출, 연관 게시글 추천등을 할 수 있습니다.</li>\n</ul>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/05-04.jpg\" width=\"30%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\t군집의 예시\n\t</p>\n</p>\n<ul>\n<li><strong>차원 축소</strong>: 혹은 비지도 학습은 <strong>비슷한 Feature</strong> 관계성을 나타 내는 차원에 대해, <strong>차원을 축소</strong> 시키는 기능을 수행 할 수 있습니다. 예로는 <strong>매니폴드 구조</strong>가 있습니다.</li>\n</ul>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/05-05.png\" width=\"50%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\t차원 촉소의 예시\n\t</p>\n</p>\n<h2>Dataset의 분류</h2>\n<p>우리가 모델을 학습 시키기 위한 Dataset은 다음과 같이 분류 할 수 있습니다.</p>\n<ul>\n<li><strong>훈련 세트 (Train Set)</strong>: 모델을 훈련 시키기 위해 사용 합니다.</li>\n<li><strong>검증 세트 (Validation Set)</strong>: 모델의 <strong>일반화 성능을 검증</strong>하기 위해 사용 합니다. 여러 개의 모델을 중간 까지 학습 시킨 후, 일반화 성능이 좋은 모델을 선택하여 계속 학습 하고자 할 때 선택 합니다.</li>\n<li><strong>테스트 세트 (Test Set)</strong>: 모델의 성능이 목표치에 달성 했을 때, 최종 평가에 사용 됩니다.</li>\n</ul>\n<h3>Overfitting?</h3>\n<p><strong>Overfitting</strong>이란, <strong>훈련 세트</strong>에 대해서는 모델이 <strong>높은 정확도</strong>를 보이나, <strong>테스트 세트</strong>에 대해서는 <strong>낮은 정확도</strong>를 보일 때를 말합니다. 다시 말하면, <strong>일반화 성능이 떨어짐을 의미</strong>하며, 이를 해결하기 위해선 <strong>검증 세트</strong>를 이용하여, 여러 가지 모델에 대해 일반화 성능을 평가 한 후, <strong>일반화 성능이 더 좋은 모델을 선택하여 학습</strong>하거나, <strong>Feature</strong>의 갯수를 최소화 하거나, <strong>더 많은 데이터 셋</strong>사용, <strong>더 단순한 모델</strong> 사용 등이 있겠습니다.</p>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/05-10.jpg\" width=\"50%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\t파란색이 일반화 면에서 이상적, 빨간색처럼 Noisy한 데이터 까지 캐치 할 필요는 없다.\n\t</p>\n</p>\n<h2>Cost Function (비용 함수)</h2>\n<p>우리가 학습이 잘 되었는지, 안 되었는지 어떻게 판단 할 수 있을가요? 이는 각 목적에 맞는 **비용 함수 (Cost Function)**를 사용 함으로써 알 수 있습니다. (혹은 이는 **Loss Function(손실 함수)**라고도 불립니다.)</p>\n<p>만약 우리가 <strong>회귀</strong>에 대해서 학습이 잘 되었는지 수치적 평가를 하고자 합니다. 그럴 때는 어떻게 하면 될까요? 답은 <strong>정답과 예측 값의 제곱의 합</strong>을 더함으로써, 수치의 차가 적으면 적을 수록, 학습이 잘 되었다고 판단 할 수 있습니다.</p>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/05-06.gif\" width=\"20%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\tMSE (Mean Square Error)\n\t</p>\n</p>\n<p>혹은 이제 <strong>분류</strong>에 대해서 학습이 잘 되었는지 수치적 평가를 하고자 할 때는요? 그럴 때는, 해당 문제를 <strong>답으로 예측한 확률과 실제 분류의 차이 값에 로그를 씌운 값을 더함</strong>으로써 가능 합니다.</p>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/05-07.gif\" width=\"20%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\tCross-Entropy Loss, C는 클래스의 갯수, t_i는 참이면 1, 아니면 0, s_i는 예측한 확률\n\t</p>\n</p>\n<p><strong>군집</strong>이 잘 되었는지는 어떻게 판단 할 수 있을까요? 이는 아마 군집들의 평균값과 군집 샘플과의 거리의 합이 될 수도 있겠네요.</p>\n<p>아무튼 이런 식으로, <strong>모델이 잘 학습 되었는지에 대한 평가</strong>를 통해, 이를 <strong>줄여 나가는 방식으로 학습</strong>하면 될 것입니다. 그런데 어떻게 학습 하냐고요..?</p>\n<h2>Gradient Descent (경사 하강법)</h2>\n<p><a href=\"https://justkode.kr/data-science/just-data-science-1\">1강</a>때 진행 했던 **계산 그래프(Computational Graph)**를 기억 하시나요? <strong>계산 그래프</strong>를 이용해서, 우리는 <strong>손실 함수를 줄이는 방향으로 값을 이동</strong>하면, 이에 맞는 파라미터 또한 같이 <strong>계산 그래프에서 전달된 미분 값</strong>을 바탕으로 파라미터 값을 변경 해 주면 될 것입니다.</p>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/01-06.png\" width=\"30%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n        Cost Function의 미분을 구한 후, 경사를 따라 내려 감.\n\t</p>\n</p>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/01-07.jpg\" width=\"60%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\t구한 미분 값을 바탕으로, 이를 파라미터에 전달함.\n\t</p>\n</p>\n<p>사실, 경사 하강법을 하는 방법은 매우 다양합니다. 우리가 정직하게 내려 가면, 그것은 <strong>극소에서 멈출 가능성</strong>이 높습니다.</p>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/05-08.jpg\" width=\"50%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\t손실 함수 그래프가 이렇게 생겨 버리면..? 생각보다 킹받는 상황.\n\t</p>\n</p>\n<p>극소값에서 멈추지 않게 하기 위해, 다음과 같이 여러개의 경사 하강법을 사용 할 수 있습니다.</p>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/05-09.gif\" width=\"50%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\t다양한 경사 하강법\n\t</p>\n</p>\n<h3>배치와 미니 배치, 확률적 경사 하강법</h3>\n<p>학습을 할 때, <strong>행렬 연산을 한꺼번에 하느냐, 나누어서 하느냐</strong>에 따라 경사 하강법의 종류가 달라집니다.</p>\n<ul>\n<li><strong>배치 경사 하강법 (Batch Gradient Descent: BGD)</strong>: 배치 경사 하강법은, <strong>전체 학습 데이터를 묶어서 학습</strong> 시키는 경사 하강법 입니다. <strong>안정적인 수렴이 가능</strong>하지만, 속도가 느리고, 극소값에 갇힐 확률이 늘어 납니다.</li>\n</ul>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/05-11.jpg\" width=\"50%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\t배치 경사 하강법\n\t</p>\n</p>\n<ul>\n<li><strong>확률적 경사 하강법 (Stochastic Gradient Descent: SGD)</strong>: 확률적 경사 하강법은 <strong>하나의 데이터 당, 한 번 학습</strong>을 진행 하는 방법으로, <strong>극소값에 갇힐 확률이 적지만,</strong> 노이즈가 심하고, <strong>병렬 연산</strong>에 능한 GPU를 잘 활용 할 수 없습니다.</li>\n</ul>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/05-12.jpg\" width=\"50%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\t확률적 경사 하강법\n\t</p>\n</p>\n<ul>\n<li><strong>미니 배치 확률적 경사 하강법 (Mini-Batch Stochastic Gradient Descent: MSGD)</strong>: 미니 배치 확률적 경사 하강법은 <strong>하나의 배치를, 여러 개의 미니 배치로 쪼어 학습</strong> 하는 방식으로, <strong>배치 경사 하강법과, 확률적 경사 하강법의 중간 경계</strong>라고 생각 할 수 있습니다.</li>\n</ul>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/05-13.jpg\" width=\"50%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\t미니 배치 확률적 경사 하강법\n\t</p>\n</p>\n<h2>학습 과정</h2>\n<p>고로 <strong>기계학습의 학습 과정</strong>은 다음과 같습니다.</p>\n<ol>\n<li>데이터에 맞는 <strong>적절한 모델, 손실 함수</strong>과 <strong>하이퍼 파라미터</strong>를 사용 합니다.</li>\n<li>가지고 있는 데이터를 바탕으로 현재 모델에 대해서 <strong>손실 함수를 계산</strong>합니다.</li>\n<li>손실 함수가 낮아지는 방향으로 <strong>경사 하강법을 진행</strong> 합니다.</li>\n<li>2 ~ 3번의 과정을 <strong>원하는 결과 (정확도)가 나올 때 까지 반복</strong> 합니다.</li>\n<li>(검증 데이터셋이 있고, 여러 개의 모델을 학습 중일 때) <strong>검증 데이터 셋</strong>을 통해 일반화 성능을 비교 하고, 좋은 일반화 성능을 가진 모델을 원하는 결과가 나올 때 까지, 다시 학습 합니다.</li>\n<li><strong>테스트 데이터 셋</strong>으로 <strong>검증</strong>합니다.</li>\n</ol>\n<h2>마치며</h2>\n<p>이번 시간에는 <strong>머신 러닝의 필수 기본 개념</strong>에 대해서 배워 보았습니다. 다음 시간에는 <strong>선형 회귀와 로지스틱 회귀</strong>에 대해 이론을 알아 보고, <code class=\"language-text\">scikit-learn</code>으로 실습 하는 시간을 가져 보도록 하겠습니다.</p>","id":"054cd65e-03d6-5c3c-b0f2-e171db0bbaa9","frontmatter":{"date":"2021-07-19","path":"/data-science/just-data-science-5","title":"[찍먹 Data Science] 5. Machine Learning Basic","tags":["Data-Science","Machine-Learning","Archive"],"keyword":"Data Science, 데이터 사이언스, Machine Learning, 머신 러닝","summary":"머신 러닝의 기본 개념에 대해 알아보자.","img":"/post_image/thumbnail/just-data-science-5.jpg","series":"찍먹 Data Science"}}},"pageContext":{"postPath":"/data-science/just-data-science-5","series":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"698a9c45-a694-5162-83e2-df87f531ce2c","excerpt":"Generative Adversarial Network 안녕하세요? 오늘은 GAN, Generative Adversarial Network에 대해서 알아 보도록 하겠습니다. Generative Adversarial Network…","frontmatter":{"date":"2021-08-07","tags":["Data-Science","Deep-Learning","Archive"],"path":"/data-science/just-data-science-12","title":"[찍먹 Data Science] 12. Generative Adversarial Network","img":"/post_image/thumbnail/just-data-science-12.jpg","summary":"서로가 적대적으로 학습하는 GAN에 대해서 알아 보자."}}},{"node":{"id":"624bc092-2941-5c7a-9da0-9a5bc005200f","excerpt":"Recurrent Neural Network 안녕하세요? 오늘은 RNN, Recurrent Neural Network에 대해서 알아 보도록 하겠습니다. RNN…","frontmatter":{"date":"2021-08-05","tags":["Data-Science","Deep-Learning","Archive"],"path":"/data-science/just-data-science-11","title":"[찍먹 Data Science] 11. Recurrent Neural Network","img":"/post_image/thumbnail/just-data-science-11.jpg","summary":"시계열 데이터를 처리하는 RNN을 알아보자."}}},{"node":{"id":"436261e2-af47-5094-b1cb-cd18bad403c4","excerpt":"Convolutional Neural Network 안녕하세요? 오늘은 CNN, Convolutional Neural Network에 대해서 알아 보도록 하겠습니다. 저번 시간에는 DNN…","frontmatter":{"date":"2021-07-31","tags":["Data-Science","Deep-Learning","Archive"],"path":"/data-science/just-data-science-10","title":"[찍먹 Data Science] 10. Convolutional Neural Network","img":"/post_image/thumbnail/just-data-science-10.jpg","summary":"국소적인 정보를 추출하는 CNN에 대해 알아 보자."}}},{"node":{"id":"6e88111c-5a0d-5a25-964f-b61f8280477b","excerpt":"Deep Neural Network 안녕하세요? 오늘은 DNN, Deep Neural Network에 대해서 알아 보도록 하겠습니다. 여태까지 우리는 간단한 선형 모델에 대해서만 학습을 진행 하였습니다.  (혹은 ) 와 같이, 선형 연산을 통해서, 데이터에 대해서 예측하고, 분류 해 보는 실습을 진행 하였습니다. 하지만, 이러한 선형적인 모델이 비선형적인 문제를 해결 하려면 어떻게 해야 할까요? 일단 간단한 예제를 생각 해 보겠습니다. XOR…","frontmatter":{"date":"2021-07-29","tags":["Data-Science","Deep-Learning","Archive"],"path":"/data-science/just-data-science-9","title":"[찍먹 Data Science] 9. Deep Neural Network","img":"/post_image/thumbnail/just-data-science-9.jpg","summary":"딥러닝의 기초, DNN에 대해서 알아 보자."}}},{"node":{"id":"6f7b18e9-32a4-5a08-b237-7b9a08821c9d","excerpt":"Normalization, PCA 안녕하세요? Justkode 입니다. 이번 시간에는 **Normalization (정규화)**와, 차원 축소를 위한 PCA에 대해 공부 해 보는 시간을 가져 보도록 하겠습니다. 정규화와 차원 축소는 기계 학습에서 중요 한 요소 입니다. 학습에서 직접적인 영향을 주기 때문이죠. Normalization 저번에 Linear Regression의 Cost Function에 대한 미분을 하게 되면, Input…","frontmatter":{"date":"2021-07-25","tags":["Data-Science","Machine-Learning","Archive"],"path":"/data-science/just-data-science-8","title":"[찍먹 Data Science] 8. Normalization, PCA","img":"/post_image/thumbnail/just-data-science-8.jpg","summary":"값의 범위를 줄이고, 차원을 효율 적으로 줄여보자."}}},{"node":{"id":"62c99c1e-2ef6-5a5d-aa55-08b7ef88c8e1","excerpt":"Linear Regression, Classification 안녕하세요? Justkode 입니다. 오늘은 선형 회귀와 분류에 대해 이론을 공부 해 보고, 실습을 진행 해 보는 시간을 가져 보도록 하겠습니다. Before we start 먼저 이번 실습에는  모듈이 필요합니다. 다음을 통해 설치 해 주세요. (단, numpy, pandas, matplotlib이 설치 되어 있다면 scikit-learn만 설치 하셔도 됩니다.) Linear…","frontmatter":{"date":"2021-07-21","tags":["Data-Science","Machine-Learning","Archive"],"path":"/data-science/just-data-science-6","title":"[찍먹 Data Science] 6. Linear Regression, Logistic Regression","img":"/post_image/thumbnail/just-data-science-6.jpg","summary":"선형 회귀와 로지스틱 회귀에 대해서 알아 보자."}}},{"node":{"id":"6a5775e6-c516-509c-9c96-36caf04e38b2","excerpt":"SVM, K-NN, Random Forest 안녕하세요? Justkode 입니다. 저번 시간에는 선형 회귀와 분류에 대해 공부 해 보았습니다. 그런데 Logistic Regression…","frontmatter":{"date":"2021-07-21","tags":["Data-Science","Machine-Learning","Archive"],"path":"/data-science/just-data-science-7","title":"[찍먹 Data Science] 7. SVM, K-NN, Random forest","img":"/post_image/thumbnail/just-data-science-7.jpg","summary":"자주 사용 되는 ML 모델을 사용 해 보자."}}},{"node":{"id":"054cd65e-03d6-5c3c-b0f2-e171db0bbaa9","excerpt":"Maching Learning Basic. 안녕하세요? Justkode 입니다. 오늘은 머신 러닝의 기본 개념에 대해 공부 해 보는 시간을 가져 보도록 하겠습니다. 학습의 종류 머신 러닝 학습의 종류는 두 종류가 있습니다. 지도 학습 (Supervised Learning) 첫 번째는 지도 학습입니다. 지도 학습은 훈련 데이터로 **Feature(특징)**와 Target…","frontmatter":{"date":"2021-07-19","tags":["Data-Science","Machine-Learning","Archive"],"path":"/data-science/just-data-science-5","title":"[찍먹 Data Science] 5. Machine Learning Basic","img":"/post_image/thumbnail/just-data-science-5.jpg","summary":"머신 러닝의 기본 개념에 대해 알아보자."}}},{"node":{"id":"d22f27b6-4eb7-525c-b9c8-3e7fa34cd4fc","excerpt":"SQL 안녕하세요? Justkode 입니다. 오늘은 SQL에 대해서 간단하게 알아보는 시간을 가져보도록 하겠습니다. SQL은 Structured Query Language의 약자로, RDBMS의 데이터베이스를 주로 조회 하는데에 사용이 되는, 데이터베이스 관리 시스템(RDBMS)의 데이터를 관리하기 위해 설계된 특수 목적의 프로그래밍 언어입니다. 여기서 설명 하는 문법들은 많은 내용을 담지 않고, SQL…","frontmatter":{"date":"2021-07-11","tags":["Data-Science","Python","Archive"],"path":"/data-science/just-data-science-4","title":"[찍먹 Data Science] 4. SQL","img":"/post_image/thumbnail/just-data-science-4.jpg","summary":"SQL의 기본 문법에 대해 알아보자."}}},{"node":{"id":"eb2ed1e4-be19-5e89-865c-b3733d2e2029","excerpt":"Matplotlib 안녕하세요? Justkode 입니다. 오늘은 Matplotlib에 대해서 알아보는 시간을 가져보도록 하겠습니다. Matplotlib는 데이터 분석을 위해 만들어진 라이브러리로 Numpy, Pandas…","frontmatter":{"date":"2021-07-08","tags":["Data-Science","Python","Archive"],"path":"/data-science/just-data-science-3","title":"[찍먹 Data Science] 3. Matplotlib","img":"/post_image/thumbnail/just-data-science-3.jpeg","summary":"데이터 시각화 모듈, Matplotlib을 알아보자."}}},{"node":{"id":"d44a4255-a2d5-5b07-a7e9-1cd24112445a","excerpt":"Pandas 안녕하세요? Justkode 입니다. 오늘은 Pandas에 대해서 심층있게 알아보는 시간을 가져보도록 하겠습니다. Pandas는 데이터 분석을 위해 만들어진 라이브러리로 Numpy와 함께 많이 사용 됩니다. 주로 사용하는 데이터 구조는 Dataframe과 Series로, Table 정보와 같은 데이터를 처리 하는데 이점이 있습니다. Series and DataFrame 첫 번째로 Series입니다. Series는…","frontmatter":{"date":"2021-07-04","tags":["Data-Science","Python","Archive"],"path":"/data-science/just-data-science-2","title":"[찍먹 Data Science] 2. Pandas","img":"/post_image/thumbnail/just-data-science-2.jpg","summary":"데이터 분석에 쓰이는 Pandas를 알아보자."}}},{"node":{"id":"48359f74-97a6-5283-bb9a-210c96d8e13c","excerpt":"Data Science And Math 안녕하세요? Justkode 입니다. 많은 Machine Learning과 Deep Learning…","frontmatter":{"date":"2021-06-30","tags":["Data-Science","Python","Archive"],"path":"/data-science/just-data-science-1","title":"[찍먹 Data Science] 1. Math, Numpy","img":"/post_image/thumbnail/just-data-science-1.jpg","summary":"간단한 수학 식을 Numpy로 구현해 보자"}}},{"node":{"id":"b8351f08-b827-510b-a60a-caa72c82cf61","excerpt":"Data Science, 어디부터 해야 할까? 안녕하세요? Justkode 입니다. 일단, 제가 대학교 1,…","frontmatter":{"date":"2021-06-23","tags":["Data-Science","Archive"],"path":"/data-science/just-data-science-0","title":"[찍먹 Data Science] 0. Orientation","img":"/post_image/thumbnail/just-data-science-0.jpg","summary":"Data Science를 찍먹해 보자."}}}]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[]}}}}},"staticQueryHashes":["3819017183","63159454"],"slicesMap":{}}