{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-science/just-data-science-8","result":{"data":{"markdownRemark":{"html":"<h2>Normalization, PCA</h2>\n<p>안녕하세요? <strong>Justkode</strong> 입니다. 이번 시간에는 <strong>Normalization (정규화)</strong>와, 차원 축소를 위한 <strong>PCA</strong>에 대해 공부 해 보는 시간을 가져 보도록 하겠습니다. <strong>정규화</strong>와 <strong>차원 축소</strong>는 기계 학습에서 중요 한 요소 입니다. 학습에서 직접적인 영향을 주기 때문이죠.</p>\n<h2>Normalization</h2>\n<p>저번에 <strong>Linear Regression</strong>의 <strong>Cost Function</strong>에 대한 미분을 하게 되면, <strong>Input Vector</strong>가 나온다는 말을 한적이 있습니다. 다음과 같이 말이죠.</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><mi>M</mi><mi>S</mi><mi>E</mi></mrow><mrow><mi mathvariant=\"normal\">∂</mi><mi>w</mi></mrow></mfrac><mo>=</mo><mfrac><mn>2</mn><mi>m</mi></mfrac><munderover><mo>∑</mo><mi>i</mi><mi>C</mi></munderover><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo>−</mo><mi>y</mi><mo stretchy=\"false\">)</mo><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">\\frac{\\partial MSE}{\\partial w} = \\frac{2}{m}\\sum_{i}^{C}(\\hat{y} - y)X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.05744em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.37144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.106005em;vertical-align:-1.277669em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8283360000000002em;\"><span style=\"top:-1.872331em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.07153em;\">C</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.277669em;\"><span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span></span></span></span></span>\n<p>만약 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mo>=</mo><msup><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><msub><mi>x</mi><mn>0</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><msub><mi>x</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><msub><mi>x</mi><mi>n</mi></msub></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">X = \\begin{bmatrix} x_0 &amp; x_1 &amp; ... &amp; x_n \\end{bmatrix}^T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.431241em;vertical-align:-0.35001em;\"></span><span class=\"minner\"><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8500000000000001em;\"><span style=\"top:-3.01em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35000000000000003em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8500000000000001em;\"><span style=\"top:-3.01em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35000000000000003em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8500000000000001em;\"><span style=\"top:-3.01em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35000000000000003em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8500000000000001em;\"><span style=\"top:-3.01em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.35000000000000003em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">]</span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.081231em;\"><span style=\"top:-3.3029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span> 라고 가정 하면, 식을 보면 알다 싶이, 특정 feature의 범위가 0~100, 0~1 이렇게 들쑥 날쑥하게 되면, 똑같은 <strong>학습률</strong>을 바탕으로, 다른 정도로 학습이 되기 때문에 정규화 과정이 필요 합니다.</p>\n<h3>Min - Max 정규화</h3>\n<p>일단 첫 번째로는 <strong>Min - Max 정규화</strong>가 있습니다. 데이터를 <strong>최솟값</strong>과 <strong>최고값</strong>을 이용하여 정규화 하는 방법이며, 이렇게 정규화를 진행 하면 데이터의 범위가 [0, 1] 로 변하게 됩니다.</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>X</mi><mo>−</mo><msub><mi>X</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow><mrow><msub><mi>X</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo>−</mo><msub><mi>X</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{X - X_{min}} {X_{max} - X_{min}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.19633em;vertical-align:-0.8360000000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.36033em;\"><span style=\"top:-2.3139999999999996em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">m</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\">x</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">m</span><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">m</span><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8360000000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span>\n<p>이를 코드로 구현 하면 다음과 같습니다. <code class=\"language-text\">numpy.ndarray</code>를 정규화 한다고 가정 하겠습니다.</p>\n<ul>\n<li>\n<p>Module Import</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd</code></pre></div>\n</li>\n<li>\n<p>In</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">before_n <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>normal<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nbefore_n</code></pre></div>\n</li>\n<li>\n<p>Out: 정규화 전</p>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">array([ -7.60552157,  -7.4768014 ,   3.58856804,  -8.64994768,\n    -5.43849334,  11.49147181,   0.71011417,  -1.98272815,\n   -10.6252785 , -14.26019951])</code></pre></div>\n</li>\n<li>\n<p>In</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">after_n <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>before_n <span class=\"token operator\">-</span> before_n<span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token punctuation\">(</span>before_n<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> before_n<span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nafter_n  <span class=\"token comment\"># numpy의 Broadcast를 이용하여 간편하게 구현 가능.</span></code></pre></div>\n</li>\n<li>\n<p>Out</p>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">array([0.25841732, 0.26341584, 0.69311103, 0.21785972, 0.3425683 ,\n   1.        , 0.58133367, 0.47676406, 0.14115282, 0.        ])</code></pre></div>\n</li>\n</ul>\n<h3>Z-Score Normalization</h3>\n<p>두 번째는 <strong>Z-Score Normalization</strong> 입니다. 이는 입력 데이터의 <strong>표준 편차</strong>와 <strong>평균</strong>을 이용하여 구할 수 있습니다. 이를 통해 정규화를 진행 하면, 데이터를 중간으로 모으는 효과를 가질 수 있습니다.</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>Z</mi><mo>−</mo><mi>μ</mi></mrow><mi>σ</mi></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac {Z - \\mu} {\\sigma}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.0463299999999998em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3603299999999998em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">σ</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">Z</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathdefault\">μ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span>\n<p>이를 코드로 구현 하면 다음과 같습니다. <code class=\"language-text\">numpy.ndarray</code>를 정규화 한다고 가정 하겠습니다.</p>\n<ul>\n<li>\n<p>In</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">before_n <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>normal<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nbefore_n</code></pre></div>\n</li>\n<li>\n<p>Out: 정규화 전</p>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">array([  3.88259694, -12.78964916,  11.31123123,  -1.39481419,\n    12.67724562,  12.82906507,   6.78477706,  -3.9266831 ,\n    26.89122036,  13.87650172])</code></pre></div>\n</li>\n<li>\n<p>In</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">after_n <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>before_n <span class=\"token operator\">-</span> before_n<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> before_n<span class=\"token punctuation\">.</span>std<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># mean(): 평균, std(): 표준편차</span>\nafter_n</code></pre></div>\n</li>\n<li>\n<p>Out</p>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">array([-0.29603595, -1.87211833,  0.40621733, -0.79492702,  0.53535118,\n    0.54970317, -0.0216833 , -1.03427294,  1.87904506,  0.64872081])</code></pre></div>\n</li>\n</ul>\n<h2>PCA (Principal Component Analysis)</h2>\n<p><strong>PCA</strong>를 한국 말로 나타내면 <strong>주성분 분석</strong> 입니다. 이는 분포된 데이터들을 통해, <strong>분포의 주성분</strong>을 찾아 줌으로써, <strong>가장 큰 분산</strong>을 가진 주성분 (분산이 클 수록, 차원을 이동하더라도 정보의 손실이 적음)에 대해 사영 함으로써, 데이터의 차원을 줄이는 방법 중 하나 입니다.</p>\n<h3>numpy 만으로 구현하기</h3>\n<p>일단 코드를 먼저 보여 드리겠습니다. <code class=\"language-text\">np.random.multivariate_normal</code> 를 이용하여, [5, 5]를 평균으로 하고 [[1, 2], [2, 1]] 의 <strong>Covariance Matrix</strong>를 가지는 50개의 샘플을 만들어 보겠습니다.</p>\n<ul>\n<li>In</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n\narray <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>multivariate_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token number\">50</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>xlim<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>array<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> array<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<ul>\n<li>Out</li>\n</ul>\n<p align=\"center\">\n       <img src=\"/post_image/just-data-science/08-01.png\" width=\"50%\"/>\n       <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n              초기 데이터\n       </p>\n</p>\n<p>그 다음, 샘플들을 <strong>Broadcasting</strong> 을 이용하여, 데이터를 원점으로 모아 줍니다.</p>\n<ul>\n<li>In</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">array <span class=\"token operator\">-=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>array<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> array<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>xlim<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>array<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> array<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<ul>\n<li>Out</li>\n</ul>\n<p align=\"center\">\n       <img src=\"/post_image/just-data-science/08-02.png\" width=\"50%\"/>\n       <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n              중앙으로 모아줌\n       </p>\n</p>\n<p>그 다음, 생성된 데이터에 대한 <strong>Covariance Matrix</strong>를 구하고, 이에 대한 <strong>고유 벡터</strong>와 <strong>고유값</strong>을 구해 줍니다. 여기서 <strong>고유값이 높다</strong>는 것은, 이에 대응하는 <strong>고유 벡터 (혹은 주성분)</strong>에 각 <strong>Input Vector</strong>를 사영 할때, <strong>얼마나 분산이 높은지?</strong> 그리하여, 어떻게 <strong>정보의 손실없이 사영</strong>할 수 있는 지를 나타냅니다. 다시 한번 정리 하자면, <strong>고윳값이 높을 수록, 이에 대응하는 고유벡터를 주성분으로 삼았을 때, 정보의 손실이 작다</strong>는 것을 의미 합니다.</p>\n<ul>\n<li>In</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">cov <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>cov<span class=\"token punctuation\">(</span>array<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">)</span>\neigen_val<span class=\"token punctuation\">,</span> eigen_vec <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>linalg<span class=\"token punctuation\">.</span>eig<span class=\"token punctuation\">(</span>cov<span class=\"token punctuation\">)</span>\n\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>array<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> array<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>quiver<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> eigen_vec<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> eigen_vec<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'r'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> scale<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"eigenvalue: \"</span><span class=\"token punctuation\">,</span> eigen_val<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"eigenvector: \"</span><span class=\"token punctuation\">,</span> eigen_vec<span class=\"token punctuation\">)</span></code></pre></div>\n<ul>\n<li>Out</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">eigenvalue:  [2.24427897 0.89684849]\neigenvector:  [[ 0.76269005 -0.64676417]\n [ 0.64676417  0.76269005]]</code></pre></div>\n<p align=\"center\">\n       <img src=\"/post_image/just-data-science/08-03.png\" width=\"50%\"/>\n       <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n              Eigenvector == 주성분\n       </p>\n</p>\n<p>마지막으로, 해당 주성분에 벡터들을 사영을 해주면 완성이 됩니다. <code class=\"language-text\">argmax()</code> 메서드를 이용하여, <strong>주 성분</strong>으로 뽑을 <strong>고유 벡터</strong>를 선택합니다.</p>\n<ul>\n<li>In</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">index <span class=\"token operator\">=</span> eigen_val<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nv <span class=\"token operator\">=</span> eigen_vec<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># norm: 1</span>\n\nresult <span class=\"token operator\">=</span> array<span class=\"token punctuation\">.</span>dot<span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> v<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> result<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">'green'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>scatter<span class=\"token punctuation\">(</span>array<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> array<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>quiver<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> v<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> v<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">'black'</span><span class=\"token punctuation\">,</span> scale<span class=\"token operator\">=</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>xlim<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylim<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<ul>\n<li>Out</li>\n</ul>\n<p align=\"center\">\n       <img src=\"/post_image/just-data-science/08-04.png\" width=\"50%\"/>\n       <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n              사영 한 모습\n       </p>\n</p>\n<h3>sklearn으로 더 쉽게 구현하기</h3>\n<p>이는 <strong>Scikit-Learn</strong>으로 더 쉽게 구현 할 수 있습니다. <code class=\"language-text\">sklearn.decomposition</code> 내의 <code class=\"language-text\">PCA</code>를 이용합니다. <code class=\"language-text\">n_components</code>를 이용 하여, 몇 차원으로 줄이고 싶은지 입력 할 수 있습니다.</p>\n<ul>\n<li>In</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>decomposition <span class=\"token keyword\">import</span> PCA\n\npca <span class=\"token operator\">=</span> PCA<span class=\"token punctuation\">(</span>n_components<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 차원 수 1개</span>\npca<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>array<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'고유 값 :'</span><span class=\"token punctuation\">,</span> pca<span class=\"token punctuation\">.</span>explained_variance_<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 고윳값</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'고유 벡터 :'</span><span class=\"token punctuation\">,</span> pca<span class=\"token punctuation\">.</span>components_<span class=\"token punctuation\">.</span>T<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 고유 벡터</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'사영 후:'</span><span class=\"token punctuation\">,</span> pca<span class=\"token punctuation\">.</span>transform<span class=\"token punctuation\">(</span>array<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<ul>\n<li>Out</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">고유 값 : [2.6328486]\n고유 벡터 : [[0.81183442]\n [0.58388772]]\n사영 후: [[ 1.1017955 ]\n [ 1.90965349]\n [-1.26196986]\n [ 0.47308556]\n ...\n [ 0.83702101]\n [-1.95731602]]</code></pre></div>\n<h2>마치며</h2>\n<p>이번 시간에는 <strong>Normalization, PCA</strong>에 다뤄 보았습니다. 다음 시간에는 <strong>딥러닝의 제일 기본이 되는, DNN</strong>에 대해 공부해 보는 시간을 가져 보도록 하겠습니다.</p>","id":"a272e5eb-daef-505b-91e4-ddb97a4caf45","frontmatter":{"date":"2021-07-25","path":"/data-science/just-data-science-8","title":"[찍먹 Data Science] 8. Normalization, PCA","tags":["Data-Science","Machine-Learning"],"keyword":"Data Science, 데이터 사이언스, Machine Learning, 머신 러닝, 정규화, Normalization, PCA","summary":"값의 범위를 줄이고, 차원을 효율 적으로 줄여보자.","img":"/post_image/thumbnail/just-data-science-8.jpg","series":"찍먹 Data Science"}}},"pageContext":{"series":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"78aa3994-0aa2-55e7-b6cb-0ebc85c57591","excerpt":"Convolutional Neural Network 안녕하세요? 오늘은 CNN, Convolutional Neural Network에 대해서 알아 보도록 하겠습니다. 저번 시간에는 DNN…","frontmatter":{"date":"2021-07-31","tags":["Data-Science","Deep-Learning"],"path":"/data-science/just-data-science-10","title":"[찍먹 Data Science] 10. Convolutional Neural Network","img":"/post_image/thumbnail/just-data-science-10.jpg","summary":"국소적인 정보를 추출하는 CNN에 대해 알아 보자."}}},{"node":{"id":"e708c84f-fcff-5de6-9204-de9a7569750c","excerpt":"Deep Neural Network 안녕하세요? 오늘은 DNN, Deep Neural Network에 대해서 알아 보도록 하겠습니다. 여태까지 우리는 간단한 선형 모델에 대해서만 학습을 진행 하였습니다.  (혹은 ) 와 같이, 선형 연산을 통해서, 데이터에 대해서 예측하고, 분류 해 보는 실습을 진행 하였습니다. 하지만, 이러한 선형적인 모델이 비선형적인 문제를 해결 하려면 어떻게 해야 할까요? 일단 간단한 예제를 생각 해 보겠습니다. XOR…","frontmatter":{"date":"2021-07-29","tags":["Data-Science","Deep-Learning"],"path":"/data-science/just-data-science-9","title":"[찍먹 Data Science] 9. Deep Neural Network","img":"/post_image/thumbnail/just-data-science-9.jpg","summary":"딥러닝의 기초, DNN에 대해서 알아 보자."}}},{"node":{"id":"a272e5eb-daef-505b-91e4-ddb97a4caf45","excerpt":"Normalization, PCA 안녕하세요? Justkode 입니다. 이번 시간에는 Normalization (정규화)와, 차원 축소를 위한 PCA에 대해 공부 해 보는 시간을 가져 보도록 하겠습니다. 정규화와 차원 축소는 기계 학습에서 중요 한 요소 입니다. 학습에서 직접적인 영향을 주기 때문이죠. Normalization 저번에 Linear Regression의 Cost Function에 대한 미분을 하게 되면, Input Vector…","frontmatter":{"date":"2021-07-25","tags":["Data-Science","Machine-Learning"],"path":"/data-science/just-data-science-8","title":"[찍먹 Data Science] 8. Normalization, PCA","img":"/post_image/thumbnail/just-data-science-8.jpg","summary":"값의 범위를 줄이고, 차원을 효율 적으로 줄여보자."}}},{"node":{"id":"8276c1fb-09d2-5fea-a583-b11d7ca961a3","excerpt":"SVM, K-NN, Random Forest 안녕하세요? Justkode 입니다. 저번 시간에는 선형 회귀와 분류에 대해 공부 해 보았습니다. 그런데 Logistic Regression…","frontmatter":{"date":"2021-07-21","tags":["Data-Science","Machine-Learning"],"path":"/data-science/just-data-science-7","title":"[찍먹 Data Science] 7. SVM, K-NN, Random forest","img":"/post_image/thumbnail/just-data-science-7.jpg","summary":"자주 사용 되는 ML 모델을 사용 해 보자."}}},{"node":{"id":"a15e6d2e-d923-5e8e-9bb9-ae1c7116c1bc","excerpt":"Linear Regression, Classification 안녕하세요? Justkode 입니다. 오늘은 선형 회귀와 분류에 대해 이론을 공부 해 보고, 실습을 진행 해 보는 시간을 가져 보도록 하겠습니다. Before we start 먼저 이번 실습에는  모듈이 필요합니다. 다음을 통해 설치 해 주세요. (단, numpy, pandas, matplotlib이 설치 되어 있다면 scikit-learn만 설치 하셔도 됩니다.) Linear…","frontmatter":{"date":"2021-07-21","tags":["Data-Science","Machine-Learning"],"path":"/data-science/just-data-science-6","title":"[찍먹 Data Science] 6. Linear Regression, Logistic Regression","img":"/post_image/thumbnail/just-data-science-6.jpg","summary":"선형 회귀와 로지스틱 회귀에 대해서 알아 보자."}}},{"node":{"id":"5a9d9d37-ba85-593d-9e17-cd7082bc18c6","excerpt":"Maching Learning Basic. 안녕하세요? Justkode 입니다. 오늘은 머신 러닝의 기본 개념에 대해 공부 해 보는 시간을 가져 보도록 하겠습니다. 학습의 종류 머신 러닝 학습의 종류는 두 종류가 있습니다.  지도 학습 (Supervised Learning) 첫 번째는 지도 학습입니다. 지도 학습은 훈련 데이터로 Feature(특징)와 Target…","frontmatter":{"date":"2021-07-19","tags":["Data-Science","Machine-Learning"],"path":"/data-science/just-data-science-5","title":"[찍먹 Data Science] 5. Machine Learning Basic","img":"/post_image/thumbnail/just-data-science-5.jpg","summary":"머신 러닝의 기본 개념에 대해 알아보자."}}},{"node":{"id":"67ae44e3-5a48-57d9-87ea-fd77d9876c34","excerpt":"SQL 안녕하세요? Justkode 입니다. 오늘은 SQL에 대해서 간단하게 알아보는 시간을 가져보도록 하겠습니다. SQL은 Structured Query Language의 약자로, RDBMS의 데이터베이스를 주로 조회 하는데에 사용이 되는, 데이터베이스 관리 시스템(RDBMS)의 데이터를 관리하기 위해 설계된 특수 목적의 프로그래밍 언어입니다. 여기서 설명 하는 문법들은 많은 내용을 담지 않고, SQL…","frontmatter":{"date":"2021-07-11","tags":["Data-Science","Python"],"path":"/data-science/just-data-science-4","title":"[찍먹 Data Science] 4. SQL","img":"/post_image/thumbnail/just-data-science-4.jpg","summary":"SQL의 기본 문법에 대해 알아보자."}}},{"node":{"id":"72999af7-d2c7-5f95-8d6c-eb8d5219cd76","excerpt":"Matplotlib 안녕하세요? Justkode 입니다. 오늘은 Matplotlib에 대해서 알아보는 시간을 가져보도록 하겠습니다. Matplotlib는 데이터 분석을 위해 만들어진 라이브러리로 Numpy, Pandas…","frontmatter":{"date":"2021-07-08","tags":["Data-Science","Python"],"path":"/data-science/just-data-science-3","title":"[찍먹 Data Science] 3. Matplotlib","img":"/post_image/thumbnail/just-data-science-3.jpeg","summary":"데이터 시각화 모듈, Matplotlib을 알아보자."}}},{"node":{"id":"05ccbb5b-48d4-57d0-9f3b-ca1dae54ed34","excerpt":"Pandas 안녕하세요? Justkode 입니다. 오늘은 Pandas에 대해서 심층있게 알아보는 시간을 가져보도록 하겠습니다. Pandas는 데이터 분석을 위해 만들어진 라이브러리로 Numpy와 함께 많이 사용 됩니다. 주로 사용하는 데이터 구조는 Dataframe과 Series로, Table 정보와 같은 데이터를 처리 하는데 이점이 있습니다. Series and DataFrame 첫 번째로 Series입니다. Series는…","frontmatter":{"date":"2021-07-04","tags":["Data-Science","Python"],"path":"/data-science/just-data-science-2","title":"[찍먹 Data Science] 2. Pandas","img":"/post_image/thumbnail/just-data-science-2.jpg","summary":"데이터 분석에 쓰이는 Pandas를 알아보자."}}},{"node":{"id":"c29d290f-1001-5de9-8997-cb6fe729221b","excerpt":"Data Science And Math 안녕하세요? Justkode 입니다. 많은 Machine Learning과 Deep Learning…","frontmatter":{"date":"2021-06-30","tags":["Data-Science","Python"],"path":"/data-science/just-data-science-1","title":"[찍먹 Data Science] 1. Math, Numpy","img":"/post_image/thumbnail/just-data-science-1.jpg","summary":"간단한 수학 식을 Numpy로 구현해 보자"}}},{"node":{"id":"d0d8165b-3ac6-5f7f-b1e6-e8fb46731ec5","excerpt":"Data Science, 어디부터 해야 할까? 안녕하세요? Justkode 입니다. 일단, 제가 대학교 1,…","frontmatter":{"date":"2021-06-23","tags":["Data-Science"],"path":"/data-science/just-data-science-0","title":"[찍먹 Data Science] 0. Orientation","img":"/post_image/thumbnail/just-data-science-0.jpg","summary":"Data Science를 찍먹해 보자."}}}]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"78aa3994-0aa2-55e7-b6cb-0ebc85c57591","excerpt":"Convolutional Neural Network 안녕하세요? 오늘은 CNN, Convolutional Neural Network에 대해서 알아 보도록 하겠습니다. 저번 시간에는 DNN…","frontmatter":{"date":"2021-07-31","tags":["Data-Science","Deep-Learning"],"path":"/data-science/just-data-science-10","title":"[찍먹 Data Science] 10. Convolutional Neural Network","img":"/post_image/thumbnail/just-data-science-10.jpg","summary":"국소적인 정보를 추출하는 CNN에 대해 알아 보자."}}},{"node":{"id":"e708c84f-fcff-5de6-9204-de9a7569750c","excerpt":"Deep Neural Network 안녕하세요? 오늘은 DNN, Deep Neural Network에 대해서 알아 보도록 하겠습니다. 여태까지 우리는 간단한 선형 모델에 대해서만 학습을 진행 하였습니다.  (혹은 ) 와 같이, 선형 연산을 통해서, 데이터에 대해서 예측하고, 분류 해 보는 실습을 진행 하였습니다. 하지만, 이러한 선형적인 모델이 비선형적인 문제를 해결 하려면 어떻게 해야 할까요? 일단 간단한 예제를 생각 해 보겠습니다. XOR…","frontmatter":{"date":"2021-07-29","tags":["Data-Science","Deep-Learning"],"path":"/data-science/just-data-science-9","title":"[찍먹 Data Science] 9. Deep Neural Network","img":"/post_image/thumbnail/just-data-science-9.jpg","summary":"딥러닝의 기초, DNN에 대해서 알아 보자."}}},{"node":{"id":"a272e5eb-daef-505b-91e4-ddb97a4caf45","excerpt":"Normalization, PCA 안녕하세요? Justkode 입니다. 이번 시간에는 Normalization (정규화)와, 차원 축소를 위한 PCA에 대해 공부 해 보는 시간을 가져 보도록 하겠습니다. 정규화와 차원 축소는 기계 학습에서 중요 한 요소 입니다. 학습에서 직접적인 영향을 주기 때문이죠. Normalization 저번에 Linear Regression의 Cost Function에 대한 미분을 하게 되면, Input Vector…","frontmatter":{"date":"2021-07-25","tags":["Data-Science","Machine-Learning"],"path":"/data-science/just-data-science-8","title":"[찍먹 Data Science] 8. Normalization, PCA","img":"/post_image/thumbnail/just-data-science-8.jpg","summary":"값의 범위를 줄이고, 차원을 효율 적으로 줄여보자."}}},{"node":{"id":"8276c1fb-09d2-5fea-a583-b11d7ca961a3","excerpt":"SVM, K-NN, Random Forest 안녕하세요? Justkode 입니다. 저번 시간에는 선형 회귀와 분류에 대해 공부 해 보았습니다. 그런데 Logistic Regression…","frontmatter":{"date":"2021-07-21","tags":["Data-Science","Machine-Learning"],"path":"/data-science/just-data-science-7","title":"[찍먹 Data Science] 7. SVM, K-NN, Random forest","img":"/post_image/thumbnail/just-data-science-7.jpg","summary":"자주 사용 되는 ML 모델을 사용 해 보자."}}}]}}}}},"staticQueryHashes":["234633779","63159454"]}