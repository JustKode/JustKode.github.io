{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/data-science/just-data-science-0","result":{"data":{"markdownRemark":{"html":"<h2>Data Science, 어디부터 해야 할까?</h2>\n<p>안녕하세요? <strong>Justkode</strong> 입니다. 일단, 제가 대학교 1, 2학년 때 하던 고민들이 있었습니다. \"나는 자연어 처리 쪽으로 공부를 하고 싶은데, 어디부터 해야할까?\" 주변에 딱히 자연어 처리 쪽으로 공부 하는 선배들도 적었고, 그래서 학교에서 하는 프로젝트만 하다 보니, 어쩌다 보니 <strong>타의적(?) 풀스택 프로그래머</strong> 가 되어 있었습니다. 지금은 학기 중에 빅데이터 관련 프로젝트도 진행 해 보고, 군 복무 중에는 머신러닝, 딥러닝 이론 관련 공부도 진행 하면서 나름의 지식을 쌓은 것 같아요.</p>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/00-01.gif\" width=\"80%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\t실제로 이번학기에 진행한 3GB 가량의 MBTI 가량 데이터로 추출한, 특정 유형별 연관 단어 추출 결과 입니다.\n\t</p>\n</p>\n<p>그래서 이번 기회로 어떻게 <strong>Data Science</strong>를 공부 할 수 있을까에 대한, 여러분들의 고민을 해결 하기 위해, 데이터 전처리 부터, 기본 적인 수학이론, Machine Learning, Deep Learning 이론들을 여러분들과 공유 하고자 합니다. 물론 깊게 다루지는 않을 예정입니다. 이 분야에 대해서 깊게 공부하기 위해 필요한 자료들을 매 포스트 끝에 첨부 할 테니 참고 해 주세요!</p>\n<h2>First, You Need to get to know...</h2>\n<p>첫 번째는 <strong>Linear Algebra (선형대수)</strong> 입니다. 간단한 행렬 연산과, 행렬 곱을 통해 나타나는 사영의 의미, 고유값과 고유벡터에 대한 가벼운 지식은 알고 계셔야 합니다.</p>\n<p>두 번째는 <strong>Probability and random variables (확률과 랜덤변수)</strong> 입니다. 고등학교 교육과정의 확률과 통계 지식으로 충분합니다.</p>\n<p>세 번째는 <strong>Python</strong> 기초 문법 지식입니다. 이 시리즈는 <strong>Python</strong>을 통해 진행 됩니다.</p>\n<h2>Bayes' theorem</h2>\n<p><strong>Bayes' theorem</strong>은 <strong>Data Science</strong> 에서 가장 중요한 식 중 하나 입니다.</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mi mathvariant=\"normal\">∣</mi><mi>B</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>B</mi><mi mathvariant=\"normal\">∣</mi><mi>A</mi><mo stretchy=\"false\">)</mo><mi>P</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>B</mi><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">P(A|B) = \\frac{P(B|A)P(A)}{P(B)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">A</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.53em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05017em;\">B</span><span class=\"mclose mtight\">)</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mtight\">∣</span><span class=\"mord mathdefault mtight\">A</span><span class=\"mclose mtight\">)</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\">A</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></p>\n<p>A, B 두 랜덤 변수 (혹은 사건)이 <strong>독립</strong>일 시 위 식은 성립합니다. 하지만, 이 식이 완전한 독립이 아니더라도 <strong>귀납적, 경험적으로 문제</strong>를 해결하기 위해 주로 사용됩니다. 이 식을 현실에 한 번 대입 해 볼까요?</p>\n<p>저에게는 누나가 한 명 있고, 냉장고에 누나가 사놓은 아이스크림이 있다고 가정 하겠습니다. 다음과 같이 정리 해 보겠습니다.</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">A</span></span></span></span>: 누나의 아이스크림을 먹는 사건. (A의 사전 확률)</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span></span></span></span>: 누나에게 두들겨 맞을(?) 사건. (B의 사전 확률)</li>\n</ul>\n<p>그럼 다음과 같이 나타낼 수도 있겠네요,</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mi mathvariant=\"normal\">∣</mi><mi>B</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(A|B)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">A</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span><span class=\"mclose\">)</span></span></span></span>: 누나에게 두들겨 맞았을 때, 내가 누나의 아이스크림을 먹었을 확률. (사후 확률)</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>B</mi><mi mathvariant=\"normal\">∣</mi><mi>A</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(B|A)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\">A</span><span class=\"mclose\">)</span></span></span></span>: 누나의 아이스크림을 먹었을 때, 내가 두들겨 맞을 확률. (조건부 확률)</li>\n</ul>\n<p>일단 <strong>누나의 아이스크림을 먹었을 때, 내가 두들겨 맞은 경우가 100%</strong> 라고 가정 하겠습니다. 그러면 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>B</mi><mi mathvariant=\"normal\">∣</mi><mi>A</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn><mo separator=\"true\">,</mo><mi>P</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mi mathvariant=\"normal\">∣</mi><mi>B</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>B</mi><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">P(B|A) = 1, P(A|B) = \\frac{P(A)}{P(B)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\">A</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">A</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.53em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05017em;\">B</span><span class=\"mclose mtight\">)</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\">A</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span> 라고 할 수 있겠네요.</p>\n<p>엄마 입장에서 <strong>\"누나의 아이스크림을 먹었을 때, 내가 두들겨 맞은 경우가 100%\"</strong> 라는 사실을 알았다고 가정 하겠습니다. 또한, 제가 <strong>누나의 아이스크림을 먹는 확률이 10%</strong> 라고 가정 하겠습니다. 그러면 엄마는 <strong>\"얘가 누나꺼 아이스크림을 훔쳐 먹었구나~\"</strong> 라고 추정 할 확률은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mi mathvariant=\"normal\">∣</mi><mi>B</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>0.1</mn><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>B</mi><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">P(A|B) = \\frac{0.1}{P(B)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">A</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.365108em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05017em;\">B</span><span class=\"mclose mtight\">)</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span><span class=\"mord mtight\">.</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span> 라고 할 수 있겠네요.</p>\n<p>여기서 사건 하나를 더 추가 해 보겠습니다.</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>C</mi></mrow><annotation encoding=\"application/x-tex\">C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">C</span></span></span></span>: 누나의 남은 치킨을 먹는 사건. (C의 사전 확률)</li>\n</ul>\n<p>위와 마찬가지로 엄마 입장에서 <strong>누나의 남은 치킨을 먹었을 때, 내가 두들겨 맞은 경우가 100%</strong> 라는 사실을 알았다고 가정 하고, 제가 <strong>누나의 아이스크림을 먹는 확률이 50%</strong> 라고 가정 하겠습니다. 추가로, 저는 먹는 양이 많지 않은 관계로 <strong>치킨과 아이스크림을 동시에 먹지 않고, 그 이외에 누나에게 두들겨 맞는 일이 없다고 가정</strong>합니다.</p>\n<p>그럼 다음 식들로 나타 낼 수 있겠네요.</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mo>∩</mo><mi>C</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">P(A\\cap C) = 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">A</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∩</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">C</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>C</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0.5</mn></mrow><annotation encoding=\"application/x-tex\">P(C) = 0.5</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">C</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">5</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>B</mi><mi mathvariant=\"normal\">∣</mi><mi>C</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">P(B|C) = 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">C</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> </p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>C</mi><mi mathvariant=\"normal\">∣</mi><mi>B</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>C</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>B</mi><mo stretchy=\"false\">)</mo></mrow></mfrac><mo>=</mo><mo>=</mo><mfrac><mn>0.5</mn><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>B</mi><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">P(C|B) = \\frac{P(C)}{P(B)} =  = \\frac{0.5}{P(B)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">C</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.53em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05017em;\">B</span><span class=\"mclose mtight\">)</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.36687em;vertical-align:0em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.365108em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05017em;\">B</span><span class=\"mclose mtight\">)</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span><span class=\"mord mtight\">.</span><span class=\"mord mtight\">5</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></p>\n<p>자! 위의 가정을 통해서 만약 제가 누나한테 두들겨 맞고 있을 때, 엄마는 제가 뭘 했다고 유추 할 수 있을까요? <strong>제가 또 누나꺼 치킨을 훔쳐 먹었다고, 추론 할 수 있을 것 입니다.</strong> 이렇게 저의 어머니는 <strong>사전 확률</strong>과, <strong>조건부 확률</strong>에 대한 정보를 기반으로 <strong>사후 확률</strong>을 예측 할 수 있었습니다.</p>\n<p>우리가 사례를 통해서 배우듯, <strong>머신러닝</strong>도 이러한 아이디어에서 크게 벗어나지 않습니다. 우리가 특정 사진의 분류 모델을 학습시킬 때는 다음과 같은 과정을 거칩니다.</p>\n<ol>\n<li><strong>레이블 정보(무슨 사진인지)</strong>와 <strong>특징 정보(사진의 RGB값)</strong>를 제공 받습니다.</li>\n<li>특정 알고리즘을 통해 특징 정보에 대한 값을 바탕으로, <strong>해당 정보가 무슨 레이블인지 판별 합니다.</strong></li>\n<li>손실 함수(loss function)를 이용하여, <strong>추정한 값과 실제 값을 비교</strong>합니다. 추정 값이 실제 값과 비슷할 수록, 손실함수의 값은 작습니다.</li>\n<li>특정 알고리즘 내부에 있는 <strong>파라미터를 조정</strong>하여, 손실 함수의 값을 줄여 나갑니다.</li>\n</ol>\n<p>거시적인 측면에서 보자면, 이렇게 이야기 할 수 있습니다. 그림을 보고 A라고 판별하는 것은 <strong>사후확률</strong> (<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mi mathvariant=\"normal\">∣</mi><mi>p</mi><mi>i</mi><mi>c</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>e</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(A|picture)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">A</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\">p</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">t</span><span class=\"mord mathdefault\">u</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault\">e</span><span class=\"mclose\">)</span></span></span></span>), A가 그 그림에 나타나는 경우를 <strong>조건부 확률</strong> (<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mi>i</mi><mi>c</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>e</mi><mi mathvariant=\"normal\">∣</mi><mi>A</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(picture|A)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">p</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">t</span><span class=\"mord mathdefault\">u</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault\">e</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\">A</span><span class=\"mclose\">)</span></span></span></span>)이라고 하면, 우리는 <strong>A가 그 그림에 나타나 있다는 정보</strong>를 통해서, 그 그림이 <strong>A라고 판별하는 확률</strong>을 높여 나가는 것입니다.</p>\n<p>즉, 핵심은 <strong>관찰을 통해 새로운 정보를 획득하고, 믿음의 정도 (Likelihood)를 업데이트</strong> 하는 것. 이것이 머신러닝의 핵심이며, 이는 베이즈 정리에 잘 나타나 있다고 이야기 할 수 있습니다.</p>\n<h2>Machine Learning? Deep Learning?</h2>\n<p>많은 사람들이 궁금해 합니다. <strong>도대체 딥러닝과 머신러닝의 차이가 무엇인가요?</strong> 다음의 벤 다이어그램이 답을 줄 것입니다.</p>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/00-02.jpg\" width=\"80%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\t사실, 딥러닝은 머신러닝의 하위 개념이다.\n\t</p>\n</p>\n<p><strong>Deep Learning</strong>은 사실 <strong>Machine Learning</strong>의 하위 개념입니다. 하지만 오늘날에 굳이 따지자면, <strong>Deep Learning</strong>이냐 <strong>Machine Learning</strong>이냐는 <strong>신경망 학습</strong>의 사용 유무에 따라 달라질 수 있겠습니다. 신경망 학습은 사람의 뇌 구조를 유사하게 따라하여 만든 구조로, 여러 층의 <strong>퍼셉트론을 쌓아</strong> 만든 모델이라고 할 수 있습니다. 하지만, 여러 층의 행렬 연산을 요구 하기 때문에 <strong>컴퓨팅 파워</strong>측면에서 효율적이지 않지만, 좋은 성능을 내는 모델을 만들 수 있습니다.</p>\n<p align=\"center\">\n\t<img src=\"/post_image/just-data-science/00-03.jpg\" width=\"80%\"/>\n    <p align=\"center\" style=\"color:#888888; font-size: 12px;\">\n\t\t신경망 학습\n\t</p>\n</p>\n<p>그러면 딥러닝만 배워도 되지 않느냐? 라고 할 수 있습니다. 하지만, 많은 회사에서 속도와 효율적인 측면에서 일반 머신러닝 모델을 계속 차용하고 있으며, 많은 <strong>딥러닝의 아이디어</strong>는 모두 <strong>기존 머신러닝의 아이디어</strong>에서 온 것이기 때문에, 절대 머신러닝 이론을 무시 하고 딥러닝을 완벽하게 이해할 수는 없습니다.</p>\n<ul>\n<li>Deep Learning: 신경망을 이용한 학습, <strong>연산량 매우 높음, 모델 정확도 매우 높음</strong></li>\n<li>Machine Learning: 신경망을 이용하지 않고 통계학적인 원리 기반으로 학습, <strong>연산량 낮음, 모델 정확도 높음</strong></li>\n</ul>\n<h2>Contents</h2>\n<p><strong>1. Orientation</strong><br/>\nAnaconda를 이용하여 개발 환경을 세팅하고, Data Science가 무엇인지, Machine Learning은 Deep Learning과 무엇이 다른지에 대해서 배워 봅니다.</p>\n<p><strong>2. Basic Math, Numpy</strong><br/>\n해당 강의를 진행하기 위해 필요한 수학 지식을 간단하게 복습 해 보고, Numpy 관련 실습을 진행 합니다.</p>\n<p><strong>3. Pandas</strong><br/>\nPandas의 Series, Pandas에 대해서 다뤄 봅니다.</p>\n<p><strong>4. matplotlib</strong><br/>\nMatplotlib의 사용법에 대해서 배워 봅니다.</p>\n<p><strong>5. SQL</strong><br/>\nSQL문에 대해서 복습해 보는 시간을 가져 봅니다. Join 까지만 진행 합니다.</p>\n<p><strong>6. Machine Learning Basic</strong><br/>\nMachine Learning에 핵심이 되는 학습의 과정을 수학적인 관점에서 파악 해 봅니다.</p>\n<p><strong>7. Linear Regression, Classification*</strong><br/>\nscikit-learn을 이용하여 선형 회귀 문제와 분류 문제를 해결 해 봅니다.</p>\n<p><strong>8. SVM, K-NN, Random forest</strong><br/>\nMachine Learning에서 자주 사용 되는 SVM, K-NN, Random forest를 실습 해 봅니다.</p>\n<p><strong>9. Normalization, PCA</strong><br/>\n정규화를 이용하는 이유를 수학적인 관점에서 파악해 보고, 정규화를 실시 하여 보며, PCA를 이용하여 정보의 손실을 최소화 하며 차원을 축소 시켜보는 실습을 진행합니다.</p>\n<p><strong>10. DNN</strong><br/>\nPytorch를 통해 Deep Neural Network를 구축 해 봅니다.</p>\n<p><strong>11. CNN</strong><br/>\n이미지 인식에 주로 사용 되는 Convolutional Neural Network를 구축 해 봅니다.</p>\n<p><strong>12. RNN</strong><br/>\n자연어 처리, 시계열 데이터 처리에 주로 사용 되는 Recurrent Neural Network를 구축 해 봅니다.</p>\n<p><strong>13. TensorBoard 사용 해 보기</strong><br/>\nTensorboard를 사용해 보며, 모델을 시각화 하며, 학습 과정을 지켜 보는 과정을 가져 봅니다.</p>\n<p><strong>14. Kaggle Competiton</strong><br/>\n간단한 kaggle Competiton에 참가 해 봅니다.</p>\n<h2>마치며</h2>\n<p>가장 중요한 것은, 머신러닝, 딥러닝 모델을 짜는 것도 중요하지만, 그 내부의 <strong>수학적인 원리</strong>를 이해하고, 전처리가 왜 필요하고, 어떻게 해야 하는지, <strong>Computer Science</strong>의 관점에서 어떻게 연산양을 줄일 수 있고, 빠르게, 그리고 효율적으로 연산 할 수 있는지에 대한 고찰입니다. 외우려고 하거나, 그 미시적인 딥러닝의 세계를 이해하려고 하지 않으면, 좋은 모델을 만들 수 없습니다. 다음 시간에는 <strong>기본적인 수학</strong>과 <strong>numpy</strong> 사용법에 대해 공부해 보는 시간을 가져 보겠습니다.</p>\n<h4>p.s. 수학 못하는데 머신러닝 해도 되나요?</h4>\n<p>네, 가능합니다. 수학 식을 이해하고 적용할 수 있으면 돼요, 저 수학 겁나 못합니다.</p>","id":"d7cbf27c-4bba-5955-b512-675e2c8ee850","frontmatter":{"date":"2021-06-23","path":"/data-science/just-data-science-0","title":"[찍먹 Data Science] 0. Orientation","tags":["Data-Science"],"keyword":"Data Science, Machine Learning, Deep Learning, 데이터 사이언스, 머신 러닝, 딥러닝","summary":"Data Science를 찍먹해 보자.","img":"/post_image/thumbnail/just-data-science-0.jpg","series":"찍먹 Data Science"}}},"pageContext":{"series":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"9862b423-afa3-554a-8393-711ad503873f","excerpt":"Pandas 안녕하세요? Justkode 입니다. 오늘은 Pandas에 대해서 심층있게 알아보는 시간을 가져보도록 하겠습니다. Pandas는 데이터 분석을 위해 만들어진 라이브러리로 Numpy와 함께 많이 사용 됩니다. 주로 사용하는 데이터 구조는 Dataframe과 Series로, Table 정보와 같은 데이터를 처리 하는데 이점이 있습니다. Series and DataFrame 첫 번째로 Series입니다. Series는…","frontmatter":{"date":"2021-07-04","tags":["Data-Science","Python"],"path":"/data-science/just-data-science-2","title":"[찍먹 Data Science] 2. Pandas","img":"/post_image/thumbnail/just-data-science-2.jpg","summary":"데이터 분석에 쓰이는 Pandas를 알아보자."}}},{"node":{"id":"53efb961-aeb9-55f9-92bd-aa4425df8807","excerpt":"Data Science And Math 안녕하세요? Justkode 입니다. 많은 Machine Learning과 Deep Learning…","frontmatter":{"date":"2021-06-30","tags":["Data-Science","Python"],"path":"/data-science/just-data-science-1","title":"[찍먹 Data Science] 1. Math, Numpy","img":"/post_image/thumbnail/just-data-science-1.jpg","summary":"간단한 수학 식을 Numpy로 구현해 보자"}}},{"node":{"id":"d7cbf27c-4bba-5955-b512-675e2c8ee850","excerpt":"Data Science, 어디부터 해야 할까? 안녕하세요? Justkode 입니다. 일단, 제가 대학교 1,…","frontmatter":{"date":"2021-06-23","tags":["Data-Science"],"path":"/data-science/just-data-science-0","title":"[찍먹 Data Science] 0. Orientation","img":"/post_image/thumbnail/just-data-science-0.jpg","summary":"Data Science를 찍먹해 보자."}}}]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"9862b423-afa3-554a-8393-711ad503873f","excerpt":"Pandas 안녕하세요? Justkode 입니다. 오늘은 Pandas에 대해서 심층있게 알아보는 시간을 가져보도록 하겠습니다. Pandas는 데이터 분석을 위해 만들어진 라이브러리로 Numpy와 함께 많이 사용 됩니다. 주로 사용하는 데이터 구조는 Dataframe과 Series로, Table 정보와 같은 데이터를 처리 하는데 이점이 있습니다. Series and DataFrame 첫 번째로 Series입니다. Series는…","frontmatter":{"date":"2021-07-04","tags":["Data-Science","Python"],"path":"/data-science/just-data-science-2","title":"[찍먹 Data Science] 2. Pandas","img":"/post_image/thumbnail/just-data-science-2.jpg","summary":"데이터 분석에 쓰이는 Pandas를 알아보자."}}},{"node":{"id":"53efb961-aeb9-55f9-92bd-aa4425df8807","excerpt":"Data Science And Math 안녕하세요? Justkode 입니다. 많은 Machine Learning과 Deep Learning…","frontmatter":{"date":"2021-06-30","tags":["Data-Science","Python"],"path":"/data-science/just-data-science-1","title":"[찍먹 Data Science] 1. Math, Numpy","img":"/post_image/thumbnail/just-data-science-1.jpg","summary":"간단한 수학 식을 Numpy로 구현해 보자"}}},{"node":{"id":"d7cbf27c-4bba-5955-b512-675e2c8ee850","excerpt":"Data Science, 어디부터 해야 할까? 안녕하세요? Justkode 입니다. 일단, 제가 대학교 1,…","frontmatter":{"date":"2021-06-23","tags":["Data-Science"],"path":"/data-science/just-data-science-0","title":"[찍먹 Data Science] 0. Orientation","img":"/post_image/thumbnail/just-data-science-0.jpg","summary":"Data Science를 찍먹해 보자."}}},{"node":{"id":"11084baa-cbc0-5c10-9649-702fc27bc6a4","excerpt":"…","frontmatter":{"date":"2020-08-01","tags":["Data-Science"],"path":"/data-science/regex-1","title":"정규 표현식(RegEx)을 이해 해보자!","img":"https://www.onely.com/wp-content/uploads/blog/2017/principles-regular-expressions-seo/003-picard-now-i-have-two-problems.jpg","summary":"이제는 이해하고, 사용해보자!"}}}]}}}}},"staticQueryHashes":["234633779","63159454"]}