{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/etc/surviving-as-a-data-engineer/","result":{"data":{"markdownRemark":{"html":"<h3>머릿말</h3>\n<blockquote>\n<p><strong>주의: 해당 게시글은 회사에서 Spark 등을 사용하여, Batch Job 개발을 주로 수행하고, 타 개발자에게 Data Platform 등을 제공하는 Data Engineer인 저의 상황이 반영된 게시글입니다. 다른 도메인, 다른 기술을 사용하는 Data Engineer 분들에게는 조금 다른 내용일 수도 있습니다.</strong></p>\n</blockquote>\n<p>안녕하세요? 박민재입니다. 오늘은 저의 개인적인 사견이 듬뿍 담긴, 이제 <strong>2년차</strong>로 들어가는 건방진 개발자의 사견을 듬뿍 담은 글이에요. 매우 개인적인 글이기도 하고요. 어찌보면 공격을 받기 위해 쓴 글입니다. 제가 지금 딱 이런 상황이거든요.</p>\n<p align=\"center\">\n    <img src=\"/post_image/surviving-as-a-data-engineer/1-1.png\" width=\"50%\" min-width=\"280px\"/>\n    <div align=\"center\" color=\"#aaaaaa\">\n        \"코춘기\"가 온 저의 모습입니다.</br>\n        별개로 해당 사진은 \"데브경수\" 인스타툰 인데요, 정말 재밌습니다.</br>\n        https://www.instagram.com/waterglasstoon/\n    </div>\n</p>\n<p><strong>데이터 엔지니어로 성과를 낸다</strong>는 것은 어떤 것 일까요?</p>\n<p>데이터 엔지니어로 일한지 1년이 넘어가는 상황에서, 의미있는 성과를 내고 싶은 욕망이 생겼습니다. 그래서 자연스럽게 데이터 엔지니어, 혹은 S/W 엔지니어로 의미 있는 성과를 내기 위해서는 어떻게 해야 할지에 대한 의문으로 이어진 것 같아요.</p>\n<p>일단 <strong>성과</strong>라는 단어의 정의에 대해서 먼저 정리 해 보겠습니다. 개발자에게 있어 성과란 무엇일까요? 크게 제 생각에는 4가지로 정리 할 수 있을 것 같아요.</p>\n<ul>\n<li>내가 잘해서 회사가 얻은 것: 요구 사항 수행, 서비스 수익으로 직결되는 기술적 개선</li>\n<li>내가 잘해서 팀이 얻은 것: 팀 전체의 기술적 발전, 고도화를 통한 개발 생산성 증가</li>\n<li>내가 잘해서 동료가 얻은 것: 팀원의 성장</li>\n<li>내가 잘해서 내가 얻은 것: 개인의 성장</li>\n</ul>\n<p>이러한 기준을 바탕으로 한 번 데이터 엔지니어로 할 수 있는 Challenging한 일들을 한 번 나열 해 보도록 하겠습니다.</p>\n<h3>(준)실시간 데이터 제공</h3>\n<blockquote>\n<p>선정 기준: 서비스(매출) 수익으로 직결되는 기술적 개선, 기술적 발전, 성장</p>\n</blockquote>\n<p>광고 도메인으로 예시를 들어 보도록 하겠습니다. 사용자가 앱 활성화 시간 동안, 특정 제품에 대해서 관심을 가지고 <strong>검색, 클릭, 조회 등의 이벤트</strong>를 발생 시켰다고 가정 합니다. 이 데이터가 <strong>ML 모델에 빠르게 도달</strong> 할 수록, ML을 기반으로 하는 광고 송출에 있어 <strong>더 효율적인 광고를 빠르게 서빙</strong> 할 수 있습니다.</p>\n<p>하지만, 대용량의 데이터를 다루다 보면, <strong>실시간</strong>으로 <strong>대용량의 데이터를 서빙</strong> 하는 것은 꽤나 기술적으로 쉽지 않은 일이라는 것을 알 수 있습니다. <strong>Data Quality</strong> 또한 최대한 보장 해 주어야 하며, <strong>컴퓨팅 리소스</strong>는 거의 대부분의 경우에 <strong>실시간 서빙을 수행</strong> 할 수 있는 <strong>Streaming 방식</strong> 보단, 주기적으로 <strong>한꺼번에 데이터를 처리</strong>하는 <strong>Batch 방식</strong>으로 데이터를 처리 하는 것이 리소스가 덜 사용 되기 때문이에요.</p>\n<p>그렇기 때문에, <strong>(준)실시간 데이터 제공</strong>을 위해 할 수 있는 테스크는 크게 두 가지 정도가 있을 것 같아요.</p>\n<ul>\n<li><strong>Streaming 방식의 로직을 개선</strong>하여, 최대한 <strong>적은 리소스로 유의미한 실시간 데이터 제공</strong>하기</li>\n<li><strong>Batch 방식의 주기를 감소</strong>시킨 <strong>Mini-Batch 방식으로 데이터 집계 후 제공</strong>하기</li>\n</ul>\n<p>이를 수행하기 위해서는 다음과 같은 것들을 잘 고려해야 할 것입니다.</p>\n<ul>\n<li>현재 우리가 현실적으로 사용할 수 있는 <strong>컴퓨팅 리소스</strong>는?</li>\n<li>Input Data는 <strong>어떤 Storage</strong>에서 오고, Output Data는 <strong>어떤 Storage</strong>에 저장 되는지? (ex: kafka, s3, hadoop)\n<ul>\n<li>Hadoop에 저장을 한다면, Block Size에 맞게끔 Spark의 <strong>Partition 크기</strong>에 대한 고려를, <strong>Kafka를 사용</strong>을 한다면 Topic의 <strong>Patition 수</strong>에 대한 고려를 수행 해야 합니다.</li>\n</ul>\n</li>\n<li>우리가 데이터 제공을 함에 있어, 어떤 로직이 사용되고, 이는 내가 사용하는 연산 방식에서 문제가 되지 않는지?\n<ul>\n<li><strong>Spark</strong>와 같은 <strong>분산 컴퓨팅 프레임워크</strong>를 사용 한다면, 각 Node가 네트워크를 통해 Data를 주고 받는 <strong>Shuffle 로직</strong>이 최소화 되어야 합니다.</li>\n</ul>\n</li>\n</ul>\n<h3>팀 내 Component 고도화</h3>\n<blockquote>\n<p>선정 기준: 요구사항 수행, 고도화를 통한 개발 생산성 증가, 성장</p>\n</blockquote>\n<p><strong>요구사항을 해결</strong>하는 것과, <strong>개인과 팀이 기술적으로 발전</strong> 하는 것은 함께 하는 경우도 있지만, 함께 하지 않는 경우도 있습니다. 그렇기 때문에, 요구사항이 추가 되었을 때, 빠르게 개발을 할 수 있도록 <strong>개발 생산성을 증가</strong>시킬 수 있도록 코드를 작성 하는 것도 중요 할 것 같아요. <strong>비슷한 기능들이 있거나, 재사용의 가능성이 높은 로직들을 분리</strong> 하는 것 처럼요. 다음과 같은 것들이 예시가 될 수 있을 것 같아요.</p>\n<ul>\n<li>Airflow 내의 <strong>서로 다른 DAG이 유사한 로직</strong>으로 작동하는 경우, <strong>Task Group</strong>으로 묶어서 관리 포인트를 줄인다.</li>\n<li>Spark Application의 <strong>Aggregation 로직</strong> 같은 경우에는, <strong>재처리를 대비</strong>하여, <strong>Report Job과 Aggregation 로직을 분리</strong> 한다. (Jupyter Notebook 상에서 재사용하는 것을 대비)</li>\n</ul>\n<h3>데이터 사용자 친화적 환경 제공</h3>\n<blockquote>\n<p>선정 기준: 고도화를 통한 개발 생산성 증가, 성장</p>\n</blockquote>\n<p>우리가 재가공한 데이터를 사용하는 유저들이 있습니다. <strong>ML 엔지니어, 백엔드 엔지니어, Data Analysist</strong> 등이 이에 속하는데요, 다른 분야의 엔지니어들은 Data Engineering에 지식이 많지 않은 경우가 대부분입니다.</p>\n<p>우리는 데이터를 사용하는 유저들에게 조금 더 쉽고, <strong>사용자 친화적인 환경을 제공</strong>하는 것이 중요 합니다. <strong>SQL문</strong>만 논리적으로 작성하면 뒷 단에서는 Spark Engine이든, Hive Engine이든, Flink Engine이든 <strong>어떤 엔진으로 연산을 수행 하던지에 상관 없이 논리적으로 동일한 결과를 반환</strong>하는 것 처럼 말이에요. 사용자가 쉽게 <strong>Airflow DAG</strong>을 개발 할 수 있도록 <strong>Operator를 제공</strong> 해 주거나, <strong>Data Lineage, Data Profiling</strong> 결과를 확인 할 수 있도록 <strong>Data Discovery Platform</strong>을 운영하는 것도 좋겠네요.</p>\n<p>정리하면 다음과 같은 것들이 예시가 될 수 있겠네요.</p>\n<ul>\n<li><strong>Iceberg</strong>와 같은 <strong>Table Format을 제공</strong>하여, 원하는 엔진에서 돌려도 동일하게 다른 엔진에서도 데이터를 조회 할 수 있도록 제공한다.\n<ul>\n<li>ACID, Snapshot 기능 또한 추가적으로 제공하기.</li>\n</ul>\n</li>\n<li><strong>Datahub</strong>와 같은 <strong>Data Discovery Platform</strong>과 <strong>Great Expectations</strong>와 같은 <strong>Data Quality + Data Profiling</strong> 툴을 사용하여, 데이터 사용자에게 <strong>Insight</strong> 제공하기.</li>\n<li><strong>Airflow</strong>에 지식이 부족한 엔지니어들을 위해서 고도화된 <strong>CustomOperator</strong>를 작성하여 제공 해 주기.</li>\n</ul>\n<h3>마치며</h3>\n<p>다음과 같이 크게 3가지 토픽으로 해 볼만한 것들을 (정확히는 제가 해볼만한...) 정리 해 보았는데요, 올해 성과를 내기 위해 위에 언급했던 목표를 잡고 나아가 볼 생각입니다. 의견을 받기 위해서 작성 한 글이니 만큼, 더 좋은 의견들이 있다면 댓글로 작성 해 주세요!</p>\n<p>글 읽어 주셔서 감사합니다.</p>","id":"813b3d45-a2eb-5966-87f2-59759ccc15ee","frontmatter":{"date":"2024-02-04","path":"/etc/surviving-as-a-data-engineer","title":"Data Engineer로 성과를 내려면 뭘 해야할까..?","tags":["etc"],"keyword":"Data Engineering, 데이터 엔지니어링, Big Data, 빅데이터","summary":"저의 개인적인 사견을 듬뿍 담았습니다.","img":"/post_image/thumbnail/surviving-as-a-data-engineer.jpeg","series":null}}},"pageContext":{"postPath":"/etc/surviving-as-a-data-engineer","series":{"data":{"allMarkdownRemark":{"edges":[]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"813b3d45-a2eb-5966-87f2-59759ccc15ee","excerpt":"머릿말 주의: 해당 게시글은 회사에서 Spark 등을 사용하여, Batch Job 개발을 주로 수행하고, 타 개발자에게 Data Platform 등을 제공하는 Data Engineer인 저의 상황이 반영된 게시글입니다. 다른 도메인, 다른 기술을 사용하는 Data Engineer 분들에게는 조금 다른 내용일 수도 있습니다. 안녕하세요? 박민재입니다. 오늘은 저의 개인적인 사견이 듬뿍 담긴, 이제…","frontmatter":{"date":"2024-02-04","tags":["etc"],"path":"/etc/surviving-as-a-data-engineer","title":"Data Engineer로 성과를 내려면 뭘 해야할까..?","img":"/post_image/thumbnail/surviving-as-a-data-engineer.jpeg","summary":"저의 개인적인 사견을 듬뿍 담았습니다."}}},{"node":{"id":"3d142c60-d4d3-5a2c-8537-ae5b7275682f","excerpt":"머릿말 안녕하세요? JustKode, 박민재 입니다. 이 글을 쓰는 지금, Data Engineer로 LINE Plus에 입사한지 벌써 만으로 1년이 다 되어 가네요. 올해 1월에 입사 했으니까요. 첫 사회 생활, 첫 회사에서 (첫 인턴, 첫 회사가 LINE Plus…","frontmatter":{"date":"2023-12-21","tags":["etc","Data-Engineering"],"path":"/etc/2023-retrospect","title":"1년차 Data Engineer의 회고","img":"/post_image/2023-retrospect.jpeg","summary":"2023년을 되돌아 봅니다."}}},{"node":{"id":"21a4cf16-a0ad-54d2-ac01-d16225c0bd3f","excerpt":"오랜만입니다! 안녕하세요! JustKode 입니다. 전에도  +  를 이용해서 블로그를 만들었었지만,  인스턴스 유지 비용이 현실적으로 학생 (현재는 군인)에게는 약간 부담이 되는 가격이더라고요.. 그래서 정적 페이지로 블로그를 다시 만들어 보자! 하게 되었고, 한 달 동안 시간 날 때마다 사이버지식정보방에 박혀서 열심히 만들었습니다. :D Used Framework React.js Gatsby.js TypeScript Code…","frontmatter":{"date":"2020-03-20","tags":["etc"],"path":"/etc/blog-open","title":"JustKode Blog 오픈!","img":"https://images-na.ssl-images-amazon.com/images/I/51RAI%2BrOTtL._AC_SX466_.jpg","summary":"오랜만입니다!"}}}]}}}}},"staticQueryHashes":["3819017183","63159454"],"slicesMap":{}}