{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/deep-learning/pytorch-basic","result":{"data":{"markdownRemark":{"html":"<h2>주의</h2>\n<p>필자인 저 또한 배운 것들을 정리 하면서 쓰는 글이기 때문에, 틀린 부분이 있을 수도 있습니다. 또한, 이 글은 <code class=\"language-text\">Numpy</code>에 대한 기본 적인 배경 지식을 필요로 합니다. <strong>오타, 지적사항</strong> 발생 시, 댓글 혹은 이메일로 남겨 주시면 감사하겠습니다!</p>\n<h1>Pytorch</h1>\n<p><strong>Pytorch</strong>는 두 가지 목표를 달성하기 위해 만들어진 <strong>오픈 소스 라이브러리</strong>이자, <strong>Python Package</strong>입니다. 두 가지 목표는 다음과 같습니다.</p>\n<ul>\n<li><strong>Numpy</strong>가 기존에 하던 연산들을 <strong>GPU</strong>로 대체하기 위함.</li>\n<li><strong>높은 유연성과 속도</strong>를 제공하는 <strong>Deep Learning 연구 플랫폼</strong></li>\n</ul>\n<p><strong>Facebook 인공지능 연구 팀</strong>이 개발 하였으며, <strong>러닝 커브가 낮고, 코드 가독성</strong> 또한 좋은 편입니다. 실시간 결과 값을 <strong>시각화</strong>도 가능할 뿐더러, 기계 학습 과정을 보며, 수학적으로 이해하는 데 상당히 유용하죠. 자, 한번 <strong>Pytorch</strong>의 기본 문법을 알아 볼까요?</p>\n<p align=\"center\">\n\t<img src=\"https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/challenge_thumbnails/000/822/053/datas/original.png\" width=\"30%\" />\n\t<div style=\"text-align: center; color: #aaaaaa; font-size: 12px;\">\n\t\tPytorch 로고\n\t</div>\n</p>\n<br>\n<h2>Installation</h2>\n<p><strong>Python3, pip</strong>이 설치된 상태에서 터미널에 해당 명령어를 입력 해 주세요.</p>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">pip install torch===1.4.0 torchvision===0.5.0 -f https://download.pytorch.org/whl/torch_stable.html</code></pre></div>\n<br>\n<h2>Tensor</h2>\n<p><code class=\"language-text\">Tensor</code> 객체는 <code class=\"language-text\">Numpy</code>의 <code class=\"language-text\">ndarray</code>와 상당히 유사한 구조를 가집니다. 애초에 <code class=\"language-text\">Pytorch</code>가 <code class=\"language-text\">Numpy</code>를 대체하기 위해서 나왔기 때문이죠, 일단 <code class=\"language-text\">torch</code> 모듈을 <code class=\"language-text\">import</code> 해 볼까요?</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch</code></pre></div>\n<br>\n<h3>Make some Tensor Objects</h3>\n<p>그 다음, <code class=\"language-text\">Tensor</code> 객체를 만드는 여러 가지 방법들을 알려 드리겠습니다.</p>\n<ul>\n<li><code class=\"language-text\">torch.empty(x, y)</code>: x * y 사이즈의 요소들의 값이 초기화 되지 않은 행렬 반환.</li>\n<li><code class=\"language-text\">torch.rand(x, y)</code>: x * y 사이즈의 요소들이 <strong>0 ~ 1 사이의 랜덤한 값</strong>으로 초기화 된 행렬 반환.</li>\n<li><code class=\"language-text\">torch.randn(x, y)</code>: x * y 사이즈의 요소들이 <strong>정규분포 그래프</strong> 상의 랜덤한 값으로 초기화 된 행렬 반환.</li>\n<li><code class=\"language-text\">torch.zeros(x, y, dtype=type)</code>: x * y 사이즈의 요소들이 <strong>0으로 초기화</strong> 된 행렬 반환, 요소들은 type에 맞게 초기화 된다.</li>\n<li><code class=\"language-text\">torch.ones(x, y, dtype=type)</code>: x * y 사이즈의 요소들이 <strong>1으로 초기화</strong> 된 행렬 반환, 요소들은 type에 맞게 초기화 된다.</li>\n<li><code class=\"language-text\">torch.tensor(iterable)</code>: <code class=\"language-text\">iterable</code>한 객체를 <code class=\"language-text\">Tensor</code> 객체로 변환한다.</li>\n<li><code class=\"language-text\">torch.zeros_like(tensor, dtype=type)</code>: 파라미터로 들어 간 <code class=\"language-text\">Tensor</code> 객체의 사이즈과 똑같은 행렬을 반환하며, 요소들은 <strong>0으로 초기화</strong> 되어 있다.</li>\n<li><code class=\"language-text\">torch.ones_like(tensor, dtype=type)</code>: 파라미터로 들어 간 <code class=\"language-text\">Tensor</code> 객체의 사이즈과 똑같은 행렬을 반환하며, 요소들은 <strong>1으로 초기화</strong> 되어 있다.</li>\n<li><code class=\"language-text\">torch.randn_like(tensor, dtype=type)</code>: 파라미터로 들어 간 <code class=\"language-text\">Tensor</code> 객체의 사이즈과 똑같은 행렬을 반환하며, 요소들은 <strong>정규분포 그래프</strong> 상의 랜덤한 값으로 초기화 되어 있다.</li>\n</ul>\n<br>\n<h4>Code implementation</h4>\n<ul>\n<li><strong>입력</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">empty_tensor <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>empty<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\t\t\t\t\t\t\t\t\t\t\t<span class=\"token comment\"># 3 * 3의 빈 행렬 생성</span>\nrand_tensor <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>rand<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"token comment\"># 3 * 3의 요소들이 0 ~ 1의 랜덤 값으로 초기화된 행렬 생성</span>\nrandn_tensor <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>double<span class=\"token punctuation\">)</span>\t\t\t\t\t\t<span class=\"token comment\"># 3 * 3의 요소들이 정규분포 그래프 값으로 초기화된 행렬 생성</span>\nzero_tensor <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">long</span><span class=\"token punctuation\">)</span>\t\t\t\t\t\t\t<span class=\"token comment\"># 3 * 3의 요소들이 0으로 초기화된 행렬 생성</span>\none_tensor <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>double<span class=\"token punctuation\">)</span>\t\t\t\t\t\t\t<span class=\"token comment\"># 3 * 3의 요소들이 1으로 초기화된 행렬 생성</span>\niterable_tensor <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\t\t\t\t\t\t\t\t\t<span class=\"token comment\"># list 객체를 Tensor 객체로 변환</span>\nzeros_like_tensor <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros_like<span class=\"token punctuation\">(</span>iterable_tensor<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>double<span class=\"token punctuation\">)</span>\t<span class=\"token comment\"># iterable_tensor와 사이즈가 같은, 요소들이 0으로 초기화된 행렬 생성</span>\nones_like_tensor <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>ones_like<span class=\"token punctuation\">(</span>iterable_tensor<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>double<span class=\"token punctuation\">)</span>\t\t<span class=\"token comment\"># iterable_tensor와 사이즈가 같은, 요소들이 1으로 초기화된 행렬 생성</span>\nrandn_like_tensor <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randn_like<span class=\"token punctuation\">(</span>iterable_tensor<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>double<span class=\"token punctuation\">)</span>\t<span class=\"token comment\"># iterable_tensor와 사이즈가 같은, 요소들이 정규분포 그래프 값으로 초기화된 행렬 생성</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>empty_tensor<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>rand_tensor<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>randn_tensor<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>zero_tensor<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>one_tensor<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>iterable_tensor<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>zeros_like_tensor<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>ones_like_tensor<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>randn_like_tensor<span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n<ul>\n<li><strong>출력</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">tensor([[1.2045e-35, 0.0000e+00, 4.4842e-44],\n        [0.0000e+00,        nan, 6.1657e-44],\n        [4.3722e-05, 5.2475e-08, 1.7662e-04]])\ntensor([[0.8250, 0.8530, 0.6120],\n        [0.4726, 0.9426, 0.7616],\n        [0.5276, 0.1977, 0.1966]])\ntensor([[-0.1279, -0.9227,  0.0434],\n        [-0.2085,  0.1541, -1.8450],\n        [-0.7687,  0.0956, -0.6723]], dtype=torch.float64)\ntensor([[0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]])\ntensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)\ntensor([1, 2, 3])\ntensor([0., 0., 0.], dtype=torch.float64)\ntensor([1., 1., 1.], dtype=torch.float64)\ntensor([ 0.5920, -0.2960, -0.2184], dtype=torch.float64)</code></pre></div>\n<br>\n<h3>Operations</h3>\n<p>당연히, <code class=\"language-text\">Tensor</code> 객체의 연산을 위한 <strong>연산자, 인덱싱</strong> 또한 준비 되어 있습니다.</p>\n<h4>Code Implementation</h4>\n<p>일단 기본적인 <strong>연산자</strong>는 다음과 같이 사용 할 수 있습니다. 또한, <code class=\"language-text\">Numpy</code>에서 사용 했던, <strong>차원별 인덱싱</strong>과 <strong>브로드캐스팅</strong>이 가능합니다.</p>\n<ul>\n<li><strong>입력</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">x_tensor <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 2 * 2 행렬 생성</span>\ny_tensor <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">7</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nz_tensor <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x_tensor<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>y_tensor<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x_tensor <span class=\"token operator\">+</span> y_tensor<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Index가 일치하는 요소 끼리 덧셈</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x_tensor <span class=\"token operator\">-</span> y_tensor<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Index가 일치하는 요소 끼리 뺄셈</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x_tensor <span class=\"token operator\">*</span> y_tensor<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># Index가 일치하는 요소 끼리 곱셈</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x_tensor @ y_tensor<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 행렬 곱</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x_tensor <span class=\"token operator\">*</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span>         <span class=\"token comment\"># x_tensor 각 요소에 3을 곱해줌</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>x_tensor <span class=\"token operator\">+</span> z_tensor<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 일치하는 요소에 브로드캐스팅</span>\n\na_tensor <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nb_tensor <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>a_tensor<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>b_tensor<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>a_tensor @ b_tensor<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 2 * 3 행렬과 3 * 2 행렬 곱셈</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>a_tensor<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>       <span class=\"token comment\"># 각 행의 1번째 열 추출</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>b_tensor<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>       <span class=\"token comment\"># 1번째 행의 모든 열 추출</span></code></pre></div>\n<br>\n<ul>\n<li><strong>출력</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">tensor([[1, 2],\n        [3, 4]])\ntensor([[5, 6],\n        [7, 8]])\ntensor([[ 6,  8],\n        [10, 12]])\ntensor([[-4, -4],\n        [-4, -4]])\ntensor([[ 5, 12],\n        [21, 32]])\ntensor([[19, 22],\n        [43, 50]])\ntensor([[ 3,  6],\n        [ 9, 12]])\ntensor([[[2, 4],\n         [6, 8]],\n\n        [[2, 4],\n         [6, 8]]])\ntensor([[1, 2, 3],\n        [4, 5, 6]])\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\ntensor([[22, 28],\n        [49, 64]])\ntensor([2, 5])\ntensor([3, 4])</code></pre></div>\n<p><br><br></p>\n<h3>Tensor Resize</h3>\n<p><strong>딥러닝 모델</strong>을 설계하다 보면 <strong>행렬 사이즈를 재조정</strong> 해야 하는 경우가 상당히 많습니다. 이를 위한 <strong>몇 가지 함수</strong>를 소개 시켜 드리겠습니다.</p>\n<ul>\n<li><code class=\"language-text\">Tensor.size()</code>: <code class=\"language-text\">Tensor</code> 객체의 <strong>사이즈를 반환</strong> 한다.</li>\n<li><code class=\"language-text\">Tensor.view(size)</code>: 파라미터로 들어간 사이즈로 <code class=\"language-text\">Tensor</code> 객체의 <strong>사이즈를 변환</strong> 시켜 주며, 파라미터로 -1이 들어갈 시, <strong>행렬의 차원 수를 낮춰</strong> 리사이징 하며, (-1, n)이 들어가면 가장 <strong>하위 차원에서 n개씩 끊어 넣는 방식</strong>으로 리사이징 한다.</li>\n</ul>\n<h4>Code Implementation</h4>\n<ul>\n<li><strong>입력</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">a_tensor <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>      <span class=\"token comment\"># 4 * 4 행렬</span>\n                         <span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">,</span> <span class=\"token number\">7</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                         <span class=\"token punctuation\">[</span><span class=\"token number\">9</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">11</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                         <span class=\"token punctuation\">[</span><span class=\"token number\">13</span><span class=\"token punctuation\">,</span> <span class=\"token number\">14</span><span class=\"token punctuation\">,</span> <span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>a_tensor<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>a_tensor<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nb_tensor <span class=\"token operator\">=</span> a_tensor<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">)</span>                <span class=\"token comment\"># 사이즈가 16 array</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>b_tensor<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>b_tensor<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nc_tensor <span class=\"token operator\">=</span> a_tensor<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8</span><span class=\"token punctuation\">)</span>             <span class=\"token comment\"># 4 * 4 => 8 * 2</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>c_tensor<span class=\"token punctuation\">)</span>                             <span class=\"token comment\"># 6 * 4 일시 8 * 3 으로 리사이징 된다.</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>c_tensor<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nd_tensor <span class=\"token operator\">=</span> a_tensor<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>                <span class=\"token comment\"># 4 * 4 => 16</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>d_tensor<span class=\"token punctuation\">)</span>                             <span class=\"token comment\"># 6 * 4 일시 24로 리사이징 된다.</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>d_tensor<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\ne_tensor <span class=\"token operator\">=</span> a_tensor<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>              <span class=\"token comment\"># 8 * 2 행렬로 사이즈 변환</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>e_tensor<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>e_tensor<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n<ul>\n<li><strong>출력</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">tensor([[ 1,  2,  3,  4],\n        [ 5,  6,  7,  8],\n        [ 9, 10, 11, 12],\n        [13, 14, 15, 16]])\ntorch.Size([4, 4])\ntensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])\ntorch.Size([16])\ntensor([[ 1,  2,  3,  4,  5,  6,  7,  8],\n        [ 9, 10, 11, 12, 13, 14, 15, 16]])\ntorch.Size([2, 8])\ntensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])\ntorch.Size([16])\ntensor([[ 1,  2],\n        [ 3,  4],\n        [ 5,  6],\n        [ 7,  8],\n        [ 9, 10],\n        [11, 12],\n        [13, 14],\n        [15, 16]])\ntorch.Size([8, 2])</code></pre></div>\n<p><br><br></p>\n<h3>Numpy Bridges</h3>\n<p><code class=\"language-text\">Pytorch</code>는 <code class=\"language-text\">Numpy</code>연산을 빠르게 하기 위해 탄생했습니다. 그렇기 때문에 <code class=\"language-text\">Numpy</code>와 <code class=\"language-text\">Pytorch</code>를 연동할 수 있도록, <code class=\"language-text\">Pytorch</code>에서는 <code class=\"language-text\">API</code>를 제공합니다.</p>\n<ul>\n<li><code class=\"language-text\">Tensor.numpy()</code>: <code class=\"language-text\">Tensor</code> 객체를 <code class=\"language-text\">numpy.ndarray</code> 객체로 변환 하여 반환합니다.</li>\n<li><code class=\"language-text\">torch.from_numpy(ndarray)</code>: <code class=\"language-text\">numpy.ndarray</code>를 <code class=\"language-text\">Tensor</code> 객체로 변환 하여 반환합니다.</li>\n</ul>\n<h4>Code Implementation</h4>\n<ul>\n<li><strong>입력</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> torch\n\na_matrix <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>   <span class=\"token comment\"># np.ndarray 객체 할당</span>\nb_matrix <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>from_numpy<span class=\"token punctuation\">(</span>a_matrix<span class=\"token punctuation\">)</span>   <span class=\"token comment\"># np.ndarray 객체를 이용하여 Tensor 객체 할당</span>\nc_matrix <span class=\"token operator\">=</span> b_matrix<span class=\"token punctuation\">.</span>numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>             <span class=\"token comment\"># Tensor 객체를 이용하여 np.ndarray 객체 할당</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>a_matrix<span class=\"token punctuation\">)</span>                         <span class=\"token comment\"># np.ndarray</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>b_matrix<span class=\"token punctuation\">)</span>                         <span class=\"token comment\"># Tensor</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>c_matrix<span class=\"token punctuation\">)</span>                         <span class=\"token comment\"># np.ndarray</span></code></pre></div>\n<br>\n<ul>\n<li><strong>출력</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">[[1 2]\n [3 4]]\ntensor([[1, 2],\n        [3, 4]])\n[[1 2]\n [3 4]]</code></pre></div>\n<p><br><br></p>\n<h2>마치며</h2>\n<p><code class=\"language-text\">Pytorch</code>는 <code class=\"language-text\">Numpy</code>와 <code class=\"language-text\">API</code> 형태가 상당히 유사합니다. 하지만, <code class=\"language-text\">Numpy</code>와 다른 점이 있다면, <code class=\"language-text\">Backpropagation</code>을 쉽게 구현할 수 있고, <code class=\"language-text\">loss function</code>, <code class=\"language-text\">optimizer</code> 등 많은 고수준 <code class=\"language-text\">API</code>를 제공합니다. 다음 시간에는 <strong>Pytorch로 미분하기, autograd</strong>에 대해서 알아 보겠습니다.</p>","id":"d3d26a0d-b647-5094-816f-d4c7a9c8e5d9","frontmatter":{"date":"2020-03-23","path":"/deep-learning/pytorch-basic","title":"Pytorch에 대해서 알아보자.araboza","tags":["Deep-Learning","Python"],"keyword":"Python, python, 파이썬, Pytorch, 파이토치, pytorch, 딥러닝","summary":"딥러닝 플랫폼인 Pytorch에 대하여","img":"https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/challenge_thumbnails/000/822/053/datas/original.png"}}},"pageContext":{}}}