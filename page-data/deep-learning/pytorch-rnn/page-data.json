{"componentChunkName":"component---src-layouts-post-layout-tsx","path":"/deep-learning/pytorch-rnn","result":{"data":{"markdownRemark":{"html":"<p><code class=\"language-text\">Pytorch</code> 에서는 <code class=\"language-text\">CNN</code>과 마찬가지로, <code class=\"language-text\">RNN</code>과 관련 된 <code class=\"language-text\">API</code>를 제공합니다. 이를 이용해 손쉽게 <code class=\"language-text\">RNN</code> 네트워크를 구축 할 수 있습니다.</p>\n<h2>Recurrent Neural Network</h2>\n<p><code class=\"language-text\">RNN (Recurrent Neural Network)</code>를 위한 <code class=\"language-text\">API</code>는 <code class=\"language-text\">torch.nn.RNN(*args, **kwargs)</code> 입니다.</p>\n<p>일단 <code class=\"language-text\">Input</code> 시퀀스의 각 요소에 대해, 각 레이어에서는 다음 연산을 수행합니다.</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mrow><mi>i</mi><mi>h</mi><msub><mi>x</mi><mi>t</mi></msub></mrow></msub><mo>+</mo><msub><mi>b</mi><mrow><mi>i</mi><mi>h</mi></mrow></msub><mo>+</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub><msub><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub><mo>+</mo><msub><mi>b</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_t = tanh(W_{ihx_t} + b_{ih} + W_{hh}h_{(t-1)} + b_{hh})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0001em;vertical-align:-0.2501em;\"></span><span class=\"mord mathdefault\">t</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">n</span><span class=\"mord mathdefault\">h</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">h</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29634285714285713em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2501em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">h</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.04964em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">h</span><span class=\"mord mathdefault mtight\">h</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">h</span><span class=\"mord mathdefault mtight\">h</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<h3>Parameters</h3>\n<ul>\n<li><code class=\"language-text\">input_size</code>: <code class=\"language-text\">Input</code>의 <strong>사이즈</strong>에 해당 하는 수를 입력하면 됩니다.</li>\n<li><code class=\"language-text\">hidden_size</code>: <strong>은닉층의 사이즈</strong>에 해당 하는 수를 입력하면 됩니다.</li>\n<li><code class=\"language-text\">num_layers</code>: <code class=\"language-text\">RNN</code>의 은닉층 레이어 갯수를 나타냅니다. 기본 값은 1입니다.</li>\n<li><code class=\"language-text\">nonlinearity</code>: <strong>비선형 활성화 함수</strong>를 선택합니다. <code class=\"language-text\">tanh</code>, <code class=\"language-text\">relu</code>중 하나를 선택 가능하며, 기본 값은 <code class=\"language-text\">tanh</code>입니다.</li>\n<li><code class=\"language-text\">bias</code>: <strong>바이어스 값</strong> 활성화 여부를 선택합니다. 기본 값은 <code class=\"language-text\">True</code> 입니다.</li>\n<li><code class=\"language-text\">batch_first</code>: <code class=\"language-text\">True</code>일 시, <code class=\"language-text\">Output</code> 값의 사이즈는 (batch, seq, feature) 가 됩니다. 기본 값은 <code class=\"language-text\">False</code> 입니다.</li>\n<li><code class=\"language-text\">dropout</code>: <strong>드롭아웃</strong> 비율을 설정 합니다. 기본 값은 0입니다.</li>\n<li><code class=\"language-text\">bidirectional</code>: <code class=\"language-text\">True</code>일 시, 양방향 RNN이 됩니다. 기본 값은 <code class=\"language-text\">False</code> 입니다.</li>\n</ul>\n<h4><code class=\"language-text\">num_layers</code>가 2라면?</h4>\n<p align=\"center\">\n\t<img src=\"https://discuss.pytorch.org/uploads/default/optimized/2X/f/fb98eb0d16b722e019db59f97825aa529cb6bc08_2_685x499.png\" width=\"50%\" />\n</p>\n<p>다음 그림과 같은 신경망이 만들어 진다고 생각 하면 됩니다.</p>\n<h3>Inputs: input, h_0 (<code class=\"language-text\">tuple</code> 형태)</h3>\n<ul>\n<li><code class=\"language-text\">input</code>: (seq<em>len, batch, input</em>size)</li>\n<li><code class=\"language-text\">h_0</code>: (num<em>layers * num</em>directions, batch, hidden<em>size) 여기서 <code class=\"language-text\">bidirectional</code>이 <code class=\"language-text\">True</code>라면, `num</em>directions<code class=\"language-text\">는 2,</code>False` 라면 1이 됩니다.</li>\n</ul>\n<h3>Outputs: output, h_n (<code class=\"language-text\">tuple</code> 형태)</h3>\n<ul>\n<li><code class=\"language-text\">output</code>: (seq<em>len, batch, num</em>directions * hidden<em>size) 여기서 <code class=\"language-text\">bidirectional</code>이 <code class=\"language-text\">True</code>라면, `num</em>directions<code class=\"language-text\">는 2,</code>False` 라면 1이 됩니다.</li>\n<li><code class=\"language-text\">h_n</code>: (num<em>layers * num</em>directions, batch, hidden<em>size) 여기서 <code class=\"language-text\">bidirectional</code>이 <code class=\"language-text\">True</code>라면, `num</em>directions<code class=\"language-text\">는 2,</code>False` 라면 1이 됩니다.</li>\n</ul>\n<h3>Code Example (Natural Language Processing)</h3>\n<p>해당 코드는 <code class=\"language-text\">NLP (Natural Language Processing)</code>을 위한 코드입니다. 앞의 두 단어를 보고, 뒤에 나올 단어를 예측 합니다.</p>\n<ul>\n<li><strong>In</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>optim <span class=\"token keyword\">as</span> optim\n\nsentences <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"i like dog\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"i love coffee\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"i hate milk\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"you like cat\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"you love milk\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"you hate coffee\"</span><span class=\"token punctuation\">]</span>\ndtype <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span>\n\n<span class=\"token triple-quoted-string string\">\"\"\"\nWord Processing\n\"\"\"</span>\nword_list <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>sentences<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nword_dict <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>w<span class=\"token punctuation\">:</span> i <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> w <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>word_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span>\nnumber_dict <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>i<span class=\"token punctuation\">:</span> w <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> w <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>word_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span>\nn_class <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>word_dict<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token triple-quoted-string string\">\"\"\"\nTextRNN Parameter\n\"\"\"</span>\nbatch_size <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>sentences<span class=\"token punctuation\">)</span>\nn_step <span class=\"token operator\">=</span> <span class=\"token number\">2</span>  <span class=\"token comment\"># 학습 하려고 하는 문장의 길이 - 1</span>\nn_hidden <span class=\"token operator\">=</span> <span class=\"token number\">5</span>  <span class=\"token comment\"># 은닉층 사이즈</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">make_batch</span><span class=\"token punctuation\">(</span>sentences<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  input_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n  target_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n  <span class=\"token keyword\">for</span> sen <span class=\"token keyword\">in</span> sentences<span class=\"token punctuation\">:</span>\n    word <span class=\"token operator\">=</span> sen<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token builtin\">input</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>word_dict<span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> n <span class=\"token keyword\">in</span> word<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n    target <span class=\"token operator\">=</span> word_dict<span class=\"token punctuation\">[</span>word<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n\n    input_batch<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>eye<span class=\"token punctuation\">(</span>n_class<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token builtin\">input</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># One-Hot Encoding</span>\n    target_batch<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>target<span class=\"token punctuation\">)</span>\n  \n  <span class=\"token keyword\">return</span> input_batch<span class=\"token punctuation\">,</span> target_batch\n\ninput_batch<span class=\"token punctuation\">,</span> target_batch <span class=\"token operator\">=</span> make_batch<span class=\"token punctuation\">(</span>sentences<span class=\"token punctuation\">)</span>\ninput_batch <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span>input_batch<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">,</span> requires_grad<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\ntarget_batch <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span>target_batch<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>int64<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token triple-quoted-string string\">\"\"\"\nTextRNN\n\"\"\"</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">TextRNN</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>TextRNN<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    self<span class=\"token punctuation\">.</span>rnn <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>RNN<span class=\"token punctuation\">(</span>input_size<span class=\"token operator\">=</span>n_class<span class=\"token punctuation\">,</span> hidden_size<span class=\"token operator\">=</span>n_hidden<span class=\"token punctuation\">,</span> dropout<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span>W <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Parameter<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>n_hidden<span class=\"token punctuation\">,</span> n_class<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>dtype<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span>b <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Parameter<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>n_class<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>dtype<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span>Softmax <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Softmax<span class=\"token punctuation\">(</span>dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> hidden<span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    X <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    outputs<span class=\"token punctuation\">,</span> hidden <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>rnn<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> hidden<span class=\"token punctuation\">)</span>\n    outputs <span class=\"token operator\">=</span> outputs<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># 최종 예측 Hidden Layer</span>\n    model <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>mm<span class=\"token punctuation\">(</span>outputs<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>W<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>b  <span class=\"token comment\"># 최종 예측 최종 출력 층</span>\n    <span class=\"token keyword\">return</span> model\n\t\n\n<span class=\"token triple-quoted-string string\">\"\"\"\nTraining\n\"\"\"</span>\nmodel <span class=\"token operator\">=</span> TextRNN<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ncriterion <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>CrossEntropyLoss<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\noptimizer <span class=\"token operator\">=</span> optim<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">500</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  hidden <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token punctuation\">,</span> n_hidden<span class=\"token punctuation\">,</span> requires_grad<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n  output <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>hidden<span class=\"token punctuation\">,</span> input_batch<span class=\"token punctuation\">)</span>\n  loss <span class=\"token operator\">=</span> criterion<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">,</span> target_batch<span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>epoch <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">%</span> <span class=\"token number\">100</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Epoch:'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'%04d'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>epoch <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'cost ='</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'{:.6f}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  \n  optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token builtin\">input</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>sen<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> sen <span class=\"token keyword\">in</span> sentences<span class=\"token punctuation\">]</span>\n\nhidden <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token punctuation\">,</span> n_hidden<span class=\"token punctuation\">,</span> requires_grad<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\npredict <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>hidden<span class=\"token punctuation\">,</span> input_batch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> keepdim<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>sen<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> sen <span class=\"token keyword\">in</span> sentences<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'->'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>number_dict<span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> n <span class=\"token keyword\">in</span> predict<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<ul>\n<li><strong>Out</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">Epoch: 0100 cost = 0.409607\nEpoch: 0200 cost = 0.099554\nEpoch: 0300 cost = 0.027191\nEpoch: 0400 cost = 0.013870\nEpoch: 0500 cost = 0.008780\n[[&#39;i&#39;, &#39;like&#39;], [&#39;i&#39;, &#39;love&#39;], [&#39;i&#39;, &#39;hate&#39;], [&#39;you&#39;, &#39;like&#39;], [&#39;you&#39;, &#39;love&#39;], [&#39;you&#39;, &#39;hate&#39;]] -&gt; [&#39;dog&#39;, &#39;coffee&#39;, &#39;milk&#39;, &#39;cat&#39;, &#39;milk&#39;, &#39;coffee&#39;]</code></pre></div>\n<h2>Long Short-Term Memory (LSTM)</h2>\n<p><code class=\"language-text\">LSTM (Long Short-Term Memory)</code>를 위한 <code class=\"language-text\">API</code>는 <code class=\"language-text\">torch.nn.LSTM(*args, **kwargs)</code> 입니다. <code class=\"language-text\">LSTM</code>은 <strong>기울기 폭발, 기울기 소실 등</strong>의 문제를 해결 하기 위해 기존 <code class=\"language-text\">RNN</code>을 개선한 구조로, <code class=\"language-text\">Input</code> 시퀀스의 각 요소에 대해, 각 레이어에서는 다음 연산을 수행합니다.</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>i</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mrow><mi>i</mi><mi>i</mi></mrow></msub><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mrow><mi>i</mi><mi>i</mi></mrow></msub><mo>+</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>i</mi></mrow></msub><msub><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub><mo>+</mo><msub><mi>b</mi><mrow><mi>h</mi><mi>i</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">i_t = \\sigma(W_{ii}x_t + b_{ii} + W_{hi}h_{(t-1)} + b_{hi})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.80952em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">i</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.04964em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">h</span><span class=\"mord mathdefault mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">h</span><span class=\"mord mathdefault mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>f</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mrow><mi>i</mi><mi>f</mi></mrow></msub><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mrow><mi>i</mi><mi>f</mi></mrow></msub><mo>+</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>f</mi></mrow></msub><msub><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub><mo>+</mo><msub><mi>b</mi><mrow><mi>h</mi><mi>f</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f_t = \\sigma(W_{if}x_t + b_{if} + W_{hf}h_{(t-1)} + b_{hf})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.04964em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">h</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">h</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>g</mi><mi>t</mi></msub><mo>=</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mrow><mi>i</mi><mi>g</mi></mrow></msub><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mrow><mi>i</mi><mi>g</mi></mrow></msub><mo>+</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>g</mi></mrow></msub><msub><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub><mo>+</mo><msub><mi>b</mi><mrow><mi>h</mi><mi>g</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">g_t = tanh(W_{ig}x_t + b_{ig} + W_{hg}h_{(t-1)} + b_{hg})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord mathdefault\">t</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">n</span><span class=\"mord mathdefault\">h</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.04964em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">h</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">h</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>o</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mrow><mi>i</mi><mi>o</mi></mrow></msub><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mrow><mi>i</mi><mi>o</mi></mrow></msub><mo>+</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>o</mi></mrow></msub><msub><mi>h</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub><mo>+</mo><msub><mi>b</mi><mrow><mi>h</mi><mi>o</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">o_t = \\sigma(W_{io}x_t + b_{io} + W_{ho}h_{(t-1)} + b_{ho})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">o</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">o</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">o</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.04964em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">h</span><span class=\"mord mathdefault mtight\">o</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">h</span><span class=\"mord mathdefault mtight\">o</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>c</mi><mi>t</mi></msub><mo>=</mo><msub><mi>f</mi><mi>t</mi></msub><mo>∗</mo><msub><mi>c</mi><mrow><mo stretchy=\"false\">(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub><mo>+</mo><msub><mi>i</mi><mi>t</mi></msub><mo>∗</mo><msub><mi>g</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">c_t = f_t * c_{(t-1)} + i_t * g_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9385299999999999em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.80952em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">i</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><msub><mi>o</mi><mi>t</mi></msub><mo>∗</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy=\"false\">(</mo><msub><mi>c</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_t = o_t * tanh(c_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.61528em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">o</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">t</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">n</span><span class=\"mord mathdefault\">h</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">c</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<h3>Parameters (RNN과 비슷합니다.)</h3>\n<ul>\n<li><code class=\"language-text\">input_size</code>: <code class=\"language-text\">Input</code>의 <strong>사이즈</strong>에 해당 하는 수를 입력하면 됩니다.</li>\n<li><code class=\"language-text\">hidden_size</code>: <strong>은닉층의 사이즈</strong>에 해당 하는 수를 입력하면 됩니다.</li>\n<li><code class=\"language-text\">num_layers</code>: <code class=\"language-text\">RNN</code>의 은닉층 레이어 갯수를 나타냅니다. 기본 값은 1입니다.</li>\n<li><code class=\"language-text\">bias</code>: <strong>바이어스 값</strong> 활성화 여부를 선택합니다. 기본 값은 <code class=\"language-text\">True</code> 입니다.</li>\n<li><code class=\"language-text\">batch_first</code>: <code class=\"language-text\">True</code>일 시, <code class=\"language-text\">Output</code> 값의 사이즈는 (batch, seq, feature) 가 됩니다. 기본 값은 <code class=\"language-text\">False</code> 입니다.</li>\n<li><code class=\"language-text\">dropout</code>: <strong>드롭아웃</strong> 비율을 설정 합니다. 기본 값은 0입니다.</li>\n<li><code class=\"language-text\">bidirectional</code>: <code class=\"language-text\">True</code>일 시, 양방향 RNN이 됩니다. 기본 값은 <code class=\"language-text\">False</code> 입니다.</li>\n</ul>\n<h3>Inputs: input, (h<em>0, c</em>0) (<code class=\"language-text\">tuple</code> 형태)</h3>\n<ul>\n<li><code class=\"language-text\">input</code>: (seq<em>len, batch, input</em>size)</li>\n<li><code class=\"language-text\">h_0</code>: (num<em>layers * num</em>directions, batch, hidden<em>size) 여기서 <code class=\"language-text\">bidirectional</code>이 <code class=\"language-text\">True</code>라면, `num</em>directions<code class=\"language-text\">는 2,</code>False` 라면 1이 됩니다.</li>\n<li><code class=\"language-text\">c_0</code>: (num<em>layers * num</em>directions, batch, hidden<em>size) 초기 <strong>Cell State</strong> 입니다.\n만약 (h</em>0, c_0)이 없다면, 기본 값은 영벡터 입니다.</li>\n</ul>\n<h3>Outputs: output, (h<em>n, c</em>0) (<code class=\"language-text\">tuple</code> 형태)</h3>\n<ul>\n<li><code class=\"language-text\">output</code>: (seq<em>len, batch, num</em>directions * hidden<em>size) 여기서 <code class=\"language-text\">bidirectional</code>이 <code class=\"language-text\">True</code>라면, `num</em>directions<code class=\"language-text\">는 2,</code>False` 라면 1이 됩니다.</li>\n<li><code class=\"language-text\">h_n</code>: (num<em>layers * num</em>directions, batch, hidden<em>size) 여기서 <code class=\"language-text\">bidirectional</code>이 <code class=\"language-text\">True</code>라면, `num</em>directions<code class=\"language-text\">는 2,</code>False` 라면 1이 됩니다.</li>\n<li><code class=\"language-text\">c_n</code>: (num<em>layers * num</em>directions, batch, hidden_size) <strong>Cell State</strong> 입니다.</li>\n</ul>\n<h3>Code Example</h3>\n<p>해당 코드는 <code class=\"language-text\">NLP (Natural Language Processing)</code>을 위한 코드입니다. 앞의 두 단어를 보고, 뒤에 나올 단어를 예측 합니다. <code class=\"language-text\">CNN</code> 코드와는 <code class=\"language-text\">Input</code> 파라미터에 차이가 있습니다.</p>\n<ul>\n<li><strong>In</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>optim <span class=\"token keyword\">as</span> optim\n\nsentences <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"i like dog\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"i love coffee\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"i hate milk\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"you like cat\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"you love milk\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"you hate coffee\"</span><span class=\"token punctuation\">]</span>\ndtype <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span><span class=\"token builtin\">float</span>\n\n<span class=\"token triple-quoted-string string\">\"\"\"\nWord Processing\n\"\"\"</span>\nword_list <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>sentences<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nword_dict <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>w<span class=\"token punctuation\">:</span> i <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> w <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>word_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span>\nnumber_dict <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>i<span class=\"token punctuation\">:</span> w <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> w <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>word_list<span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span>\nn_class <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>word_dict<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token triple-quoted-string string\">\"\"\"\nTextRNN Parameter\n\"\"\"</span>\nbatch_size <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>sentences<span class=\"token punctuation\">)</span>\nn_step <span class=\"token operator\">=</span> <span class=\"token number\">2</span>  <span class=\"token comment\"># 학습 하려고 하는 문장의 길이 - 1</span>\nn_hidden <span class=\"token operator\">=</span> <span class=\"token number\">5</span>  <span class=\"token comment\"># 은닉층 사이즈</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">make_batch</span><span class=\"token punctuation\">(</span>sentences<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  input_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n  target_batch <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n  <span class=\"token keyword\">for</span> sen <span class=\"token keyword\">in</span> sentences<span class=\"token punctuation\">:</span>\n    word <span class=\"token operator\">=</span> sen<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token builtin\">input</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>word_dict<span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> n <span class=\"token keyword\">in</span> word<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n    target <span class=\"token operator\">=</span> word_dict<span class=\"token punctuation\">[</span>word<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n\n    input_batch<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>eye<span class=\"token punctuation\">(</span>n_class<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token builtin\">input</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># One-Hot Encoding</span>\n    target_batch<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>target<span class=\"token punctuation\">)</span>\n  \n  <span class=\"token keyword\">return</span> input_batch<span class=\"token punctuation\">,</span> target_batch\n\ninput_batch<span class=\"token punctuation\">,</span> target_batch <span class=\"token operator\">=</span> make_batch<span class=\"token punctuation\">(</span>sentences<span class=\"token punctuation\">)</span>\ninput_batch <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span>input_batch<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">,</span> requires_grad<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\ntarget_batch <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>tensor<span class=\"token punctuation\">(</span>target_batch<span class=\"token punctuation\">,</span> dtype<span class=\"token operator\">=</span>torch<span class=\"token punctuation\">.</span>int64<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token triple-quoted-string string\">\"\"\"\nTextLSTM\n\"\"\"</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">TextLSTM</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>TextLSTM<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    self<span class=\"token punctuation\">.</span>lstm <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>LSTM<span class=\"token punctuation\">(</span>input_size<span class=\"token operator\">=</span>n_class<span class=\"token punctuation\">,</span> hidden_size<span class=\"token operator\">=</span>n_hidden<span class=\"token punctuation\">,</span> dropout<span class=\"token operator\">=</span><span class=\"token number\">0.3</span><span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span>W <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Parameter<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>n_hidden<span class=\"token punctuation\">,</span> n_class<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>dtype<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span>b <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Parameter<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>n_class<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>dtype<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span>Softmax <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Softmax<span class=\"token punctuation\">(</span>dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> hidden_and_cell<span class=\"token punctuation\">,</span> X<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    X <span class=\"token operator\">=</span> X<span class=\"token punctuation\">.</span>transpose<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    outputs<span class=\"token punctuation\">,</span> hidden <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>lstm<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> hidden_and_cell<span class=\"token punctuation\">)</span>\n    outputs <span class=\"token operator\">=</span> outputs<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># 최종 예측 Hidden Layer</span>\n    model <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>mm<span class=\"token punctuation\">(</span>outputs<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>W<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>b  <span class=\"token comment\"># 최종 예측 최종 출력 층</span>\n    <span class=\"token keyword\">return</span> model\n\t\n\n<span class=\"token triple-quoted-string string\">\"\"\"\nTraining\n\"\"\"</span>\nmodel <span class=\"token operator\">=</span> TextLSTM<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ncriterion <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>CrossEntropyLoss<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\noptimizer <span class=\"token operator\">=</span> optim<span class=\"token punctuation\">.</span>Adam<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span><span class=\"token number\">0.01</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">500</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  hidden <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token punctuation\">,</span> n_hidden<span class=\"token punctuation\">,</span> requires_grad<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n  cell <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token punctuation\">,</span> n_hidden<span class=\"token punctuation\">,</span> requires_grad<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n  output <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>hidden<span class=\"token punctuation\">,</span> cell<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> input_batch<span class=\"token punctuation\">)</span>\n  loss <span class=\"token operator\">=</span> criterion<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">,</span> target_batch<span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>epoch <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">%</span> <span class=\"token number\">100</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Epoch:'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'%04d'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>epoch <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'cost ='</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'{:.6f}'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  \n  optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token builtin\">input</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>sen<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> sen <span class=\"token keyword\">in</span> sentences<span class=\"token punctuation\">]</span>\n\nhidden <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token punctuation\">,</span> n_hidden<span class=\"token punctuation\">,</span> requires_grad<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\ncell <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token punctuation\">,</span> n_hidden<span class=\"token punctuation\">,</span> requires_grad<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\npredict <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>hidden<span class=\"token punctuation\">,</span> cell<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> input_batch<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> keepdim<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>sen<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> sen <span class=\"token keyword\">in</span> sentences<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'->'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>number_dict<span class=\"token punctuation\">[</span>n<span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> n <span class=\"token keyword\">in</span> predict<span class=\"token punctuation\">.</span>squeeze<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<ul>\n<li><strong>Out</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"terminal\"><pre class=\"language-terminal\"><code class=\"language-terminal\">Epoch: 0100 cost = 0.301909\nEpoch: 0200 cost = 0.039160\nEpoch: 0300 cost = 0.017456\nEpoch: 0400 cost = 0.009996\nEpoch: 0500 cost = 0.006636\n[[&#39;i&#39;, &#39;like&#39;], [&#39;i&#39;, &#39;love&#39;], [&#39;i&#39;, &#39;hate&#39;], [&#39;you&#39;, &#39;like&#39;], [&#39;you&#39;, &#39;love&#39;], [&#39;you&#39;, &#39;hate&#39;]] -&gt; [&#39;dog&#39;, &#39;coffee&#39;, &#39;milk&#39;, &#39;cat&#39;, &#39;milk&#39;, &#39;coffee&#39;]</code></pre></div>\n<h2>마치며</h2>\n<p>다음 시간부터는 <code class=\"language-text\">Pytorch</code>를 이용해서 실제 동작하는 <strong>어플리케이션</strong> 을 만들어 보도록 하겠습니다.</p>\n<h2>References</h2>\n<ul>\n<li><a href=\"https://pytorch.org/docs/stable/nn.html\">Pytorch Document</a></li>\n<li><a href=\"https://github.com/graykode/nlp-tutorial\">graykode/nlp-tutorial (github)</a></li>\n</ul>","id":"fd604893-7ec3-53e1-8173-e5ca5c9be50b","frontmatter":{"date":"2020-04-19","path":"/deep-learning/pytorch-rnn","title":"Pytorch로 RNN, LSTM 구현하기","tags":["Deep-Learning","Python"],"keyword":"Python, python, 파이썬, Pytorch, 파이토치, pytorch, 딥러닝, Neural Network, 신경망, RNN, Recurrent Neural Network, LSTM, Long Short-Term Memory","summary":"자연어 처리, 감성 분류 등에 사용되는 RNN, LSTM","img":"https://lionbridge.ai/wp-content/uploads/2020/03/2020-02-21_difference-between-cnn-rnn-1.png","series":"Pytorch Basic"}}},"pageContext":{"series":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"a2b924e9-9836-58ae-b3ae-4e480268cbcf","excerpt":"에서 모델의 가중치를 저장하기 위해선 3가지 함수만 알면 충분 합니다. : 객체를 디스크에 저장합니다.  모듈을 이용하여 객체를 직렬화 하며, 이 함수를 사용하여 모든 종류의 모델, Tensor 등을 저장할 수 있습니다. :  모듈을 이용하여 객체를 역직렬화하여 메모리에 할당합니다. : 역직렬화된 state_dict를 사용, 모델의 매개변수들을 불러옵니다. state_dict는 간단히 말해 각 체층을 매개변수 Tensor로 매핑한 Python…","frontmatter":{"date":"2020-04-26","tags":["Deep-Learning","Python"],"path":"/deep-learning/pytorch-save","title":"Pytorch에서 학습한 모델 저장 및 불러오기","img":"/post_image/pytorch-save.png","summary":"Pytorch 모델을 저장하고, 불러와 보기"}}},{"node":{"id":"fd604893-7ec3-53e1-8173-e5ca5c9be50b","excerpt":"에서는 과 마찬가지로, 과 관련 된 를 제공합니다. 이를 이용해 손쉽게  네트워크를 구축 할 수 있습니다. Recurrent Neural Network 를 위한 는  입니다. 일단  시퀀스의 각 요소에 대해, 각 레이어에서는 다음 연산을 수행합니다.  Parameters : 의 사이즈에 해당 하는 수를 입력하면 됩니다. : 은닉층의 사이즈에 해당 하는 수를 입력하면 됩니다. : 의 은닉층 레이어 갯수를 나타냅니다. 기본 값은…","frontmatter":{"date":"2020-04-19","tags":["Deep-Learning","Python"],"path":"/deep-learning/pytorch-rnn","title":"Pytorch로 RNN, LSTM 구현하기","img":"https://lionbridge.ai/wp-content/uploads/2020/03/2020-02-21_difference-between-cnn-rnn-1.png","summary":"자연어 처리, 감성 분류 등에 사용되는 RNN, LSTM"}}},{"node":{"id":"21ec001c-601e-5e4b-8ebc-f2cb41862240","excerpt":"CNN In Pytorch 에는 을 개발 하기 위한 들이 있습니다. 다채널로 구현 되어 있는 CNN 신경망을 위한 Layers, Max pooling, Avg pooling 등, 이번 시간에는 여러 가지 을 위한 를 알아 보겠습니다. 또한,  데이터 또한 학습 해 보겠습니다. Convolution Layers  연산을 위한 레이어들은 다음과 같습니다. Conv1d (Text-CNN에서 많이 사용) Conv2d…","frontmatter":{"date":"2020-04-08","tags":["Deep-Learning","Python"],"path":"/deep-learning/pytorch-cnn","title":"Pytorch로 CNN 구현하기","img":"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/02/Plot-of-a-Subset-of-Images-from-the-MNIST-Dataset-1024x768.png","summary":"Pytorch로 MNIST 그림 식별을 해보자."}}},{"node":{"id":"845b1f8c-db78-5c2d-9289-3248d0069fee","excerpt":"Neural Network in Pytorch 딥 러닝 프레임워크인 에선 신경망 구축을 위한 API…","frontmatter":{"date":"2020-04-04","tags":["Deep-Learning","Python"],"path":"/deep-learning/pytorch-nn","title":"Pytorch의 Neural Network","img":"https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/challenge_thumbnails/000/822/053/datas/original.png","summary":"Pytorch에서 신경망 구현하기"}}},{"node":{"id":"2f7903e5-090d-578d-a8b7-3f696d116862","excerpt":"Pytorch로 행렬을 미분해보자, autograd 딥러닝 이론에 대해서 공부 해 보신 분들은, 딥러닝의 핵심은 미분을 통해서 손실 함수(loss function)의 값을 최소화 하는 것을 알고 계실 겁니다. 그렇기 때문에 Deep Learning 연구 플랫폼인 에선, 당연하게도 행렬 미분을 위한 기능들을  객체에 내장 시켜 놓았습니다. 한 번 알아볼까요? autograd 활성화 시키기 requires_grad=True…","frontmatter":{"date":"2020-03-28","tags":["Deep-Learning","Python"],"path":"/deep-learning/pytorch-autograd","title":"Pytorch로 행렬을 미분해보자, autograd","img":"https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/challenge_thumbnails/000/822/053/datas/original.png","summary":"Pytorch로 행렬을 미분하는 방법"}}},{"node":{"id":"897e816a-7e4e-5fc4-8936-e49103bc1359","excerpt":"주의 필자인 저 또한 배운 것들을 정리 하면서 쓰는 글이기 때문에, 틀린 부분이 있을 수도 있습니다. 또한, 이 글은 에 대한 기본 적인 배경 지식을 필요로 합니다. 오타, 지적사항 발생 시, 댓글 혹은 이메일로 남겨 주시면 감사하겠습니다! Pytorch Pytorch는 두 가지 목표를 달성하기 위해 만들어진 오픈 소스 라이브러리이자, Python Package입니다. 두 가지 목표는 다음과 같습니다. Numpy가 기존에 하던 연산들을 GPU…","frontmatter":{"date":"2020-03-23","tags":["Deep-Learning","Python"],"path":"/deep-learning/pytorch-basic","title":"Pytorch에 대해서 알아보자.araboza","img":"https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/challenge_thumbnails/000/822/053/datas/original.png","summary":"딥러닝 플랫폼인 Pytorch에 대하여"}}}]}}},"categoryPosts":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"edbb5b70-1341-56dc-a484-10a4bee18986","excerpt":"Regularization 안녕하세요? 이번 시간에는 Regularization에 대해서 알아 보도록 하겠습니다. 우리가 모델을 만들 때, 많은 분들이 Overfitting을 경험 해 보셨을 것 입니다. 여러분들은 Overfitting을 경험할 때, 다음과 같은 것들을 시도 해 볼 것입니다. 모델의 크기를 줄인다. (네트워크의 깊이, 노드 갯수 등등) 데이터의 크기를 늘린다. 하지만, 이 외에도 다른 방법들이 있습니다. DropOut…","frontmatter":{"date":"2021-08-31","tags":["Data-Science","Deep-Learning"],"path":"/data-science/regularization","title":"Regularization: 모델의 과적합을 막는 방법","img":"/post_image/thumbnail/regularization.jpg","summary":"모델의 과적합을 막는 Regularization에 대해서 알아 보자."}}},{"node":{"id":"4bb77c07-a193-5691-a51c-fa1377db8569","excerpt":"Generative Adversarial Network 안녕하세요? 오늘은 GAN, Generative Adversarial Network에 대해서 알아 보도록 하겠습니다. Generative Adversarial Network…","frontmatter":{"date":"2021-08-07","tags":["Data-Science","Deep-Learning"],"path":"/data-science/just-data-science-12","title":"[찍먹 Data Science] 12. Generative Adversarial Network","img":"/post_image/thumbnail/just-data-science-12.jpg","summary":"서로가 적대적으로 학습하는 GAN에 대해서 알아 보자."}}},{"node":{"id":"8a0ee69e-b362-55d6-9ac0-8c9e8861f475","excerpt":"Recurrent Neural Network 안녕하세요? 오늘은 RNN, Recurrent Neural Network에 대해서 알아 보도록 하겠습니다. RNN…","frontmatter":{"date":"2021-08-05","tags":["Data-Science","Deep-Learning"],"path":"/data-science/just-data-science-11","title":"[찍먹 Data Science] 11. Recurrent Neural Network","img":"/post_image/thumbnail/just-data-science-11.jpg","summary":"시계열 데이터를 처리하는 RNN을 알아보자."}}},{"node":{"id":"ffe46d73-d05b-5d3f-a9ea-1f6b57ef50ba","excerpt":"Convolutional Neural Network 안녕하세요? 오늘은 CNN, Convolutional Neural Network에 대해서 알아 보도록 하겠습니다. 저번 시간에는 DNN…","frontmatter":{"date":"2021-07-31","tags":["Data-Science","Deep-Learning"],"path":"/data-science/just-data-science-10","title":"[찍먹 Data Science] 10. Convolutional Neural Network","img":"/post_image/thumbnail/just-data-science-10.jpg","summary":"국소적인 정보를 추출하는 CNN에 대해 알아 보자."}}}]}}}}},"staticQueryHashes":["234633779","63159454"]}