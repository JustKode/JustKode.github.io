{"componentChunkName":"component---src-layouts-list-layout-tsx","path":"/post/2/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"3c44d6b1-b341-5256-bb40-e6a58835b474","excerpt":"Intro 안녕하세요, 박민재입니다. 오늘은 Apache Iceberg의 Table에 수행 되는 쿼리가 최적의 성능으로 작동 될 수 있도록, File Compaction을 통해 이를 수행하는 방법에 대해 이야기 하는 시간을 가져 보도록 하겠습니다. File Compaction 우리가 쿼리를 수행 시, Hive Metastore의 정보를 이용하더라도, 혹은 Iceberg의 Metadata…","frontmatter":{"date":"2024-11-10","tags":["Data-Engineering"],"path":"/data-engineering/iceberg-table-optimization-1","title":"Iceberg Table의 성능 최적화 - 1. 압축","img":"/post_image/thumbnail/iceberg-table-optimization-1.webp","summary":"File Merge를 통한 성능 최적화에 대해 알아보자."}}},{"node":{"id":"6eaa7aeb-a4fe-5cd9-bbe5-309dde97514b","excerpt":"안녕하세요, 박민재입니다. 오늘은 Airflow DB를 관리하는 방법에 대해서 이야기 나눠 보도록 하겠습니다. Airflow Backend Database Airflow에서 Backend Database는 어떤 역할을 할까요? Airflow에서 DAG을 실행 하기 위해서, Airflow는 다음과 같은 정보들을 Backend Database에 저장하여 정합성을 유지 합니다. DagRun: 특정 Interval에 실행 된 DagRun…","frontmatter":{"date":"2024-10-27","tags":["Data-Engineering"],"path":"/data-engineering/airflow-db-management","title":"Airflow Backend Database Management (airflow db clean)","img":"/post_image/thumbnail/airflow-db-management.webp","summary":"Airflow의 Backend Database를 관리 하는 법"}}},{"node":{"id":"b595b168-8160-5abf-9641-39746d2f9e82","excerpt":"안녕하세요, 박민재입니다. 오늘은 Spark Application내의 각 Executor 내의 Task에 제한적으로 변수를 공유하는 두 가지 방법에 대해서 알아 보도록 하겠습니다. 시작하기에 앞서 단편적으로 생각 해 보면, Spark Application에서 연산 과정의 변수를 공유 한다는 것은 어려운 일인가? 라는 질문을 던져 볼 수 있습니다. 우리는 Task…","frontmatter":{"date":"2024-10-11","tags":["Data-Engineering"],"path":"/data-engineering/spark-sharing-variables","title":"Sharing Variables in Spark - Broadcast, Accumulator","img":"/post_image/thumbnail/spark-sharing-variables.png","summary":"Spark Application에서 변수를 공유 하는 방법"}}},{"node":{"id":"5effd6a1-bfd8-5a86-b718-5eb1e534601e","excerpt":"Intro 안녕하세요, 박민재입니다. 오늘은 Spark Memory에 관해 Deep Dive를 해 보도록 하겠습니다. Spark는 In-Memory를 이용하여, 빠른 연산을 할 수 있도록 보장합니다. 하지만, In-Memory 연산은 빠른 대신, 비싼 관계로 적은 리소스 만을 활용할 수 있습니다. 그렇기 때문에 우리는 효율적으로 Memory를 관리 하여, Spark Application이 빠르고, 안정적으로 Task…","frontmatter":{"date":"2024-04-12","tags":["Data-Engineering"],"path":"/data-engineering/spark-memory-deep-dive","title":"Deep Dive of Spark Memory","img":"/post_image/thumbnail/spark-memory-deep-dive.jpeg","summary":"Spark Memory의 깊은 이해를 위해 Deep Dive를 해 보자."}}},{"node":{"id":"9a77a751-f1a2-59c2-9065-808620c51bbe","excerpt":"안녕하세요? 박민재입니다. 오늘은 Data Discovery에 대해서 알아 보도록 하겠습니다. What is Data Discovery? Data Discovery란 무엇 일까요? Data Discovery는 조직 내 데이터를 찾고 이해하는 프로세스를 의미 합니다. Data Engineer들은 요구사항을 수행하기 위해, 많은 Data Source에서 다양한 Data Table…","frontmatter":{"date":"2024-03-17","tags":["Data-Engineering"],"path":"/data-engineering/what-is-data-discovery","title":"Data Discovery란 무엇인가?","img":"/post_image/thumbnail/what-is-data-discovery.jpeg","summary":"데이터를 찾고 이해하는 프로세스인, Data Discovery에 대하여"}}},{"node":{"id":"8ef2f1ec-bc6d-5cbe-923c-ab49bb89e68e","excerpt":"Intro 안녕하세요! JustKode, 박민재입니다. 오늘은 K8S Package Manager인 Helm에 대해 알아 보도록 하겠습니다. 우리는 K8S로 서비스를 서빙하기 위해, k8s yaml 파일을 이용하여, K8S Resource (, , , , ,  등)를 관리 하게 됩니다. 하지만, 우리는 실제 서비스를 운영 하는데 다음과 같은 상황을 마주치게 됩니다. 여러 개의 K8S Resource를 K8S Cluster…","frontmatter":{"date":"2024-03-01","tags":["Cloud-Computing"],"path":"/cloud-computing/what-is-helm","title":"Helm이란 무엇 인가?","img":"/post_image/thumbnail/what-is-helm.png","summary":"K8S의 Package Manager인, Helm에 대해 알아보자."}}}]}},"pageContext":{"title":"Posts","description":"전체 게시글 목록입니다.","img":"/post_background.jpg","url":"post","imagePosition":"center bottom","keyword":"전체 글","filter":{"frontmatter":{"title":{"ne":""},"tags":{"nin":["Archive"]}}},"limit":6,"skip":6,"numPages":9,"currentPage":2}},"staticQueryHashes":["3819017183","63159454"],"slicesMap":{}}